{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ee45436",
   "metadata": {},
   "source": [
    "### Starting with a little Jupyter Magic\n",
    "These magic commands tell Jupyter to automatically reload modules that have changed. This is very useful during development so you don't have to manually restart the kernel after making modifications to your Python files. `%load_ext autoreload` loads the extension, and `%autoreload 2` configures it to reload all modules (except those explicitly excluded)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "deac5a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb395d06",
   "metadata": {},
   "source": [
    "# 1. Setup our RAG Pipeline\n",
    "We implement a simple RAG pipeline using LlamaIndex - you are of course welcome to use any other framework you please!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "237e4938",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import warnings\n",
    "import nest_asyncio\n",
    "\n",
    "_ = load_dotenv(find_dotenv())\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbaeee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import (\n",
    "    Settings,\n",
    "    VectorStoreIndex,\n",
    "    SimpleDirectoryReader,\n",
    ")\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "\n",
    "Settings.llm = OpenAI(model=\"gpt-4o\")\n",
    "Settings.embed_model = OpenAIEmbedding(model=\"text-embedding-ada-002\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23e3f89",
   "metadata": {},
   "source": [
    "### Ingest documents and Generate RAG Dataset\n",
    "\n",
    "Okay, the next step in our recipe involves preparing the data and generating a synthetic dataset for Retrieval Augmented Generation (RAG)!\n",
    "\n",
    "We use gpt-4o to attempt generating 10 question-answer pairs for each chunk of text extracted from the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3248b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading files:   0%|          | 0/1 [00:00<?, ?file/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading files: 100%|██████████| 1/1 [00:00<00:00,  1.19file/s]\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.llama_dataset.generator import RagDatasetGenerator\n",
    "\n",
    "docs = SimpleDirectoryReader(\"../data/\").load_data(show_progress=True)\n",
    "data_gen = RagDatasetGenerator.from_documents(\n",
    "    docs,\n",
    "    llm= Settings.llm,\n",
    "    question_gen_query=\"You are a teacher/professor. Using the provided context, formulat a single question and its answer\",\n",
    "    num_questions_per_chunk=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12623644",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_dataset = data_gen.generate_dataset_from_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65c847c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LabelledRagDataExample(query='**Question:** What were the main findings of the study conducted by Susan Athey and Emil Palikot on the labor market value of non-traditional credentials obtained from MOOCs?', query_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>), reference_contexts=['The value of non-traditional credentials in the labor market*\\nSusan Athey & Emil Palikot\\nMay 2, 2024\\nAbstract\\nThis study investigates the labor market value of credentials obtained from Massive Open On-\\nline Courses (MOOCs) and shared on business networking platforms. We conducted a random-\\nized experiment involving more than 800,000 learners, primarily from developing countries and\\nwithout college degrees, who completed technology or business-related courses on the Coursera\\nplatform between September 2022 and March 2023. The intervention targeted learners who had\\nrecently completed their courses, encouraging them to share their credentials and simplifying the\\nsharing process. One year after the intervention, we collected data from LinkedIn profiles of ap-\\nproximately 40,000 experimental subjects. We find that the intervention leads to an increase of 17\\npercentage points for credential sharing. Further, learners in the treatment group were 6% more\\nlikely to report new employment within a year, with an 8% increase in jobs related to their certifi-\\ncates. This effect was more pronounced among LinkedIn users with lower baseline employability.\\nAcross the entire sample, the treated group received a higher number of certificate views, indicat-\\ning an increased interest in their profiles. These results suggest that facilitating credential sharing\\nand reminding learners of the value of skill signaling can yield significant gains. When the ex-\\nperiment is viewed as an encouragement design for credential sharing, we can estimate the local\\naverage treatment effect (LATE) of credential sharing (that is, the impact of credential sharing on\\nthe workers induced to share by the intervention) for the outcome of getting a job. The LATE esti-\\nmates are imprecise but large in magnitude; they suggest that credential sharing more than doubles\\nthe baseline probability of getting a new job in scope for the credential.\\n*We thank Eric Karsten and his team in Coursera for collaborating on this project. We thank Keshav Agrawal and Elena\\nPittarokoili for excellent research assistance. The Golub Capital Social Impact Lab at Stanford Graduate School of Business\\nprovided funding for this research. This research has been subject to review and approval by Research Compliance Office\\nat Stanford University, protocol number IRB-59983 and registered at AEA RCT registry AEARCTR-0009438 .\\n1\\narXiv:2405.00247v1  [econ.GN]  30 Apr 2024'], reference_answer='The study conducted by Susan Athey and Emil Palikot found that facilitating the sharing of non-traditional credentials obtained from MOOCs on business networking platforms can significantly impact labor market outcomes. The main findings include:\\n\\n1. The intervention led to a 17 percentage point increase in credential sharing among learners.\\n2. Learners in the treatment group were 6% more likely to report new employment within a year.\\n3. There was an 8% increase in jobs related to the certificates among the treatment group.\\n4. The effect was more pronounced among LinkedIn users with lower baseline employability.\\n5. The treated group received a higher number of certificate views, indicating increased interest in their profiles.\\n6. The local average treatment effect (LATE) estimates suggest that credential sharing more than doubles the baseline probability of getting a new job in scope for the credential, although these estimates are imprecise but large in magnitude.', reference_answer_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>)),\n",
       " LabelledRagDataExample(query='**Answer:** The study found that the intervention, which encouraged learners to share their credentials on business networking platforms, led to a 17 percentage point increase in credential sharing. Additionally, learners in the treatment group were 6% more likely to report new employment within a year, with an 8% increase in jobs related to their certificates. The effect was more pronounced among LinkedIn users with lower baseline employability. The treated group also received a higher number of certificate views, indicating increased interest in their profiles. These results suggest that facilitating credential sharing and reminding learners of the value of skill signaling can yield significant gains in employability.', query_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>), reference_contexts=['The value of non-traditional credentials in the labor market*\\nSusan Athey & Emil Palikot\\nMay 2, 2024\\nAbstract\\nThis study investigates the labor market value of credentials obtained from Massive Open On-\\nline Courses (MOOCs) and shared on business networking platforms. We conducted a random-\\nized experiment involving more than 800,000 learners, primarily from developing countries and\\nwithout college degrees, who completed technology or business-related courses on the Coursera\\nplatform between September 2022 and March 2023. The intervention targeted learners who had\\nrecently completed their courses, encouraging them to share their credentials and simplifying the\\nsharing process. One year after the intervention, we collected data from LinkedIn profiles of ap-\\nproximately 40,000 experimental subjects. We find that the intervention leads to an increase of 17\\npercentage points for credential sharing. Further, learners in the treatment group were 6% more\\nlikely to report new employment within a year, with an 8% increase in jobs related to their certifi-\\ncates. This effect was more pronounced among LinkedIn users with lower baseline employability.\\nAcross the entire sample, the treated group received a higher number of certificate views, indicat-\\ning an increased interest in their profiles. These results suggest that facilitating credential sharing\\nand reminding learners of the value of skill signaling can yield significant gains. When the ex-\\nperiment is viewed as an encouragement design for credential sharing, we can estimate the local\\naverage treatment effect (LATE) of credential sharing (that is, the impact of credential sharing on\\nthe workers induced to share by the intervention) for the outcome of getting a job. The LATE esti-\\nmates are imprecise but large in magnitude; they suggest that credential sharing more than doubles\\nthe baseline probability of getting a new job in scope for the credential.\\n*We thank Eric Karsten and his team in Coursera for collaborating on this project. We thank Keshav Agrawal and Elena\\nPittarokoili for excellent research assistance. The Golub Capital Social Impact Lab at Stanford Graduate School of Business\\nprovided funding for this research. This research has been subject to review and approval by Research Compliance Office\\nat Stanford University, protocol number IRB-59983 and registered at AEA RCT registry AEARCTR-0009438 .\\n1\\narXiv:2405.00247v1  [econ.GN]  30 Apr 2024'], reference_answer='The study found that the intervention, which encouraged learners to share their credentials on business networking platforms, led to a 17 percentage point increase in credential sharing. Additionally, learners in the treatment group were 6% more likely to report new employment within a year, with an 8% increase in jobs related to their certificates. The effect was more pronounced among LinkedIn users with lower baseline employability. The treated group also received a higher number of certificate views, indicating increased interest in their profiles. These results suggest that facilitating credential sharing and reminding learners of the value of skill signaling can yield significant gains in employability.', reference_answer_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>)),\n",
       " LabelledRagDataExample(query='**Question:** What was the primary focus of the randomized experiment conducted in the context of Coursera, and what were the key outcomes measured?', query_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>), reference_contexts=['1 Introduction\\nIn today’s educational landscape, non-traditional credentials, frequently acquired through online courses,\\nhave become increasingly popular. In 2021, more than 40 million learners signed up for a Massive\\nOpen Online Course (MOOC) (Shah, 2021). Many learners gain these credentials with the intention\\nof signaling specific skills to potential employers (Laryea et al., 2021). Despite their prevalence, there\\nremains a significant gap in high-quality evidence demonstrating their actual value in the labor mar-\\nket. This raises important questions: To what extent do these non-traditional credentials help learners\\nsecure new employment? Moreover, who benefits the most from them?\\nIn this paper, we study whether showcasing a credential acquired from a MOOC on a business\\nnetworking platform increases learners’ chances of finding new employment and whether light-touch\\nplatform policies encouraging doing that can be effective. In particular, we conducted a randomized\\nexperiment in the context of Coursera, a prominent MOOC provider, in which learners were encour-\\naged to add their newly gained credentials to their LinkedIn profiles. We focus on a sample of learners\\nwho have recently graduated from a career-oriented certificate program and who do not have a college\\ndegree or come from a developing country. These learners often lack access to traditional credentials\\nor to internationally renowned educational institutions, which makes them more likely to benefit from\\nsignaling skills through non-traditional credentials (Hansen and Reich, 2015; Moura et al., 2017).\\nA randomly selected subset of these learners received access to the Credential Feature. This feature\\nprovided an enhanced process for showcasing Coursera credentials on learners’ LinkedIn profiles,\\nalong with targeted notifications that encouraged this action. The control group, in contrast, did not\\nreceive access to the feature. In our primary analysis, access to Credential Feature is the treatment of\\ninterest, and the reporting of new employment on LinkedIn (New Job) is the outcome. Additionally, we\\ndefine Credential Shared as the inclusion of the MOOC credential on a LinkedIn profile by the learners.\\nCredential Shared is an outcome from the perspective of evaluating the Credential Feature intervention,\\nbut when the experiment is viewed as an encouragement design for sharing, we study the impact of\\nCredential Shared (now considered as a treatment) on employment outcomes.\\nThe primary analysis focuses on the approximately 40,000 subjects who included their LinkedIn\\nprofile URLs in their Coursera accounts before randomization. For these learners, we analyze data\\nfrom their LinkedIn profiles to assess if they reported new employment after their exposure to the\\nCredential Feature, especially in a role related to their MOOC credentials.\\n2'], reference_answer=\"The primary focus of the randomized experiment conducted in the context of Coursera was to study whether showcasing a credential acquired from a MOOC on a business networking platform, specifically LinkedIn, increases learners' chances of finding new employment. The experiment also aimed to evaluate the effectiveness of light-touch platform policies that encourage learners to add their credentials to their LinkedIn profiles. The key outcomes measured were the reporting of new employment on LinkedIn (New Job) and the inclusion of the MOOC credential on a LinkedIn profile by the learners (Credential Shared).\", reference_answer_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>)),\n",
       " LabelledRagDataExample(query=\"**Answer:** The primary focus of the randomized experiment conducted in the context of Coursera was to determine whether showcasing a credential acquired from a MOOC on a business networking platform, specifically LinkedIn, increases learners' chances of finding new employment. The key outcomes measured were the reporting of new employment on LinkedIn (New Job) and the inclusion of the MOOC credential on a LinkedIn profile by the learners (Credential Shared). The experiment aimed to evaluate the effectiveness of the Credential Feature, which provided an enhanced process for showcasing Coursera credentials on LinkedIn profiles, along with targeted notifications encouraging this action.\", query_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>), reference_contexts=['1 Introduction\\nIn today’s educational landscape, non-traditional credentials, frequently acquired through online courses,\\nhave become increasingly popular. In 2021, more than 40 million learners signed up for a Massive\\nOpen Online Course (MOOC) (Shah, 2021). Many learners gain these credentials with the intention\\nof signaling specific skills to potential employers (Laryea et al., 2021). Despite their prevalence, there\\nremains a significant gap in high-quality evidence demonstrating their actual value in the labor mar-\\nket. This raises important questions: To what extent do these non-traditional credentials help learners\\nsecure new employment? Moreover, who benefits the most from them?\\nIn this paper, we study whether showcasing a credential acquired from a MOOC on a business\\nnetworking platform increases learners’ chances of finding new employment and whether light-touch\\nplatform policies encouraging doing that can be effective. In particular, we conducted a randomized\\nexperiment in the context of Coursera, a prominent MOOC provider, in which learners were encour-\\naged to add their newly gained credentials to their LinkedIn profiles. We focus on a sample of learners\\nwho have recently graduated from a career-oriented certificate program and who do not have a college\\ndegree or come from a developing country. These learners often lack access to traditional credentials\\nor to internationally renowned educational institutions, which makes them more likely to benefit from\\nsignaling skills through non-traditional credentials (Hansen and Reich, 2015; Moura et al., 2017).\\nA randomly selected subset of these learners received access to the Credential Feature. This feature\\nprovided an enhanced process for showcasing Coursera credentials on learners’ LinkedIn profiles,\\nalong with targeted notifications that encouraged this action. The control group, in contrast, did not\\nreceive access to the feature. In our primary analysis, access to Credential Feature is the treatment of\\ninterest, and the reporting of new employment on LinkedIn (New Job) is the outcome. Additionally, we\\ndefine Credential Shared as the inclusion of the MOOC credential on a LinkedIn profile by the learners.\\nCredential Shared is an outcome from the perspective of evaluating the Credential Feature intervention,\\nbut when the experiment is viewed as an encouragement design for sharing, we study the impact of\\nCredential Shared (now considered as a treatment) on employment outcomes.\\nThe primary analysis focuses on the approximately 40,000 subjects who included their LinkedIn\\nprofile URLs in their Coursera accounts before randomization. For these learners, we analyze data\\nfrom their LinkedIn profiles to assess if they reported new employment after their exposure to the\\nCredential Feature, especially in a role related to their MOOC credentials.\\n2'], reference_answer=\"The primary focus of the randomized experiment conducted in the context of Coursera was to determine whether showcasing a credential acquired from a MOOC on a business networking platform, specifically LinkedIn, increases learners' chances of finding new employment. The key outcomes measured were the reporting of new employment on LinkedIn (New Job) and the inclusion of the MOOC credential on a LinkedIn profile by the learners (Credential Shared). The experiment aimed to evaluate the effectiveness of the Credential Feature, which provided an enhanced process for showcasing Coursera credentials on LinkedIn profiles, along with targeted notifications encouraging this action.\", reference_answer_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>)),\n",
       " LabelledRagDataExample(query=\"**Question:** Based on the study's findings, how does the act of sharing credentials on LinkedIn influence the likelihood of obtaining a new job, particularly for learners with lower baseline employability?\", query_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>), reference_contexts=['Within this sample, we estimate that the learners in the treatment group are 6% (S.E. 2%) more\\nlikely to report new employment within a year after the treatment, representing a 1 percentage point\\n(p.p.) increase from the baseline of 17%. Furthermore, there is a 9% (S.E. 3%) higher likelihood that\\nthe treated learners report a new job directly related to the certificate they earned, an increase of 1.2\\np.p. (S.E. 0.6 p.p.) from the baseline of 13%. These results remain robust even when excluding new\\njobs reported with a starting date within the first four months after the randomization, which could\\npotentially reflect jobs found earlier and reported on LinkedIn due to treatment. Furthermore, this\\neffect does not appear to be driven by an increased engagement with LinkedIn, as evidenced by a\\ncomparative analysis of the completeness of LinkedIn profiles between groups. Instead, the effect of\\nthe treatment appears to be primarily mediated by the presence of credentials in learners’ profiles: we\\nestimate that the treatment group is 17% (2.8 p.p. S.E. 0.4 p.p.) more likely to share their credentials\\non LinkedIn.\\nCredential Shared, which is the act of sharing the credential on LinkedIn, is another treatment of\\ninterest. In this case, the random assignment of the Credential Feature works as an encouragement for\\nadding the credential to LinkedIn, and the effect of Credential Feature on New Job is then interpreted as\\nthe intent to treat (ITT) for theCredential Shared treatment. The local average treatment effect (LATE) of\\nCredential Shared on New Job, which is the effect for the type of learner induced to share credentials by\\nexposure to the Credential Feature, is 24 p.p. (S.E. 13 p.p.) and 36 p.p. (S.E. 12 p.p.) when considering\\nonly jobs directly related to the certificate they earned.\\nPrevious literature has documented that participants of MOOCs are predominantly highly edu-\\ncated individuals often employed in high-quality jobs, leading to the conclusion that MOOCs can\\nexacerbate outcome disparities (Christensen et al., 2013; Zhenghao et al., 2015). Our study focuses on\\nlearners without college degrees and those from developing countries. Thus, we focus on learners\\nwith lower baseline employability as compared to the general population of learners participating in\\nMOOCs. To better understand whether our treatments contribute to or mitigate disparities in out-\\ncomes within the population of our interest, we analyze heterogeneity in the effects of both the Cre-\\ndential Feature and the Credential Shared with respect to predicted baseline employability. We leverage\\ndata on educational and employment backgrounds from learners’ LinkedIn profiles to build a predic-\\ntive model for the outcome of finding a job in the absence of the intervention. Our analysis reveals that\\namong learners who shared their LinkedIn accounts, those with a lower baseline predicted probabil-\\nity of finding a new job have higher treatment effects from the Credential Feature and Credential Shared\\n3'], reference_answer=\"Based on the study's findings, the act of sharing credentials on LinkedIn significantly influences the likelihood of obtaining a new job, especially for learners with lower baseline employability. The local average treatment effect (LATE) of sharing credentials on LinkedIn is substantial, with a 24 percentage point increase in the likelihood of obtaining a new job and a 36 percentage point increase when considering jobs directly related to the certificate earned. Additionally, the analysis reveals that learners with a lower baseline predicted probability of finding a new job experience higher treatment effects from sharing credentials, suggesting that this practice can help mitigate disparities in employment outcomes for these individuals.\", reference_answer_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>)),\n",
       " LabelledRagDataExample(query='**Answer:** The study indicates that the act of sharing credentials on LinkedIn significantly increases the likelihood of obtaining a new job, especially for learners with lower baseline employability. The local average treatment effect (LATE) of sharing credentials on LinkedIn is 24 percentage points for new jobs in general and 36 percentage points for jobs directly related to the certificate earned. This suggests that sharing credentials can be particularly beneficial for those with initially lower chances of employment, as it enhances their visibility and credibility in the job market.', query_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>), reference_contexts=['Within this sample, we estimate that the learners in the treatment group are 6% (S.E. 2%) more\\nlikely to report new employment within a year after the treatment, representing a 1 percentage point\\n(p.p.) increase from the baseline of 17%. Furthermore, there is a 9% (S.E. 3%) higher likelihood that\\nthe treated learners report a new job directly related to the certificate they earned, an increase of 1.2\\np.p. (S.E. 0.6 p.p.) from the baseline of 13%. These results remain robust even when excluding new\\njobs reported with a starting date within the first four months after the randomization, which could\\npotentially reflect jobs found earlier and reported on LinkedIn due to treatment. Furthermore, this\\neffect does not appear to be driven by an increased engagement with LinkedIn, as evidenced by a\\ncomparative analysis of the completeness of LinkedIn profiles between groups. Instead, the effect of\\nthe treatment appears to be primarily mediated by the presence of credentials in learners’ profiles: we\\nestimate that the treatment group is 17% (2.8 p.p. S.E. 0.4 p.p.) more likely to share their credentials\\non LinkedIn.\\nCredential Shared, which is the act of sharing the credential on LinkedIn, is another treatment of\\ninterest. In this case, the random assignment of the Credential Feature works as an encouragement for\\nadding the credential to LinkedIn, and the effect of Credential Feature on New Job is then interpreted as\\nthe intent to treat (ITT) for theCredential Shared treatment. The local average treatment effect (LATE) of\\nCredential Shared on New Job, which is the effect for the type of learner induced to share credentials by\\nexposure to the Credential Feature, is 24 p.p. (S.E. 13 p.p.) and 36 p.p. (S.E. 12 p.p.) when considering\\nonly jobs directly related to the certificate they earned.\\nPrevious literature has documented that participants of MOOCs are predominantly highly edu-\\ncated individuals often employed in high-quality jobs, leading to the conclusion that MOOCs can\\nexacerbate outcome disparities (Christensen et al., 2013; Zhenghao et al., 2015). Our study focuses on\\nlearners without college degrees and those from developing countries. Thus, we focus on learners\\nwith lower baseline employability as compared to the general population of learners participating in\\nMOOCs. To better understand whether our treatments contribute to or mitigate disparities in out-\\ncomes within the population of our interest, we analyze heterogeneity in the effects of both the Cre-\\ndential Feature and the Credential Shared with respect to predicted baseline employability. We leverage\\ndata on educational and employment backgrounds from learners’ LinkedIn profiles to build a predic-\\ntive model for the outcome of finding a job in the absence of the intervention. Our analysis reveals that\\namong learners who shared their LinkedIn accounts, those with a lower baseline predicted probabil-\\nity of finding a new job have higher treatment effects from the Credential Feature and Credential Shared\\n3'], reference_answer='The study indicates that the act of sharing credentials on LinkedIn significantly increases the likelihood of obtaining a new job, especially for learners with lower baseline employability. The local average treatment effect (LATE) of sharing credentials on LinkedIn is 24 percentage points for new jobs in general and 36 percentage points for jobs directly related to the certificate earned. This suggests that sharing credentials can be particularly beneficial for those with initially lower chances of employment, as it enhances their visibility and credibility in the job market.', reference_answer_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>)),\n",
       " LabelledRagDataExample(query='Question: How do non-traditional credentials, such as MOOC certificates, impact the employability of LinkedIn users with lower baseline employability according to the study?', query_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>), reference_contexts=['than learners with high baseline employability. This suggests that platform policies that facilitate and\\nencourage the sharing of credentials particularly benefit learners in groups with the lowest chance of\\nreporting new jobs. Furthermore, our results show that signaling skills with non-traditional creden-\\ntials benefits LinkedIn users with lower baseline employability and could be an effective strategy for\\nthese learners to increase their chances of finding new jobs.\\nA secondary analysis relies on surrogate outcomes for the entire experimental population of over\\n800,000 learners. Although we do not observe the details of the LinkedIn profiles for most of these\\nlearners, we can still measure whether the learner placed the credential on their profile and received\\na click on it from another LinkedIn user. Clicking on the credential redirects to the certificate page\\non Coursera and reveals more information about it, specifically concerning the skills learned by the\\nindividual. This click may indicate increased interest from potential employers, and we show in the\\nsubsample with employment outcomes that clicks on the certificate are strongly correlated with new\\njob reporting. We refer to this surrogate outcome as Credential View. Adjusted for the characteristics\\nof the learners, we estimate that the assignment of the Credential Feature increases the probability of\\nCredential View by 2% to 4% of the baseline probability of receiving a view, which is about 0.13. This\\nevidence suggests that the impact of the intervention extended beyond the sub-sample where we\\nobserved employment outcomes.\\n2 Literature review\\nThis paper engages with several strands of literature. It primarily contributes to research on the per-\\nception and value of non-traditional credentials among employers and the impact of MOOC creden-\\ntials on learners’ employability. It further connects with literature on skill signaling and credential\\nsignaling. Our study offers evidence from a randomized experiment, isolating the impact of skill\\nsignaling with MOOC credentials and separating it from the skill level or job search motivation of\\nlearners.\\nUsing randomized audit studies (sending fictitious resumes to job openings posted online), Dem-\\ning et al. (2016) and Lennon (2021) showed that online degrees have a lower impact on employa-\\nbility than traditional degrees. Rivas et al. (2020), using a recruited experiment where mechanical\\nTurk workers were asked to select among alternative hypothetical worker profiles, demonstrated that\\nMOOC credentials increase the chances of being selected for a job as compared to having no creden-\\ntials at all. Hadavand et al. (2018) compared outcomes of completers to non-completers of a large\\n4'], reference_answer='According to the study, non-traditional credentials, such as MOOC certificates, positively impact the employability of LinkedIn users with lower baseline employability. These credentials benefit these users by increasing their chances of finding new jobs. The study suggests that signaling skills with non-traditional credentials is an effective strategy for these learners to enhance their employability. Additionally, the study found that clicks on the credential, which indicate increased interest from potential employers, are strongly correlated with new job reporting, further supporting the positive impact of these credentials on employability.', reference_answer_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>)),\n",
       " LabelledRagDataExample(query='Answer: The study suggests that signaling skills with non-traditional credentials, like MOOC certificates, benefits LinkedIn users with lower baseline employability by increasing their chances of finding new jobs. The platform policies that encourage sharing these credentials particularly benefit learners in groups with the lowest chance of reporting new jobs. Additionally, clicks on the credential, which redirect to the certificate page on Coursera, are strongly correlated with new job reporting, indicating increased interest from potential employers.', query_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>), reference_contexts=['than learners with high baseline employability. This suggests that platform policies that facilitate and\\nencourage the sharing of credentials particularly benefit learners in groups with the lowest chance of\\nreporting new jobs. Furthermore, our results show that signaling skills with non-traditional creden-\\ntials benefits LinkedIn users with lower baseline employability and could be an effective strategy for\\nthese learners to increase their chances of finding new jobs.\\nA secondary analysis relies on surrogate outcomes for the entire experimental population of over\\n800,000 learners. Although we do not observe the details of the LinkedIn profiles for most of these\\nlearners, we can still measure whether the learner placed the credential on their profile and received\\na click on it from another LinkedIn user. Clicking on the credential redirects to the certificate page\\non Coursera and reveals more information about it, specifically concerning the skills learned by the\\nindividual. This click may indicate increased interest from potential employers, and we show in the\\nsubsample with employment outcomes that clicks on the certificate are strongly correlated with new\\njob reporting. We refer to this surrogate outcome as Credential View. Adjusted for the characteristics\\nof the learners, we estimate that the assignment of the Credential Feature increases the probability of\\nCredential View by 2% to 4% of the baseline probability of receiving a view, which is about 0.13. This\\nevidence suggests that the impact of the intervention extended beyond the sub-sample where we\\nobserved employment outcomes.\\n2 Literature review\\nThis paper engages with several strands of literature. It primarily contributes to research on the per-\\nception and value of non-traditional credentials among employers and the impact of MOOC creden-\\ntials on learners’ employability. It further connects with literature on skill signaling and credential\\nsignaling. Our study offers evidence from a randomized experiment, isolating the impact of skill\\nsignaling with MOOC credentials and separating it from the skill level or job search motivation of\\nlearners.\\nUsing randomized audit studies (sending fictitious resumes to job openings posted online), Dem-\\ning et al. (2016) and Lennon (2021) showed that online degrees have a lower impact on employa-\\nbility than traditional degrees. Rivas et al. (2020), using a recruited experiment where mechanical\\nTurk workers were asked to select among alternative hypothetical worker profiles, demonstrated that\\nMOOC credentials increase the chances of being selected for a job as compared to having no creden-\\ntials at all. Hadavand et al. (2018) compared outcomes of completers to non-completers of a large\\n4'], reference_answer='The study suggests that signaling skills with non-traditional credentials, such as MOOC certificates, benefits LinkedIn users with lower baseline employability by increasing their chances of finding new jobs. Platform policies that encourage sharing these credentials particularly benefit learners in groups with the lowest chance of reporting new jobs. Additionally, clicks on the credential, which redirect to the certificate page on Coursera, are strongly correlated with new job reporting, indicating increased interest from potential employers.', reference_answer_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>)),\n",
       " LabelledRagDataExample(query='Question: How do MOOC credentials impact labor market outcomes, particularly in developing countries and for learners without college degrees, according to the study?', query_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>), reference_contexts=['data science specialization and estimates a salary increase and a higher likelihood of job mobility for\\ncompleters. Zhenghao et al. (2015), using a survey carried out after course completion, found that a\\nsignificant majority of learners report that their MOOC courses helped them achieve career objectives.\\nOur work adds to this discussion by investigating the impact of MOOC credentials on actual labor\\nmarket outcomes, particularly in the context of developing countries and learners without college\\ndegrees.\\nA related research agenda studies employers’ perception of MOOC credentials. Rosendale (2016)\\nsurveyed 202 employers about their perceptions of MOOC credentials, showing a general preference\\nfor traditional degrees. Radford et al. (2014), surveying 103 human resources professionals, found that\\nwhile MOOCs were viewed favorably on a resume, they were perceived as less likely to demonstrate\\nspecific skills than traditional credentials. Kizilcec et al. (2019) revealed that respondents believed\\nthat online degree programs are less legitimate and respected than conventional degrees. Our study\\ncontributes to this literature by providing experimental evidence of the positive impact of MOOC cre-\\ndentials on employer interest and real-world employment outcomes, suggesting a positive perception\\nof these credentials by employers.\\nWe also engage with the broader literature on skill signaling and educational credential signaling,\\nas outlined in works such as Spence (1978), Tyler et al. (2000), and Hussey (2012). Our research adds\\nto this body of work by examining the career outcomes of learners who add MOOC certificates to\\ntheir professional profiles, thereby contributing to a more comprehensive understanding of the role of\\nonline education in the modern labor market.\\nFinally, our study aligns with research on the value of signaling capability through non-traditional\\ncredentials. Pallais (2014) examined the value of signals in the form of educational credentials and\\nwork history on online freelancing platforms, while Kässi and Lehdonvirta (2019) explored the impact\\nof self-certification and client reviews on freelancers’ success. Abebe et al. (2020) evaluated the effects\\nof a job application workshop that provides certificates in various skills, leading to improvements\\nin employment and a significant increase in earnings. Carranza et al. (2020) found that certificates\\nimproved job search outcomes and increased callbacks from firms. Athey and Palikot (2022) reported\\nhigh impacts of a program focused on developing portfolios that helped women signal technical skills\\nin their search for technology jobs. Bassi and Nansamba (2022) showed that soft skills certificates in\\nUganda increased employability and earnings. Piopiunik et al. (2020) demonstrated the significant\\neffect of different skill signals on job interview invitations in Germany. Our contribution to this liter-\\n5'], reference_answer='According to the study, MOOC credentials have a positive impact on labor market outcomes, particularly in developing countries and for learners without college degrees. The study provides experimental evidence suggesting that MOOC credentials enhance employer interest and improve real-world employment outcomes. This indicates a positive perception of these credentials by employers, which can lead to increased job mobility and salary increases for individuals who complete MOOC courses.', reference_answer_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>)),\n",
       " LabelledRagDataExample(query='Answer: The study investigates the impact of MOOC credentials on actual labor market outcomes and suggests that these credentials have a positive effect on employer interest and real-world employment outcomes, particularly in the context of developing countries and for learners without college degrees.', query_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>), reference_contexts=['data science specialization and estimates a salary increase and a higher likelihood of job mobility for\\ncompleters. Zhenghao et al. (2015), using a survey carried out after course completion, found that a\\nsignificant majority of learners report that their MOOC courses helped them achieve career objectives.\\nOur work adds to this discussion by investigating the impact of MOOC credentials on actual labor\\nmarket outcomes, particularly in the context of developing countries and learners without college\\ndegrees.\\nA related research agenda studies employers’ perception of MOOC credentials. Rosendale (2016)\\nsurveyed 202 employers about their perceptions of MOOC credentials, showing a general preference\\nfor traditional degrees. Radford et al. (2014), surveying 103 human resources professionals, found that\\nwhile MOOCs were viewed favorably on a resume, they were perceived as less likely to demonstrate\\nspecific skills than traditional credentials. Kizilcec et al. (2019) revealed that respondents believed\\nthat online degree programs are less legitimate and respected than conventional degrees. Our study\\ncontributes to this literature by providing experimental evidence of the positive impact of MOOC cre-\\ndentials on employer interest and real-world employment outcomes, suggesting a positive perception\\nof these credentials by employers.\\nWe also engage with the broader literature on skill signaling and educational credential signaling,\\nas outlined in works such as Spence (1978), Tyler et al. (2000), and Hussey (2012). Our research adds\\nto this body of work by examining the career outcomes of learners who add MOOC certificates to\\ntheir professional profiles, thereby contributing to a more comprehensive understanding of the role of\\nonline education in the modern labor market.\\nFinally, our study aligns with research on the value of signaling capability through non-traditional\\ncredentials. Pallais (2014) examined the value of signals in the form of educational credentials and\\nwork history on online freelancing platforms, while Kässi and Lehdonvirta (2019) explored the impact\\nof self-certification and client reviews on freelancers’ success. Abebe et al. (2020) evaluated the effects\\nof a job application workshop that provides certificates in various skills, leading to improvements\\nin employment and a significant increase in earnings. Carranza et al. (2020) found that certificates\\nimproved job search outcomes and increased callbacks from firms. Athey and Palikot (2022) reported\\nhigh impacts of a program focused on developing portfolios that helped women signal technical skills\\nin their search for technology jobs. Bassi and Nansamba (2022) showed that soft skills certificates in\\nUganda increased employability and earnings. Piopiunik et al. (2020) demonstrated the significant\\neffect of different skill signals on job interview invitations in Germany. Our contribution to this liter-\\n5'], reference_answer='The study investigates the impact of MOOC credentials on actual labor market outcomes and suggests that these credentials have a positive effect on employer interest and real-world employment outcomes, particularly in the context of developing countries and for learners without college degrees.', reference_answer_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>)),\n",
       " LabelledRagDataExample(query='**Question:** What is the purpose of the Credential Feature introduced in the randomized experiment on Coursera, and how does it aim to impact learners?', query_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>), reference_contexts=['ature is the focus on the value of signals across various levels of employability and skills, particularly\\nin the context of MOOCs.\\n3 Empirical setting and randomized experiment\\nCoursera, one of the largest online platforms hosting MOOCs, is characterized by its extensive course\\nofferings and partnerships with global universities and organizations (Coursera, Inc., 2023). In 2022, it\\nhad over 100 million users, adding more than 21 million new learners during the year (ThinkImpact,\\n2021; Learnopoly, 2022; Coursera, 2022). Most courses can be audited for free. Obtaining a certificate\\ntypically involves a fee, which varies depending on the course and the institution, and ranges from\\n$29 to $99 for individual courses. Specializations and professional certificates, which consist of a series\\nof related courses, usually cost between $39 and $79 per month, with the total expense depending on\\nthe time taken to complete the series.1 The affordability and flexibility of Coursera’s offerings are cen-\\ntral to its appeal, particularly for learners from economically disadvantaged regions or marginalized\\ngroups (Kizilcec et al., 2017; Chirikov et al., 2020).\\nMany courses offered by Coursera allow learners to obtain completion certificates. In addition to\\npaying for them, obtaining certificates typically requires completing coursework and passing assess-\\nments. These certificates are often valued for their focus on practical skills relevant to career advance-\\nment, and observational data studies and recruited experiments suggest that, indeed, credentials ob-\\ntained through such courses can positively impact career progression (Hadavand et al., 2018; Rivas\\net al., 2020; Castaño-Muñoz and Rodrigues, 2021). Many Coursera courses are thus career-oriented,\\nand some of the most popular domains include Information Technology, Computer Science, Data Science,\\nand Business.\\n3.1 Randomized experiment\\nIn the experiment, the treatment group was randomized to receive access to the Credential Feature, a\\nnew feature composed of notifications that encouraged the sharing of credentials on LinkedIn and\\nprovided a simplified process to do so. The first notification was sent on the learner’s first visit to the\\nCoursera app after the credential was granted, with the message: “ Do you want to boost your career?\\nOnly [XYZ]% of learners manage to complete [course name] on Coursera and get a certificate. Let everyone\\nknow you did it! Add the certificate to your LinkedIn profile in just two clicks .”2 If the learner did not\\n1Coursera also offers online degrees with significantly higher costs, but individuals graduating with online degrees are\\nnot part of this study.\\n2This message included the corresponding course name and the percentage of learners completing it.\\n6'], reference_answer=\"The purpose of the Credential Feature introduced in the randomized experiment on Coursera is to encourage learners to share their course completion credentials on LinkedIn. This feature aims to impact learners by providing notifications that promote the sharing of credentials and simplifying the process to do so. The intention is to boost learners' careers by highlighting their achievements, as the notifications emphasize the rarity of completing certain courses and the potential career benefits of showcasing these credentials on a professional platform like LinkedIn.\", reference_answer_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>)),\n",
       " LabelledRagDataExample(query=\"**Answer:** The Credential Feature introduced in the randomized experiment on Coursera is designed to encourage learners to share their course completion credentials on LinkedIn. It aims to impact learners by providing notifications that highlight the achievement of completing a course, which is relatively rare, and offering a simplified process to add the certificate to their LinkedIn profile. This feature is intended to boost learners' career prospects by making their newly acquired skills and achievements more visible to potential employers.\", query_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>), reference_contexts=['ature is the focus on the value of signals across various levels of employability and skills, particularly\\nin the context of MOOCs.\\n3 Empirical setting and randomized experiment\\nCoursera, one of the largest online platforms hosting MOOCs, is characterized by its extensive course\\nofferings and partnerships with global universities and organizations (Coursera, Inc., 2023). In 2022, it\\nhad over 100 million users, adding more than 21 million new learners during the year (ThinkImpact,\\n2021; Learnopoly, 2022; Coursera, 2022). Most courses can be audited for free. Obtaining a certificate\\ntypically involves a fee, which varies depending on the course and the institution, and ranges from\\n$29 to $99 for individual courses. Specializations and professional certificates, which consist of a series\\nof related courses, usually cost between $39 and $79 per month, with the total expense depending on\\nthe time taken to complete the series.1 The affordability and flexibility of Coursera’s offerings are cen-\\ntral to its appeal, particularly for learners from economically disadvantaged regions or marginalized\\ngroups (Kizilcec et al., 2017; Chirikov et al., 2020).\\nMany courses offered by Coursera allow learners to obtain completion certificates. In addition to\\npaying for them, obtaining certificates typically requires completing coursework and passing assess-\\nments. These certificates are often valued for their focus on practical skills relevant to career advance-\\nment, and observational data studies and recruited experiments suggest that, indeed, credentials ob-\\ntained through such courses can positively impact career progression (Hadavand et al., 2018; Rivas\\net al., 2020; Castaño-Muñoz and Rodrigues, 2021). Many Coursera courses are thus career-oriented,\\nand some of the most popular domains include Information Technology, Computer Science, Data Science,\\nand Business.\\n3.1 Randomized experiment\\nIn the experiment, the treatment group was randomized to receive access to the Credential Feature, a\\nnew feature composed of notifications that encouraged the sharing of credentials on LinkedIn and\\nprovided a simplified process to do so. The first notification was sent on the learner’s first visit to the\\nCoursera app after the credential was granted, with the message: “ Do you want to boost your career?\\nOnly [XYZ]% of learners manage to complete [course name] on Coursera and get a certificate. Let everyone\\nknow you did it! Add the certificate to your LinkedIn profile in just two clicks .”2 If the learner did not\\n1Coursera also offers online degrees with significantly higher costs, but individuals graduating with online degrees are\\nnot part of this study.\\n2This message included the corresponding course name and the percentage of learners completing it.\\n6'], reference_answer=\"The Credential Feature introduced in the randomized experiment on Coursera is designed to encourage learners to share their course completion credentials on LinkedIn. It aims to impact learners by providing notifications that highlight the achievement of completing a course, which is relatively rare, and offering a simplified process to add the certificate to their LinkedIn profile. This feature is intended to boost learners' career prospects by making their newly acquired skills and achievements more visible to potential employers.\", reference_answer_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>)),\n",
       " LabelledRagDataExample(query=\"**Question:** What was the purpose of the notifications sent to learners in the experimental group, and how did they differ from the control group's experience?\", query_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>), reference_contexts=['click the “Share now” button in the first notification, they received a second notification during their\\nsubsequent visit to the app, stating: “Looking to boost your career? LinkedIn profiles with credentials receive\\n6x more views! Don’t waste your hard-earned certificate! Add the certificate to your LinkedIn profile in just\\ntwo clicks. PS. This is your last reminder. ” These notifications highlighted a streamlined process to\\nadd certificates to LinkedIn profiles, which required only two clicks, compared to the baseline case,\\nwhere learners had to manually copy a link from their credential page and paste it into their LinkedIn\\nprofile. Figure 1 shows how a notification looks on a web app. The control group did not receive these\\nnotifications or the streamlined credential-sharing process.\\nFigure 1: Screenshot of Coursera web app with a notification\\nThe in-app notification is in the bottom right corner\\nThe experimental sample was restricted to learners from developing countries and learners with-\\nout college degrees who graduated with credentials in the selected primary domains (Information\\nTechnology, Data Science, Computer Science, and Business) between September 2022 and March 2023.\\nAll Coursera learners in these target groups were recruited into the experiment. The experimental\\npopulation consisted of 880,000 learners, with 37% in Business, 25% in Computer Science, 24% in\\nData Science, and 14% in Information Technology. The credentials were issued from 7,355 unique\\ncourses, ranging from shorter formats such as Courses (82%) and Guided Projects (16%) to longer\\nones such as Specializations (1.6%) and Professional Certificates (1%).\\n7'], reference_answer='The purpose of the notifications sent to learners in the experimental group was to encourage them to add their earned credentials to their LinkedIn profiles, highlighting that profiles with credentials receive significantly more views. The notifications emphasized a streamlined process that allowed learners to add certificates to their LinkedIn profiles in just two clicks. This process was more efficient compared to the baseline case, where learners had to manually copy a link from their credential page and paste it into their LinkedIn profile.\\n\\nIn contrast, the control group did not receive these notifications or the streamlined credential-sharing process, meaning they had to follow the more manual and time-consuming method to add their credentials to LinkedIn.', reference_answer_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>)),\n",
       " LabelledRagDataExample(query='**Answer:** The purpose of the notifications sent to learners in the experimental group was to encourage them to add their earned credentials to their LinkedIn profiles by highlighting the benefits, such as receiving 6 times more profile views. These notifications offered a streamlined process that allowed learners to add their certificates to LinkedIn in just two clicks. In contrast, the control group did not receive these notifications or the streamlined credential-sharing process, meaning they would have had to manually copy and paste the credential link into their LinkedIn profiles.', query_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>), reference_contexts=['click the “Share now” button in the first notification, they received a second notification during their\\nsubsequent visit to the app, stating: “Looking to boost your career? LinkedIn profiles with credentials receive\\n6x more views! Don’t waste your hard-earned certificate! Add the certificate to your LinkedIn profile in just\\ntwo clicks. PS. This is your last reminder. ” These notifications highlighted a streamlined process to\\nadd certificates to LinkedIn profiles, which required only two clicks, compared to the baseline case,\\nwhere learners had to manually copy a link from their credential page and paste it into their LinkedIn\\nprofile. Figure 1 shows how a notification looks on a web app. The control group did not receive these\\nnotifications or the streamlined credential-sharing process.\\nFigure 1: Screenshot of Coursera web app with a notification\\nThe in-app notification is in the bottom right corner\\nThe experimental sample was restricted to learners from developing countries and learners with-\\nout college degrees who graduated with credentials in the selected primary domains (Information\\nTechnology, Data Science, Computer Science, and Business) between September 2022 and March 2023.\\nAll Coursera learners in these target groups were recruited into the experiment. The experimental\\npopulation consisted of 880,000 learners, with 37% in Business, 25% in Computer Science, 24% in\\nData Science, and 14% in Information Technology. The credentials were issued from 7,355 unique\\ncourses, ranging from shorter formats such as Courses (82%) and Guided Projects (16%) to longer\\nones such as Specializations (1.6%) and Professional Certificates (1%).\\n7'], reference_answer='The purpose of the notifications sent to learners in the experimental group was to encourage them to add their earned credentials to their LinkedIn profiles by highlighting the benefits, such as receiving 6 times more profile views. These notifications offered a streamlined process that allowed learners to add their certificates to LinkedIn in just two clicks. In contrast, the control group did not receive these notifications or the streamlined credential-sharing process, meaning they would have had to manually copy and paste the credential link into their LinkedIn profiles.', reference_answer_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>)),\n",
       " LabelledRagDataExample(query='**Question:** How was the randomization process structured in the experiment involving Coursera learners, and what factors were considered in stratifying the learners?', query_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>), reference_contexts=['Randomization was carried out in monthly batches from September 2022 to March 2023. Each\\nbatch included learners who received the certificate between the first and last day of the month. The\\nsize of the batches varied from 130,000 to 160,000 learners. At the end of each month, the learners in\\na given batch were randomized to treatment and control. Randomization was stratified based on the\\nlearners’ primary domain, whether they came from a developing country, and whether they had a\\ncollege degree. Each learner was randomized to the treatment or control group with equal probability\\nwithin these strata.\\nLearners who did not launch the Coursera app within 30 days of being assigned to the treatment\\ngroup did not receive any notification. However, we continue to consider these users to be part of the\\ntreatment group. The percentage of learners who launched the app after graduation varied between\\nbatches, with the second batch having the highest percentage (96% of learners) and the fifth batch\\nhaving the lowest (82%). Note that the batch is defined on the basis of graduation date rather than\\non visit dates to the app. Thus, a learner who graduated in September (the first batch) but visited the\\nCoursera app and saw the notification in October is still classified as batch 1.\\n3.2 Data\\nTo analyze the results of the experiment, we combined data from two sources. The first is the Cours-\\nera Internal Data , which includes data that describes user engagement with Coursera apps and user\\nregistration surveys. For each learner, we observe the name and dates of granted certificates and the\\nlevel of engagement (which may come from potential employers) on the certificate pages, including\\nthe number of views (page visits) on the certificate page. Each view is categorized by its origin, in-\\ncluding whether or not the view came from LinkedIn (the referral page was LinkedIn) and whether\\nthe view came from the associated learner. The last metric is inferred by Coursera from several signals\\nand might have both type I and type II errors. Each certificate is associated with a primary domain\\nand skills (e.g., “project management”, “digital marketing”, “web development”). In our dataset, we\\nobserve 462 different skills. For each learner, Coursera assesses skill mastery and assigns a score (Red-\\ndick, 2019). Additionally, we compute a max-mean standardization of the learners’ skill level. We also\\nobserve the country where the learner registered for the course. Following the OECD classification,\\nwe use this information to group countries into developing and developed. Finally, we also observe\\nthe information provided by the learners in their registration survey. Specifically, we have informa-\\ntion about the level of education and gender. The response to the study is voluntary; thus, we do not\\n8'], reference_answer=\"The randomization process in the experiment involving Coursera learners was structured by dividing learners into monthly batches from September 2022 to March 2023. Each batch consisted of learners who received their certificates within that month, with batch sizes ranging from 130,000 to 160,000 learners. At the end of each month, learners in a given batch were randomized into treatment and control groups. The randomization was stratified based on three factors: the learners' primary domain, whether they came from a developing country, and whether they had a college degree. Each learner was assigned to the treatment or control group with equal probability within these strata.\", reference_answer_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>)),\n",
       " LabelledRagDataExample(query=\"**Answer:** The randomization process in the experiment was carried out in monthly batches from September 2022 to March 2023, with each batch consisting of learners who received their certificates within that month. The size of these batches varied between 130,000 to 160,000 learners. At the end of each month, learners in a given batch were randomized into treatment and control groups. The randomization was stratified based on three factors: the learners' primary domain, whether they came from a developing country, and whether they had a college degree. Each learner was assigned to the treatment or control group with equal probability within these strata.\", query_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>), reference_contexts=['Randomization was carried out in monthly batches from September 2022 to March 2023. Each\\nbatch included learners who received the certificate between the first and last day of the month. The\\nsize of the batches varied from 130,000 to 160,000 learners. At the end of each month, the learners in\\na given batch were randomized to treatment and control. Randomization was stratified based on the\\nlearners’ primary domain, whether they came from a developing country, and whether they had a\\ncollege degree. Each learner was randomized to the treatment or control group with equal probability\\nwithin these strata.\\nLearners who did not launch the Coursera app within 30 days of being assigned to the treatment\\ngroup did not receive any notification. However, we continue to consider these users to be part of the\\ntreatment group. The percentage of learners who launched the app after graduation varied between\\nbatches, with the second batch having the highest percentage (96% of learners) and the fifth batch\\nhaving the lowest (82%). Note that the batch is defined on the basis of graduation date rather than\\non visit dates to the app. Thus, a learner who graduated in September (the first batch) but visited the\\nCoursera app and saw the notification in October is still classified as batch 1.\\n3.2 Data\\nTo analyze the results of the experiment, we combined data from two sources. The first is the Cours-\\nera Internal Data , which includes data that describes user engagement with Coursera apps and user\\nregistration surveys. For each learner, we observe the name and dates of granted certificates and the\\nlevel of engagement (which may come from potential employers) on the certificate pages, including\\nthe number of views (page visits) on the certificate page. Each view is categorized by its origin, in-\\ncluding whether or not the view came from LinkedIn (the referral page was LinkedIn) and whether\\nthe view came from the associated learner. The last metric is inferred by Coursera from several signals\\nand might have both type I and type II errors. Each certificate is associated with a primary domain\\nand skills (e.g., “project management”, “digital marketing”, “web development”). In our dataset, we\\nobserve 462 different skills. For each learner, Coursera assesses skill mastery and assigns a score (Red-\\ndick, 2019). Additionally, we compute a max-mean standardization of the learners’ skill level. We also\\nobserve the country where the learner registered for the course. Following the OECD classification,\\nwe use this information to group countries into developing and developed. Finally, we also observe\\nthe information provided by the learners in their registration survey. Specifically, we have informa-\\ntion about the level of education and gender. The response to the study is voluntary; thus, we do not\\n8'], reference_answer=\"The randomization process in the experiment was carried out in monthly batches from September 2022 to March 2023, with each batch consisting of learners who received their certificates within that month. The size of these batches varied between 130,000 to 160,000 learners. At the end of each month, learners in a given batch were randomized into treatment and control groups. The randomization was stratified based on three factors: the learners' primary domain, whether they came from a developing country, and whether they had a college degree. Each learner was assigned to the treatment or control group with equal probability within these strata.\", reference_answer_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>)),\n",
       " LabelledRagDataExample(query='**Question:** Based on the LinkedIn Matched Sample data, how is the primary outcome of interest, \"New Job,\" defined, and what criteria are used to determine if a position qualifies as a \"New Job in Scope\"?', query_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>), reference_contexts=['observe these characteristics for some learners.\\nThe second source of data is the LinkedIn Matched Sample. Upon enrolling in the course, learners\\nwere asked to provide their LinkedIn profile URLs. In September 2023, we collected LinkedIn profiles\\nof approximately 40,000 learners who provided this information. As a result, there was a 12-month\\ngap between randomization and LinkedIn data collection for learners in the first batch and an 8-\\nmonth gap for those in the last batch. The dataset includes additional information on educational\\nbackground, work experience, and LinkedIn activity. Details about the construction of features using\\nLinkedIn data are provided in Appendix A.1.\\nThe primary outcome of interest is whether learners reported new employment on their LinkedIn\\nprofiles—termed New Job. This outcome is observed exclusively within the LinkedIn Matched Sample.\\nWe define New Jobs as positions that had a reported starting date at least one month after random-\\nization.3 This category includes positions with the same employer. Additionally, to better align with\\nthe career aspirations of learners in our sample, we limit our analysis to positions in the technology\\nsector or managerial roles. Relevant positions are identified by job titles containing keywords such as\\nsoftware, data, and manager. Consequently, New Job in Scope is assigned a value of 1 if the job starts at\\nleast one month after the randomization and fits these job title criteria. Moreover, Credential Shared is\\nvalued at 1 if the credential appears on the learner’s LinkedIn profile and zero otherwise.4\\nFinally, for all learners in Coursera Internal Data, we observe the number of visits to the credential\\npage and the referring page. Based on this data, we construct four indicator variables. Specifically,All\\nViews takes the value of 1 when the certificate received any view;All Views by Otherstakes the value of\\n1 when the certificate page has been viewed at least once by someone other than the learner; andViews\\nLinkedIn and Views LinkedIn by Others take the value of 1 for views originating only from LinkedIn by\\nanyone or by someone other than the learner, respectively.\\nSummary statistics are presented in Table 1, and the balance of covariates between experimental\\ngroups is assessed in Appendix B.1. We do not find statistically significant differences in the covariate\\nvalues between the treatment and control groups. Comparing the average covariate values inCoursera\\nInternal Data and the LinkedIn Matched Sample, we find that the learners in the LinkedIn Matched Sample\\nare more likely to have graduated with a certificate in Data Science (the difference is 0.067 p.p. with\\nS.E. <0.001), less likely to participate in a Guided Project (the difference is - 0.074 p.p. with S.E. 0.002)\\n3Additionally, a robustness check restricts our analysis to positions starting four months or more after randomization.\\n4Credentials are identified by their unique ID, provided by Coursera and displayed next to the credential’s name on\\nLinkedIn profiles.\\n9'], reference_answer='The primary outcome of interest, \"New Job,\" is defined based on whether learners reported new employment on their LinkedIn profiles. A \"New Job\" is identified as a position with a reported starting date at least one month after randomization. To qualify as a \"New Job in Scope,\" the position must also align with the career aspirations of learners in the sample, specifically being in the technology sector or managerial roles. Relevant positions are identified by job titles containing keywords such as software, data, and manager.', reference_answer_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>)),\n",
       " LabelledRagDataExample(query='**Answer:** The primary outcome of interest, \"New Job,\" is defined as positions reported on LinkedIn profiles with a starting date at least one month after randomization. To qualify as a \"New Job in Scope,\" the position must also align with the career aspirations of learners by being in the technology sector or a managerial role. Relevant positions are identified by job titles containing keywords such as software, data, and manager.', query_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>), reference_contexts=['observe these characteristics for some learners.\\nThe second source of data is the LinkedIn Matched Sample. Upon enrolling in the course, learners\\nwere asked to provide their LinkedIn profile URLs. In September 2023, we collected LinkedIn profiles\\nof approximately 40,000 learners who provided this information. As a result, there was a 12-month\\ngap between randomization and LinkedIn data collection for learners in the first batch and an 8-\\nmonth gap for those in the last batch. The dataset includes additional information on educational\\nbackground, work experience, and LinkedIn activity. Details about the construction of features using\\nLinkedIn data are provided in Appendix A.1.\\nThe primary outcome of interest is whether learners reported new employment on their LinkedIn\\nprofiles—termed New Job. This outcome is observed exclusively within the LinkedIn Matched Sample.\\nWe define New Jobs as positions that had a reported starting date at least one month after random-\\nization.3 This category includes positions with the same employer. Additionally, to better align with\\nthe career aspirations of learners in our sample, we limit our analysis to positions in the technology\\nsector or managerial roles. Relevant positions are identified by job titles containing keywords such as\\nsoftware, data, and manager. Consequently, New Job in Scope is assigned a value of 1 if the job starts at\\nleast one month after the randomization and fits these job title criteria. Moreover, Credential Shared is\\nvalued at 1 if the credential appears on the learner’s LinkedIn profile and zero otherwise.4\\nFinally, for all learners in Coursera Internal Data, we observe the number of visits to the credential\\npage and the referring page. Based on this data, we construct four indicator variables. Specifically,All\\nViews takes the value of 1 when the certificate received any view;All Views by Otherstakes the value of\\n1 when the certificate page has been viewed at least once by someone other than the learner; andViews\\nLinkedIn and Views LinkedIn by Others take the value of 1 for views originating only from LinkedIn by\\nanyone or by someone other than the learner, respectively.\\nSummary statistics are presented in Table 1, and the balance of covariates between experimental\\ngroups is assessed in Appendix B.1. We do not find statistically significant differences in the covariate\\nvalues between the treatment and control groups. Comparing the average covariate values inCoursera\\nInternal Data and the LinkedIn Matched Sample, we find that the learners in the LinkedIn Matched Sample\\nare more likely to have graduated with a certificate in Data Science (the difference is 0.067 p.p. with\\nS.E. <0.001), less likely to participate in a Guided Project (the difference is - 0.074 p.p. with S.E. 0.002)\\n3Additionally, a robustness check restricts our analysis to positions starting four months or more after randomization.\\n4Credentials are identified by their unique ID, provided by Coursera and displayed next to the credential’s name on\\nLinkedIn profiles.\\n9'], reference_answer='The primary outcome of interest, \"New Job,\" is defined as positions reported on LinkedIn profiles with a starting date at least one month after randomization. To qualify as a \"New Job in Scope,\" the position must also align with the career aspirations of learners by being in the technology sector or a managerial role. Relevant positions are identified by job titles containing keywords such as software, data, and manager.', reference_answer_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>)),\n",
       " LabelledRagDataExample(query=\"Question: Based on the summary statistics in Table 1, what is the difference in the mean percentage of individuals with a Bachelor's degree between the Coursera Internal Data and the LinkedIn Matched Sample?\", query_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>), reference_contexts=['Table 1: Summary statistics pretreatment and outcome variables\\nCoursera Internal Data LinkedIn Matched Sample\\nVariable name Mean S.E. Mean S.E.\\nTreatment 0.499 0.001 0.500 0.003\\nPanel A: Pre-treatment covariates\\nProfessional Experience Years – – 3.040 0.028\\nPast Tech Job – – 0.127 0.002\\nPast Managerial Job – – 0.064 0.001\\nMain Skill Absolute 0.099 0.001 2.074 0.010\\nMain Skill Standardized 0.000 <0.001 0.000 0.001\\nComputer Science 0.252 0.001 0.230 0.002\\nData Science 0.236 0.001 0.300 0.002\\nInformation Technology 0.140 0.001 0.138 0.002\\nGuided Project 0.168 0.001 0.097 0.002\\nProfessional Certificate 0.005 <0.001 0.005 <0.001\\nSpecialization 0.009 <0.001 0.009 0.001\\nDeveloping Country 0.896 0.001 0.850 0.002\\nAssociate Degree 0.029 <0.001 0.062 0.001\\nBachelor Degree 0.127 0.001 0.367 0.003\\nSome College 0.072 0.001 0.130 0.002\\nDoctorate Degree 0.004 <0.001 0.012 0.001\\nHigh School Diploma 0.059 0.001 0.097 0.002\\nLess than High School 0.009 <0.001 0.012 0.001\\nMasters Degree 0.050 0.001 0.146 0.002\\nNo Education Mentioned 0.645 0.002 0.164 0.002\\nProfessional Degree 0.004 <0.001 0.010 0.001\\nMale 0.302 0.002 0.674 0.002\\nGender Not Mentioned 0.533 0.002 0.101 0.002\\nPanel B: Outcome variables\\nNew Job – – 0.177 0.002\\nNew Job in Scope – – 0.133 0.002\\nCredential Shared – – 0.181 0.002\\nAll Views 0.191 0.001 0.429 0.003\\nAll Views by Others 0.143 0.001 0.318 0.002\\nViews LinkedIn 0.165 0.001 0.409 0.003\\nViews LinkedIn by Others 0.124 0.001 0.296 0.002\\nNote: Professional Experience Years is the number of years between the starting date of the first job and August 2023. Past Tech Job\\ntakes the value of 1 when the learner had a job title related to technology before randomization and zero otherwise. Analogously, Past\\nManagerial Job for jobs with managerial titles.\\n10'], reference_answer=\"The mean percentage of individuals with a Bachelor's degree in the Coursera Internal Data is 12.7%, while in the LinkedIn Matched Sample, it is 36.7%. The difference in the mean percentage between the two samples is 36.7% - 12.7% = 24%.\", reference_answer_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>)),\n",
       " LabelledRagDataExample(query=\"Answer: The mean percentage of individuals with a Bachelor's degree is 12.7% in the Coursera Internal Data and 36.7% in the LinkedIn Matched Sample, indicating a difference of 24%.\", query_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>), reference_contexts=['Table 1: Summary statistics pretreatment and outcome variables\\nCoursera Internal Data LinkedIn Matched Sample\\nVariable name Mean S.E. Mean S.E.\\nTreatment 0.499 0.001 0.500 0.003\\nPanel A: Pre-treatment covariates\\nProfessional Experience Years – – 3.040 0.028\\nPast Tech Job – – 0.127 0.002\\nPast Managerial Job – – 0.064 0.001\\nMain Skill Absolute 0.099 0.001 2.074 0.010\\nMain Skill Standardized 0.000 <0.001 0.000 0.001\\nComputer Science 0.252 0.001 0.230 0.002\\nData Science 0.236 0.001 0.300 0.002\\nInformation Technology 0.140 0.001 0.138 0.002\\nGuided Project 0.168 0.001 0.097 0.002\\nProfessional Certificate 0.005 <0.001 0.005 <0.001\\nSpecialization 0.009 <0.001 0.009 0.001\\nDeveloping Country 0.896 0.001 0.850 0.002\\nAssociate Degree 0.029 <0.001 0.062 0.001\\nBachelor Degree 0.127 0.001 0.367 0.003\\nSome College 0.072 0.001 0.130 0.002\\nDoctorate Degree 0.004 <0.001 0.012 0.001\\nHigh School Diploma 0.059 0.001 0.097 0.002\\nLess than High School 0.009 <0.001 0.012 0.001\\nMasters Degree 0.050 0.001 0.146 0.002\\nNo Education Mentioned 0.645 0.002 0.164 0.002\\nProfessional Degree 0.004 <0.001 0.010 0.001\\nMale 0.302 0.002 0.674 0.002\\nGender Not Mentioned 0.533 0.002 0.101 0.002\\nPanel B: Outcome variables\\nNew Job – – 0.177 0.002\\nNew Job in Scope – – 0.133 0.002\\nCredential Shared – – 0.181 0.002\\nAll Views 0.191 0.001 0.429 0.003\\nAll Views by Others 0.143 0.001 0.318 0.002\\nViews LinkedIn 0.165 0.001 0.409 0.003\\nViews LinkedIn by Others 0.124 0.001 0.296 0.002\\nNote: Professional Experience Years is the number of years between the starting date of the first job and August 2023. Past Tech Job\\ntakes the value of 1 when the learner had a job title related to technology before randomization and zero otherwise. Analogously, Past\\nManagerial Job for jobs with managerial titles.\\n10'], reference_answer=\"The mean percentage of individuals with a Bachelor's degree is 12.7% in the Coursera Internal Data and 36.7% in the LinkedIn Matched Sample, indicating a difference of 24%.\", reference_answer_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>)),\n",
       " LabelledRagDataExample(query='**Question:** What is the Local Average Treatment Effect (LATE) of the Credential Shared on job outcomes for Coursera learners who added credentials due to the intervention, and why is this analysis significant?', query_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>), reference_contexts=['and less likely to be from a developing country (the difference is -0.048 p.p. with S.E. 0.002). Recall\\nthat gender and level of education are provided voluntarily through the registration survey, similar to\\nthe LinkedIn URLs. We observe that in the LinkedIn Matched Sample, learners are more likely to report\\ntheir gender or level of education.\\nPanel B of Table 1 presents the summary statistics of the outcome variables. In theLinkedIn Matched\\nSample, 18% of the learners found new jobs during the considered period, and 13% of all the learners\\nfound jobs that we consider in scope, indicating that most of the new jobs reported were related to\\ncertificates. However, most learners did not receive views on their credentials. In theLinkedIn Matched\\nSample, these shares were 43% and 30%, respectively. In the Coursera Internal Data , 19% of learners\\nreceived any views and only 12% of them received views from others originating from LinkedIn.\\nFinally, we find that 18% of learners in the LinkedIn Matched Sample had certificates in their profiles.5\\n4 Treatment effects in the LinkedIn Matched Sample\\nUsing the randomized experiment, we first explore the effect of the Credential Feature on the average\\nrate at which Coursera learners report new jobs, and second, we consider the Local Average Treat-\\nment Effect (LATE) (Angrist and Imbens, 1995) of Credential Shared on job outcomes, which is the\\neffect on learners who added credentials due to the intervention. From a managerial perspective, the\\nevaluation of the Credential Feature yields the overall benefit of the intervention—a combination of en-\\ncouragement to share credentials and a streamlined process—to all Coursera learners. This evaluation\\nwould be relevant for a cost-benefit analysis of the development of the feature (where, in this case, the\\ndevelopment costs of the feature were low). The second analysis is relevant to understanding the\\nimpact of showcasing course completion on LinkedIn on the likelihood of securing new employment.\\nThis analysis focuses on the outcomes of learners who adhered to the treatment, highlighting the po-\\ntential value of adding these credentials to their LinkedIn profiles. Both questions are examined using\\nthe LinkedIn Matched Sample.\\n4.1 Average Impact of a Credential-Sharing Intervention\\nFigure 2 shows the share of subjects per experimental group and batch that reported a new job since\\nthe date of randomization. Month 0 corresponds to the month in which the batch was randomized\\ninto treatment or control groups, which is a different calendar month for each batch. Earlier batches\\n5Note that approximately 10% of learners received views from LinkedIn on their credentials even though they do not\\nhave the credentials in their profile. This can happen, for example, when a learner shares the credential as a post in their\\nfeed instead of adding it to their profile.\\n11'], reference_answer='The Local Average Treatment Effect (LATE) of the Credential Shared on job outcomes refers to the effect on Coursera learners who added credentials to their LinkedIn profiles due to the intervention. This analysis is significant because it helps to understand the impact of showcasing course completion on LinkedIn on the likelihood of securing new employment. By focusing on learners who adhered to the treatment, the analysis highlights the potential value of adding these credentials to their LinkedIn profiles, providing insights into how such interventions can enhance job prospects for learners.', reference_answer_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>)),\n",
       " LabelledRagDataExample(query='**Answer:** The Local Average Treatment Effect (LATE) of the Credential Shared on job outcomes refers to the impact on Coursera learners who added credentials to their LinkedIn profiles as a result of the intervention. This analysis is significant because it highlights the potential value of showcasing course completion on LinkedIn in increasing the likelihood of securing new employment. By focusing on learners who adhered to the treatment, the analysis provides insights into the effectiveness of the Credential Feature in encouraging learners to share their credentials and the subsequent benefits in terms of job outcomes.', query_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>), reference_contexts=['and less likely to be from a developing country (the difference is -0.048 p.p. with S.E. 0.002). Recall\\nthat gender and level of education are provided voluntarily through the registration survey, similar to\\nthe LinkedIn URLs. We observe that in the LinkedIn Matched Sample, learners are more likely to report\\ntheir gender or level of education.\\nPanel B of Table 1 presents the summary statistics of the outcome variables. In theLinkedIn Matched\\nSample, 18% of the learners found new jobs during the considered period, and 13% of all the learners\\nfound jobs that we consider in scope, indicating that most of the new jobs reported were related to\\ncertificates. However, most learners did not receive views on their credentials. In theLinkedIn Matched\\nSample, these shares were 43% and 30%, respectively. In the Coursera Internal Data , 19% of learners\\nreceived any views and only 12% of them received views from others originating from LinkedIn.\\nFinally, we find that 18% of learners in the LinkedIn Matched Sample had certificates in their profiles.5\\n4 Treatment effects in the LinkedIn Matched Sample\\nUsing the randomized experiment, we first explore the effect of the Credential Feature on the average\\nrate at which Coursera learners report new jobs, and second, we consider the Local Average Treat-\\nment Effect (LATE) (Angrist and Imbens, 1995) of Credential Shared on job outcomes, which is the\\neffect on learners who added credentials due to the intervention. From a managerial perspective, the\\nevaluation of the Credential Feature yields the overall benefit of the intervention—a combination of en-\\ncouragement to share credentials and a streamlined process—to all Coursera learners. This evaluation\\nwould be relevant for a cost-benefit analysis of the development of the feature (where, in this case, the\\ndevelopment costs of the feature were low). The second analysis is relevant to understanding the\\nimpact of showcasing course completion on LinkedIn on the likelihood of securing new employment.\\nThis analysis focuses on the outcomes of learners who adhered to the treatment, highlighting the po-\\ntential value of adding these credentials to their LinkedIn profiles. Both questions are examined using\\nthe LinkedIn Matched Sample.\\n4.1 Average Impact of a Credential-Sharing Intervention\\nFigure 2 shows the share of subjects per experimental group and batch that reported a new job since\\nthe date of randomization. Month 0 corresponds to the month in which the batch was randomized\\ninto treatment or control groups, which is a different calendar month for each batch. Earlier batches\\n5Note that approximately 10% of learners received views from LinkedIn on their credentials even though they do not\\nhave the credentials in their profile. This can happen, for example, when a learner shares the credential as a post in their\\nfeed instead of adding it to their profile.\\n11'], reference_answer='The Local Average Treatment Effect (LATE) of the Credential Shared on job outcomes refers to the impact on Coursera learners who added credentials to their LinkedIn profiles as a result of the intervention. This analysis is significant because it highlights the potential value of showcasing course completion on LinkedIn in increasing the likelihood of securing new employment. By focusing on learners who adhered to the treatment, the analysis provides insights into the effectiveness of the Credential Feature in encouraging learners to share their credentials and the subsequent benefits in terms of job outcomes.', reference_answer_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>)),\n",
       " LabelledRagDataExample(query=\"**Question:** Based on the study's findings, what was the observed effect of the Credential Feature on the probability of learners reporting a new job, and how did this effect differ between the treatment and control groups?\", query_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>), reference_contexts=['are followed for longer than the later cohorts, with the first batch being followed for 12 months and\\nthe last one for 8. We notice that each batch followed a similar trend in reporting new jobs, with\\napproximately 10% of learners reporting a new job after six months. In all batches, except for the fifth\\nbatch, more users in the treatment group reported new jobs than users in the control group. In that\\nbatch, there was also a negligible treatment effect on credential sharing (see Appendix C).\\nFigure 2: Share of learners reporting new jobs in treatment and control groups\\nNote: For each batch, the figure presents the share of learners by treatment and control groups who have reported a new job. Solid lines\\ntreatment groups. Dashed lines control groups.\\nIn Table 2, we present the estimates of the average effect of theCredential Feature on the probability\\nof reporting a new job. We use the Cox proportional hazard model in all six models and use censoring\\nas defined by the duration between randomization and data collection for each batch. Models 1, 2, and\\n3 consider new jobs reported with a starting date at least one month after the randomization. Models\\n4, 5, and 6 restrict attention to jobs with a starting date at least 4 months after the randomization.\\nModels 1 and 4 consider New Job outcome, and all other models New Job in Scope. Models 3 and 6 are\\nbased on the subsample of LinkedIn Matched Sample of learners whose previous job was not in scope.\\nAll models are adjusted for learners’ covariates.\\nWe estimate a statistically significant difference in the probability of reporting a new job between\\ntreatment and control in all specifications. Considering New Job outcome we find a 5.8% (S.E. 2.6%)\\nincrease from baseline and 6.8% (S.E. 3.6%) when restricting to employment with a reported starting\\ndate at least 4 months after the treatment. Point estimates are higher when focusing on New Job in\\n12'], reference_answer=\"Based on the study's findings, the Credential Feature had a statistically significant effect on the probability of learners reporting a new job. In all specifications, there was a higher probability of reporting a new job in the treatment group compared to the control group. Specifically, there was a 5.8% increase from baseline in the probability of reporting a new job when considering the New Job outcome, and a 6.8% increase when restricting to employment with a reported starting date at least 4 months after the treatment. This indicates that the Credential Feature positively influenced the likelihood of learners in the treatment group reporting new jobs compared to those in the control group.\", reference_answer_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>)),\n",
       " LabelledRagDataExample(query='**Answer:** The study found a statistically significant difference in the probability of reporting a new job between the treatment and control groups. Specifically, there was a 5.8% increase from baseline in the probability of reporting a new job for the treatment group compared to the control group. This increase was even higher, at 6.8%, when considering employment with a reported starting date at least 4 months after the treatment.', query_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>), reference_contexts=['are followed for longer than the later cohorts, with the first batch being followed for 12 months and\\nthe last one for 8. We notice that each batch followed a similar trend in reporting new jobs, with\\napproximately 10% of learners reporting a new job after six months. In all batches, except for the fifth\\nbatch, more users in the treatment group reported new jobs than users in the control group. In that\\nbatch, there was also a negligible treatment effect on credential sharing (see Appendix C).\\nFigure 2: Share of learners reporting new jobs in treatment and control groups\\nNote: For each batch, the figure presents the share of learners by treatment and control groups who have reported a new job. Solid lines\\ntreatment groups. Dashed lines control groups.\\nIn Table 2, we present the estimates of the average effect of theCredential Feature on the probability\\nof reporting a new job. We use the Cox proportional hazard model in all six models and use censoring\\nas defined by the duration between randomization and data collection for each batch. Models 1, 2, and\\n3 consider new jobs reported with a starting date at least one month after the randomization. Models\\n4, 5, and 6 restrict attention to jobs with a starting date at least 4 months after the randomization.\\nModels 1 and 4 consider New Job outcome, and all other models New Job in Scope. Models 3 and 6 are\\nbased on the subsample of LinkedIn Matched Sample of learners whose previous job was not in scope.\\nAll models are adjusted for learners’ covariates.\\nWe estimate a statistically significant difference in the probability of reporting a new job between\\ntreatment and control in all specifications. Considering New Job outcome we find a 5.8% (S.E. 2.6%)\\nincrease from baseline and 6.8% (S.E. 3.6%) when restricting to employment with a reported starting\\ndate at least 4 months after the treatment. Point estimates are higher when focusing on New Job in\\n12'], reference_answer='The study found a statistically significant difference in the probability of reporting a new job between the treatment and control groups. Specifically, there was a 5.8% increase from baseline in the probability of reporting a new job for the treatment group compared to the control group. This increase was even higher, at 6.8%, when considering employment with a reported starting date at least 4 months after the treatment.', reference_answer_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>)),\n",
       " LabelledRagDataExample(query='**Question:** Based on the data presented in Table 2, how does the Credential Feature impact the probability of learners reporting a new job in scope when excluding the first four months after randomization, and what are the associated standard errors?', query_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>), reference_contexts=['Table 2: Effect of Credential Feature on New Job and New Job in Scope\\nCox Prop. Hazards Overall Cox Prop. Hazards Exclude 4 months\\nNew Job New Job in Scope New Job in Scope & Old Not in Scope New Job New Job in Scope New Job in Scope & Old Not in Scope\\nATE 1.006 1.187 0.906 0.612 0.668 0.633(0.452) (0.397) (0.363) (0.329) (0.274) (0.353)ATE % baseline 5.815 9.320 10.451 6.785 11.341 7.301(2.611) (3.118) (4.184) (3.646) (4.659) (4.072)\\nBaseline 17.303 12.736 8.666 9.020 5.889 8.666(0.067) (0.058) (0.238) (0.048) (0.039) (0.238)No. of obs. 36,946 36,946 30,607 36,946 36,946 30,607Learners covariates Yes Yes Yes Yes Yes Yes\\nNote: Estimates of the impact of Credential Feature on New Job and New Job in Scope using Cox proportional hazards models. The first\\nthree columns based on new employment reported with a start date at least one month after randomization. The baseline is the share of\\nlearners in the control group that reported new jobs or jobs in scope. ATE is reported as a percentage point increase. Standard errors in\\nparantheses.\\nScope, we estimate a 9.3% (S.E. 3.1%) and 11.3% (S.E. 4.7%) respectively. When we additionally restrict\\nthe sample to learners whose employment prior to the experiment was not in scope, we find that the\\nCredential Feature increases the probably of reporting New Job in Scope with a starting date at least 1\\nmonth after the randomization by 10.5% (S.E. 4.2%) and 7.3% (S.E. 4.1%) with jobs starting 4 months\\nafter the randomization.\\nGroups based on certificate sharing and new employment We classify learners into four groups\\nbased on New job and Credential Shared: Group 1 consists of learners who neither added the certificate\\nnor reported a new job, Group 2 includes those who did not add the certificate but reported a new\\njob, Group 3 comprises learners who added the certificate but did not report a new job, and Group 4\\nconsists of learners who both added the certificate and reported a new job. In the control group, the\\ndistribution of learners is as follows: 63% in Group 1, 7% in Group 2, 19% in Group 3, and 10% in\\nGroup 4.\\nTable 3 presents estimates of multinomial logistic models with the group indicators as dependent\\nvariables. Model 1 only has the Credential Feature indicator on the left-hand side; it takes the value\\nof 1 for learners in the treatment group and 0 for control group learners. We find that among those\\ntreated, there are more learners in all groups exceptGroup 1 (reference group, not displayed); however,\\nthe difference is particularly pronounced forGroup 4. Model 2 also accounts for the low employability\\nindicator and the interaction between treatment and employability. We predict baseline employabil-\\nity following the methodology described in Athey et al. (2023). We initially train a Gradient Boosted\\nMachine (GBM) model using data from the control group. This model predicts the likelihood of a\\nlearner reporting a new job based on pre-treatment characteristics. We then apply this model to par-\\n13'], reference_answer='Based on the data presented in Table 2, when excluding the first four months after randomization, the Credential Feature increases the probability of learners reporting a new job in scope by 11.3%. The associated standard error for this estimate is 4.7%.', reference_answer_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>)),\n",
       " LabelledRagDataExample(query='**Answer:** When excluding the first four months after randomization, the Credential Feature increases the probability of learners reporting a new job in scope by 11.3%, with a standard error of 4.7%.', query_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>), reference_contexts=['Table 2: Effect of Credential Feature on New Job and New Job in Scope\\nCox Prop. Hazards Overall Cox Prop. Hazards Exclude 4 months\\nNew Job New Job in Scope New Job in Scope & Old Not in Scope New Job New Job in Scope New Job in Scope & Old Not in Scope\\nATE 1.006 1.187 0.906 0.612 0.668 0.633(0.452) (0.397) (0.363) (0.329) (0.274) (0.353)ATE % baseline 5.815 9.320 10.451 6.785 11.341 7.301(2.611) (3.118) (4.184) (3.646) (4.659) (4.072)\\nBaseline 17.303 12.736 8.666 9.020 5.889 8.666(0.067) (0.058) (0.238) (0.048) (0.039) (0.238)No. of obs. 36,946 36,946 30,607 36,946 36,946 30,607Learners covariates Yes Yes Yes Yes Yes Yes\\nNote: Estimates of the impact of Credential Feature on New Job and New Job in Scope using Cox proportional hazards models. The first\\nthree columns based on new employment reported with a start date at least one month after randomization. The baseline is the share of\\nlearners in the control group that reported new jobs or jobs in scope. ATE is reported as a percentage point increase. Standard errors in\\nparantheses.\\nScope, we estimate a 9.3% (S.E. 3.1%) and 11.3% (S.E. 4.7%) respectively. When we additionally restrict\\nthe sample to learners whose employment prior to the experiment was not in scope, we find that the\\nCredential Feature increases the probably of reporting New Job in Scope with a starting date at least 1\\nmonth after the randomization by 10.5% (S.E. 4.2%) and 7.3% (S.E. 4.1%) with jobs starting 4 months\\nafter the randomization.\\nGroups based on certificate sharing and new employment We classify learners into four groups\\nbased on New job and Credential Shared: Group 1 consists of learners who neither added the certificate\\nnor reported a new job, Group 2 includes those who did not add the certificate but reported a new\\njob, Group 3 comprises learners who added the certificate but did not report a new job, and Group 4\\nconsists of learners who both added the certificate and reported a new job. In the control group, the\\ndistribution of learners is as follows: 63% in Group 1, 7% in Group 2, 19% in Group 3, and 10% in\\nGroup 4.\\nTable 3 presents estimates of multinomial logistic models with the group indicators as dependent\\nvariables. Model 1 only has the Credential Feature indicator on the left-hand side; it takes the value\\nof 1 for learners in the treatment group and 0 for control group learners. We find that among those\\ntreated, there are more learners in all groups exceptGroup 1 (reference group, not displayed); however,\\nthe difference is particularly pronounced forGroup 4. Model 2 also accounts for the low employability\\nindicator and the interaction between treatment and employability. We predict baseline employabil-\\nity following the methodology described in Athey et al. (2023). We initially train a Gradient Boosted\\nMachine (GBM) model using data from the control group. This model predicts the likelihood of a\\nlearner reporting a new job based on pre-treatment characteristics. We then apply this model to par-\\n13'], reference_answer='The statement is correct. When excluding the first four months after randomization, the Credential Feature increases the probability of learners reporting a new job in scope by 11.3%, with a standard error of 4.7%.', reference_answer_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>)),\n",
       " LabelledRagDataExample(query='Question: Based on the data presented in Table 3, how does the interaction between Credential Feature and low employability affect the likelihood of reporting a new job?', query_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>), reference_contexts=['Table 3: Impact of Credential Feature on combined Credential Shareed and New Job indicators\\nModel 1 Model 2\\nNew Job No new job New Job New Job No new job New Job\\nNo certificate Certificate Certificate No certificate Certificate Certificate\\nCredential Feature 0.034 0.050 0.116 −0.071 −0.002 −0.035\\n(0.041) (0.027) (0.034) (0.053) (0.038) (0.044)\\nLow employability −1.113 −0.513 −1.245\\n(0.063) (0.039) (0.054)\\nCredential Feature * Low employability 0.266 0.098 0.415\\n(0.087) (0.054) (0.073)\\nBaseline 0.0696 0.193 0.103 0.0696 0.193 0.103\\n(0.0019) (0.0029) (0.0022) (0.0019) (0.0029) (0.0022)\\nObservations 36,946 36,946 36,946 36,946 36,946 36,946\\nNote: Multinomial logistic regression with outcome variable equal to the group indicator. Model 1 includes only the Credential Feature\\nindicator as a covariate, and Model 2 includes the Credential Feature indicator and the interaction term with a low employability\\nindicator. No learners covariates. Low employability is the lowest tertile, as predicted by the GBM model trained on the control group.\\nStandard errors in parentheses.\\nticipants in both the treatment and control groups and classify them into tertiles according to their\\npredicted employability. We find that controlling for the interaction term, the treatment is statistically\\ninsignificant and the interaction term is statistically different from zero for Group 2 and Group 4. This\\nresult suggests that the effect of Credential Feature is present amongst the learners with low baseline\\nemployability (we analyze this further in Section 4.3).\\n4.2 The impact of Credential Sharedon the probability of reporting a new job\\nThe results presented in Tables 2 correspond to the average increase in the probability of reporting a\\nnew job among all treated learners. Now, we estimate the Local Average Treatment Effect ofCredential\\nShared treatment. In the first stage, we consider the impact of theCredential Featureon Credential Shared,\\nand in the second stage, the impact of Credential Shared on New Job and New Job in Scope . Results are\\npresented in Table 4.\\nColumns 1 and 2 of Table 4 show estimates from the first-stage regression. We find that treatment\\nincreases the probability of sharing credentials by 2.8 p.p. (S.E. 0.4 p.p.), which corresponds to a\\n17% increase from baseline. The remaining columns present estimates from the instrumental variable\\nregression with New Job and New Job in Scope as outcomes. In Columns 6, 7, and 8, we restrict attention\\nto jobs reported with a starting date at least four months after treatment. We estimate positive and\\nstatistically significant effects. Specifically, we estimate the local average treatment effect of 0.24 (S.E.\\n0.13) for any new job starting at least one month after treatment and 0.36 (S.E. 0.12) when restricting\\n14'], reference_answer='Based on the data presented in Table 3, the interaction between Credential Feature and low employability positively affects the likelihood of reporting a new job. Specifically, the interaction term \"Credential Feature * Low employability\" has a positive coefficient of 0.266 in Model 1 and 0.415 in Model 2, indicating that the presence of the Credential Feature increases the likelihood of reporting a new job for individuals with low employability. This suggests that the effect of the Credential Feature is more pronounced among learners with low baseline employability.', reference_answer_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>)),\n",
       " LabelledRagDataExample(query='Answer: The interaction between Credential Feature and low employability positively affects the likelihood of reporting a new job, as indicated by the statistically significant coefficients of 0.266, 0.098, and 0.415 in Model 2. This suggests that the Credential Feature has a more pronounced effect on learners with low baseline employability, increasing their chances of reporting a new job compared to those without the interaction term.', query_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>), reference_contexts=['Table 3: Impact of Credential Feature on combined Credential Shareed and New Job indicators\\nModel 1 Model 2\\nNew Job No new job New Job New Job No new job New Job\\nNo certificate Certificate Certificate No certificate Certificate Certificate\\nCredential Feature 0.034 0.050 0.116 −0.071 −0.002 −0.035\\n(0.041) (0.027) (0.034) (0.053) (0.038) (0.044)\\nLow employability −1.113 −0.513 −1.245\\n(0.063) (0.039) (0.054)\\nCredential Feature * Low employability 0.266 0.098 0.415\\n(0.087) (0.054) (0.073)\\nBaseline 0.0696 0.193 0.103 0.0696 0.193 0.103\\n(0.0019) (0.0029) (0.0022) (0.0019) (0.0029) (0.0022)\\nObservations 36,946 36,946 36,946 36,946 36,946 36,946\\nNote: Multinomial logistic regression with outcome variable equal to the group indicator. Model 1 includes only the Credential Feature\\nindicator as a covariate, and Model 2 includes the Credential Feature indicator and the interaction term with a low employability\\nindicator. No learners covariates. Low employability is the lowest tertile, as predicted by the GBM model trained on the control group.\\nStandard errors in parentheses.\\nticipants in both the treatment and control groups and classify them into tertiles according to their\\npredicted employability. We find that controlling for the interaction term, the treatment is statistically\\ninsignificant and the interaction term is statistically different from zero for Group 2 and Group 4. This\\nresult suggests that the effect of Credential Feature is present amongst the learners with low baseline\\nemployability (we analyze this further in Section 4.3).\\n4.2 The impact of Credential Sharedon the probability of reporting a new job\\nThe results presented in Tables 2 correspond to the average increase in the probability of reporting a\\nnew job among all treated learners. Now, we estimate the Local Average Treatment Effect ofCredential\\nShared treatment. In the first stage, we consider the impact of theCredential Featureon Credential Shared,\\nand in the second stage, the impact of Credential Shared on New Job and New Job in Scope . Results are\\npresented in Table 4.\\nColumns 1 and 2 of Table 4 show estimates from the first-stage regression. We find that treatment\\nincreases the probability of sharing credentials by 2.8 p.p. (S.E. 0.4 p.p.), which corresponds to a\\n17% increase from baseline. The remaining columns present estimates from the instrumental variable\\nregression with New Job and New Job in Scope as outcomes. In Columns 6, 7, and 8, we restrict attention\\nto jobs reported with a starting date at least four months after treatment. We estimate positive and\\nstatistically significant effects. Specifically, we estimate the local average treatment effect of 0.24 (S.E.\\n0.13) for any new job starting at least one month after treatment and 0.36 (S.E. 0.12) when restricting\\n14'], reference_answer='The interaction between Credential Feature and low employability positively affects the likelihood of reporting a new job, as indicated by the statistically significant coefficients of 0.266, 0.098, and 0.415 in Model 2. This suggests that the Credential Feature has a more pronounced effect on learners with low baseline employability, increasing their chances of reporting a new job compared to those without the interaction term.', reference_answer_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>)),\n",
       " LabelledRagDataExample(query='Question: Based on Table 5, what is the impact of the Credential Feature on employment for individuals in the lower tertile of predicted employability, and how does it compare to the impact on individuals in the upper and middle tertiles?', query_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>), reference_contexts=['Table 4: Local Average Treatment Effects of Credential Sharing: First and Second Stage\\nFirst Stage Second Stage Overall Second Stage Exclude 4 monthsCred. Shared Cred. Shared & Past Not In Scope New Job New Job in Scope New Job in Scope & Past Not in Scope New Job New Job in Scope New Job in Scope & Past Not in Scope\\nCred. Feature 0.028 0.023(0.004) (0.004)Cred. Shared 0.242 0.360 0.287 0.188 0.217 0.166(0.130) (0.117) (0.132) (0.105) (0.090) (0.101)\\nNo. of obs. 36,946 30,607 36,946 36,946 30,607 36,946 36,946 30,607Learners covariates Yes Yes Yes Yes Yes Yes Yes Yes\\nNote: The first two Columns show the results from the first-stage regression. The estimates in Column 1 are based on the entire LinkedIn\\nMatched Sample, in Column 2 we restrict the sample to learners whose past jobs were not in scope. Columns 3 to 8 present results of\\nthe second stage regressions. Columns 3 to 5 consider all jobs. The last three columns restrict attention to jobs reported with a starting\\ndate at least 4 months after randomization. Columns 3 and 6 New Job outcome; Columns 4, 5, 7, 8 New Job in Scope. Columns 5 and 8\\nrestrict to subsample of learners with past jobs out of scope. Standard errors in parantheses.\\nattention to jobs with a starting date at least four months after the treatment.\\n4.3 Effect of Credential Featureand Credential Sharedon Employment Across Levels of\\nEmployability.\\nIn this section, we examine the impact of theCredential Feature and Credential Shared on the probability\\nthat workers with varying levels of baseline employability report a new job. Our analysis aims to de-\\ntermine whether our intervention and credential sharing more broadly increase or reduce disparities\\nin outcomes.\\nTable 5: Effect of Credential Intervention and Credential Sharing on Employment by Tertile\\nof Predicted Employability\\nImpact of Credential Feature: Proportional Hazard Model Impact of credential sharing: Instrumental Variable Model\\nHigh Employ. Medium Employ. Low Employ. High Employ. Medium Employ. Low Employ.\\nCredential Feature/Shared Credential (pp) 0.382 0.671 1.265 0.074 0.193 0.622(1.141) (0.640) (0.529) (0.207) (0.190) (0.296)Credential Feature (%) 0.012 0.054 0.109(0.037) (0.053) (0.048)\\nBaseline in employability group 0.316 0.120 0.110 0.316 0.120 0.110(0.005) (0.003) (0.002) (0.005) (0.003) (0.002)Observations 9,432 11,817 15,697 9,432 11,817 15,697\\nNote: Estimates of the heterogeneous treatment effects across tertiles of predicted employability from the GBM model. The first three\\ncolumns show the estimate from the proportional hazard model of the average treatment effect of the Credential Feature. Standard errors\\nare in parentheses.\\nThe results of this analysis are presented in Table 5. The baseline probability of reporting employ-\\nment is 32% for the upper tertile, 12% for the middle tertile, and 11% for the lower tertile. The first\\nthree columns of the table show the estimates from the Cox proportional hazard model of the impact\\nof Credential Feature on New Job. For the upper and middle tertiles, the effects are statistically insignifi-\\ncant, with estimates of 0.382 p.p. (S.E. 1.141) and 0.671 p.p. (S.E. 0.640), respectively. However, for the\\nbottom tertile, we find a statistically significant effect of 1.265 p.p. (S.E. 0.529). When comparing the\\n15'], reference_answer='Based on Table 5, the impact of the Credential Feature on employment for individuals in the lower tertile of predicted employability is a statistically significant increase of 1.265 percentage points (p.p.) with a standard error of 0.529. In comparison, the impact on individuals in the upper and middle tertiles is statistically insignificant, with estimates of 0.382 p.p. (S.E. 1.141) for the upper tertile and 0.671 p.p. (S.E. 0.640) for the middle tertile. This indicates that the Credential Feature has a more pronounced and statistically significant positive effect on employment for individuals in the lower tertile of predicted employability compared to those in the upper and middle tertiles.', reference_answer_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>)),\n",
       " LabelledRagDataExample(query='Answer: The impact of the Credential Feature on employment for individuals in the lower tertile of predicted employability is a statistically significant increase of 1.265 percentage points (S.E. 0.529). In contrast, the effects for individuals in the upper and middle tertiles are statistically insignificant, with estimates of 0.382 percentage points (S.E. 1.141) and 0.671 percentage points (S.E. 0.640), respectively.', query_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>), reference_contexts=['Table 4: Local Average Treatment Effects of Credential Sharing: First and Second Stage\\nFirst Stage Second Stage Overall Second Stage Exclude 4 monthsCred. Shared Cred. Shared & Past Not In Scope New Job New Job in Scope New Job in Scope & Past Not in Scope New Job New Job in Scope New Job in Scope & Past Not in Scope\\nCred. Feature 0.028 0.023(0.004) (0.004)Cred. Shared 0.242 0.360 0.287 0.188 0.217 0.166(0.130) (0.117) (0.132) (0.105) (0.090) (0.101)\\nNo. of obs. 36,946 30,607 36,946 36,946 30,607 36,946 36,946 30,607Learners covariates Yes Yes Yes Yes Yes Yes Yes Yes\\nNote: The first two Columns show the results from the first-stage regression. The estimates in Column 1 are based on the entire LinkedIn\\nMatched Sample, in Column 2 we restrict the sample to learners whose past jobs were not in scope. Columns 3 to 8 present results of\\nthe second stage regressions. Columns 3 to 5 consider all jobs. The last three columns restrict attention to jobs reported with a starting\\ndate at least 4 months after randomization. Columns 3 and 6 New Job outcome; Columns 4, 5, 7, 8 New Job in Scope. Columns 5 and 8\\nrestrict to subsample of learners with past jobs out of scope. Standard errors in parantheses.\\nattention to jobs with a starting date at least four months after the treatment.\\n4.3 Effect of Credential Featureand Credential Sharedon Employment Across Levels of\\nEmployability.\\nIn this section, we examine the impact of theCredential Feature and Credential Shared on the probability\\nthat workers with varying levels of baseline employability report a new job. Our analysis aims to de-\\ntermine whether our intervention and credential sharing more broadly increase or reduce disparities\\nin outcomes.\\nTable 5: Effect of Credential Intervention and Credential Sharing on Employment by Tertile\\nof Predicted Employability\\nImpact of Credential Feature: Proportional Hazard Model Impact of credential sharing: Instrumental Variable Model\\nHigh Employ. Medium Employ. Low Employ. High Employ. Medium Employ. Low Employ.\\nCredential Feature/Shared Credential (pp) 0.382 0.671 1.265 0.074 0.193 0.622(1.141) (0.640) (0.529) (0.207) (0.190) (0.296)Credential Feature (%) 0.012 0.054 0.109(0.037) (0.053) (0.048)\\nBaseline in employability group 0.316 0.120 0.110 0.316 0.120 0.110(0.005) (0.003) (0.002) (0.005) (0.003) (0.002)Observations 9,432 11,817 15,697 9,432 11,817 15,697\\nNote: Estimates of the heterogeneous treatment effects across tertiles of predicted employability from the GBM model. The first three\\ncolumns show the estimate from the proportional hazard model of the average treatment effect of the Credential Feature. Standard errors\\nare in parentheses.\\nThe results of this analysis are presented in Table 5. The baseline probability of reporting employ-\\nment is 32% for the upper tertile, 12% for the middle tertile, and 11% for the lower tertile. The first\\nthree columns of the table show the estimates from the Cox proportional hazard model of the impact\\nof Credential Feature on New Job. For the upper and middle tertiles, the effects are statistically insignifi-\\ncant, with estimates of 0.382 p.p. (S.E. 1.141) and 0.671 p.p. (S.E. 0.640), respectively. However, for the\\nbottom tertile, we find a statistically significant effect of 1.265 p.p. (S.E. 0.529). When comparing the\\n15'], reference_answer='The impact of the Credential Feature on employment for individuals in the lower tertile of predicted employability is a statistically significant increase of 1.265 percentage points (S.E. 0.529). In contrast, the effects for individuals in the upper and middle tertiles are statistically insignificant, with estimates of 0.382 percentage points (S.E. 1.141) and 0.671 percentage points (S.E. 0.640), respectively.', reference_answer_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>)),\n",
       " LabelledRagDataExample(query='**Question:** Based on the findings presented, how does the Credential Feature impact learners with different baseline employability levels, and what implications does this have for prioritizing access to the feature?', query_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>), reference_contexts=['effects between the bottom and top tertiles, the difference is 0.1 p.p. (S.E. 0.06).\\nColumns 4 through 6 of Table 5 present the heterogeneity in LATE estimates across tertiles of\\nbaseline employability. The estimate is statistically significant only in the lower tertile. Therefore,\\nthe impact of both the Credential Feature and Credential Shared observed in the entire experimental\\npopulation appears to be driven by improved outcomes among learners with lower baseline chances\\nof finding a new job, thus reducing the disparity in outcomes across learners.6\\nFirst, these findings suggest that prioritizing access to the feature for learners with low baseline\\nemployability may be advantageous when the feature cannot be rolled out to all learners. Second, we\\nfind that credential sharing, for example, due to encouragement with Credential Feature, can particu-\\nlarly benefit learners with low baseline outcomes.\\n4.4 Change in the pattern of LinkedIn engagement\\nThe Credential Feature emphasized the importance of having up-to-date LinkedIn profiles. Thus, it is\\nnot implausible that the feature drove treated learners to complete their LinkedIn profiles in addition\\nto sharing their credentials. We consider two mechanisms that, if true, would upwardly bias our\\nresults.\\nFirst, treated learners who found a job between graduating from the course and receiving treat-\\nment but have not yet added the new job to their LinkedIn profile might update their profiles due to\\nthe nudge. Thus, the jobs added in the first month or two after treatment reflect the difference in the\\nprobability of having an up-to-date profile rather than getting a new job. In Columns 2 and 3 of Table\\n2, we consider the impact of treatment on the probability of reporting a new job with a start date of\\nat least four months after the randomization’s date (we find qualitatively the same results for 3 and\\n5 months). Taking into account only such jobs, we estimate the treatment effect of 7.1% (SE 3.1%).\\nThere were no differences in reminders or other Coursera services between the treatment and control\\ngroups after the initial treatment. Thus, it is unlikely that at the time of treatment, many learners\\nwould add jobs with a start date four months later. Thus, while we cannot rule out that some learn-\\ners updated their profiles because of the treatment, the difference in the probability of reporting jobs\\nstarting several months after the treatment is suggestive of an impact from the treatment.\\nSecond, treated learners could also become more active on LinkedIn and have more complete\\nprofiles. If that were the case, the treatment effect could combine the effect of signaling skills with the\\n6We analyze the impact of Credential Shared on finer employability groups (deciles) in Appendix E. We show that the\\ntreatment effect is particularly pronounced in the bottom two deciles.\\n16'], reference_answer=\"The findings indicate that the Credential Feature has a significant impact on learners with lower baseline employability levels. Specifically, the positive outcomes observed in the entire experimental population are primarily driven by improvements among learners who initially have lower chances of finding a new job. This suggests that the feature helps reduce disparities in employment outcomes across different learners.\\n\\nThe implications for prioritizing access to the Credential Feature are twofold. First, it may be advantageous to prioritize access to this feature for learners with low baseline employability when it cannot be rolled out to all learners. Second, credential sharing, encouraged by the Credential Feature, can particularly benefit those with lower baseline outcomes, further supporting the idea of targeted access to maximize the feature's impact.\", reference_answer_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>)),\n",
       " LabelledRagDataExample(query='**Answer:** The Credential Feature has a statistically significant impact primarily on learners in the lower tertile of baseline employability, suggesting that it improves outcomes for those with lower initial chances of finding a new job. This indicates that prioritizing access to the feature for learners with low baseline employability may be advantageous, as it helps reduce disparities in employment outcomes across different learner groups. Additionally, credential sharing, encouraged by the Credential Feature, particularly benefits learners with low baseline outcomes.', query_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>), reference_contexts=['effects between the bottom and top tertiles, the difference is 0.1 p.p. (S.E. 0.06).\\nColumns 4 through 6 of Table 5 present the heterogeneity in LATE estimates across tertiles of\\nbaseline employability. The estimate is statistically significant only in the lower tertile. Therefore,\\nthe impact of both the Credential Feature and Credential Shared observed in the entire experimental\\npopulation appears to be driven by improved outcomes among learners with lower baseline chances\\nof finding a new job, thus reducing the disparity in outcomes across learners.6\\nFirst, these findings suggest that prioritizing access to the feature for learners with low baseline\\nemployability may be advantageous when the feature cannot be rolled out to all learners. Second, we\\nfind that credential sharing, for example, due to encouragement with Credential Feature, can particu-\\nlarly benefit learners with low baseline outcomes.\\n4.4 Change in the pattern of LinkedIn engagement\\nThe Credential Feature emphasized the importance of having up-to-date LinkedIn profiles. Thus, it is\\nnot implausible that the feature drove treated learners to complete their LinkedIn profiles in addition\\nto sharing their credentials. We consider two mechanisms that, if true, would upwardly bias our\\nresults.\\nFirst, treated learners who found a job between graduating from the course and receiving treat-\\nment but have not yet added the new job to their LinkedIn profile might update their profiles due to\\nthe nudge. Thus, the jobs added in the first month or two after treatment reflect the difference in the\\nprobability of having an up-to-date profile rather than getting a new job. In Columns 2 and 3 of Table\\n2, we consider the impact of treatment on the probability of reporting a new job with a start date of\\nat least four months after the randomization’s date (we find qualitatively the same results for 3 and\\n5 months). Taking into account only such jobs, we estimate the treatment effect of 7.1% (SE 3.1%).\\nThere were no differences in reminders or other Coursera services between the treatment and control\\ngroups after the initial treatment. Thus, it is unlikely that at the time of treatment, many learners\\nwould add jobs with a start date four months later. Thus, while we cannot rule out that some learn-\\ners updated their profiles because of the treatment, the difference in the probability of reporting jobs\\nstarting several months after the treatment is suggestive of an impact from the treatment.\\nSecond, treated learners could also become more active on LinkedIn and have more complete\\nprofiles. If that were the case, the treatment effect could combine the effect of signaling skills with the\\n6We analyze the impact of Credential Shared on finer employability groups (deciles) in Appendix E. We show that the\\ntreatment effect is particularly pronounced in the bottom two deciles.\\n16'], reference_answer='The Credential Feature has a statistically significant impact primarily on learners in the lower tertile of baseline employability, suggesting that it improves outcomes for those with lower initial chances of finding a new job. This indicates that prioritizing access to the feature for learners with low baseline employability may be advantageous, as it helps reduce disparities in employment outcomes across different learner groups. Additionally, credential sharing, encouraged by the Credential Feature, particularly benefits learners with low baseline outcomes.', reference_answer_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>)),\n",
       " LabelledRagDataExample(query='**Question:** What is the estimated impact of the Credential Feature on the probability of receiving views on LinkedIn, and how does this impact vary when considering views by others versus all views?', query_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>), reference_contexts=['impact of a more complete LinkedIn profile. To test for this mechanism, we compute the number of\\ncharacters in the learner’s LinkedIn profile, excluding fields related to credentials and new jobs. We\\nfind that, on average, learners in the treated group have 1362 characters, and learners in the control\\ngroup have 1356. The effect of treatment on this outcome is, therefore, 6 characters (S.E. 6). Thus, we\\ndo not find that the profiles of treated learners are more complete.\\n5 Impact of the Credential Featureon Certificate Views\\nIn this section, we consider the impact of the Credential Feature on the probability that learners’ cer-\\ntificates were viewed. In this analysis, we consider the entire experimental group, which includes\\nlearners in the LinkedIn Matched Sample, all of whom have LinkedIn accounts, and other learners, in-\\ncluding those who might not have LinkedIn accounts. In Appendix D, we show that there is a high\\ncorrelation between certificate views and the probability of reporting a new job; thus, we treat certifi-\\ncate views as a proxy for employment outcome.\\nTable 6 shows the estimates of the average effect ofCredential Feature on the probability of getting a\\nclick on LinkedIn from the OLS estimator. Models 3 and 4 restrict attention to views where the referral\\npage was LinkedIn. Models 2 and 4 restrict attention to views by someone other than the learner. All\\nestimates are adjusted for learners’ characteristics.\\nTable 6: Impact of Credential Feature on the probability of receiving views\\nOLS\\nAll views All views by others Views LinkedIn Views LinkedIn by others\\nATE 0.00619 0.00246 0.00600 0.00214\\n(0.00090) (0.00080) (0.00085) (0.00075)\\nATE % baseline 3.371 1.8041 3.8036 1.8278\\n(0.5473) (0.4894) (0.5152) (0.4596)\\nBaseline 0.1884 0.1421 0.1621 0.1228\\n(0.00063) (0.00056) (0.00059) (0.00053)\\nObservations 765,616 765,616 765,616 765,616\\nLearners covariates Yes Yes Yes Yes\\nNote: Estimates of the average treatment effect on the probability of receiving views from LinkedIn. Columns 1 and 3 have all LinkedIn\\nviews as outcomes, and Columns 2 and 4 restrict attention to views not by the user. Estimates in Columns 1 and 2 are from the OLS\\nestimator, and in Columns 3 and 4, they are with logit regression. Each estimate is adjusted using learners’ characteristics as controls.\\nWe estimate that Credential Feature increases the probability of having at least one view on the\\ncertificate by 0.7 p.p. (S.E. 0.1 p.p.) to 0.3 p.p. (SE 0.1 p.p.) corresponding to a 4% to 2% increase from\\nthe baseline levels.\\n17'], reference_answer='The estimated impact of the Credential Feature on the probability of receiving views on LinkedIn is an increase of 0.00619 (or 0.619 percentage points) for all views and 0.00246 (or 0.246 percentage points) for views by others. This corresponds to a 3.371% increase from baseline for all views and a 1.8041% increase from baseline for views by others. The impact is greater when considering all views compared to views by others.', reference_answer_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>)),\n",
       " LabelledRagDataExample(query='**Answer:** The estimated impact of the Credential Feature on the probability of receiving views on LinkedIn is an increase of 0.00619 (or 0.619%) for all views and 0.00246 (or 0.246%) for views by others. This corresponds to a percentage increase from baseline levels of 3.371% for all views and 1.8041% for views by others.', query_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>), reference_contexts=['impact of a more complete LinkedIn profile. To test for this mechanism, we compute the number of\\ncharacters in the learner’s LinkedIn profile, excluding fields related to credentials and new jobs. We\\nfind that, on average, learners in the treated group have 1362 characters, and learners in the control\\ngroup have 1356. The effect of treatment on this outcome is, therefore, 6 characters (S.E. 6). Thus, we\\ndo not find that the profiles of treated learners are more complete.\\n5 Impact of the Credential Featureon Certificate Views\\nIn this section, we consider the impact of the Credential Feature on the probability that learners’ cer-\\ntificates were viewed. In this analysis, we consider the entire experimental group, which includes\\nlearners in the LinkedIn Matched Sample, all of whom have LinkedIn accounts, and other learners, in-\\ncluding those who might not have LinkedIn accounts. In Appendix D, we show that there is a high\\ncorrelation between certificate views and the probability of reporting a new job; thus, we treat certifi-\\ncate views as a proxy for employment outcome.\\nTable 6 shows the estimates of the average effect ofCredential Feature on the probability of getting a\\nclick on LinkedIn from the OLS estimator. Models 3 and 4 restrict attention to views where the referral\\npage was LinkedIn. Models 2 and 4 restrict attention to views by someone other than the learner. All\\nestimates are adjusted for learners’ characteristics.\\nTable 6: Impact of Credential Feature on the probability of receiving views\\nOLS\\nAll views All views by others Views LinkedIn Views LinkedIn by others\\nATE 0.00619 0.00246 0.00600 0.00214\\n(0.00090) (0.00080) (0.00085) (0.00075)\\nATE % baseline 3.371 1.8041 3.8036 1.8278\\n(0.5473) (0.4894) (0.5152) (0.4596)\\nBaseline 0.1884 0.1421 0.1621 0.1228\\n(0.00063) (0.00056) (0.00059) (0.00053)\\nObservations 765,616 765,616 765,616 765,616\\nLearners covariates Yes Yes Yes Yes\\nNote: Estimates of the average treatment effect on the probability of receiving views from LinkedIn. Columns 1 and 3 have all LinkedIn\\nviews as outcomes, and Columns 2 and 4 restrict attention to views not by the user. Estimates in Columns 1 and 2 are from the OLS\\nestimator, and in Columns 3 and 4, they are with logit regression. Each estimate is adjusted using learners’ characteristics as controls.\\nWe estimate that Credential Feature increases the probability of having at least one view on the\\ncertificate by 0.7 p.p. (S.E. 0.1 p.p.) to 0.3 p.p. (SE 0.1 p.p.) corresponding to a 4% to 2% increase from\\nthe baseline levels.\\n17'], reference_answer='The estimated impact of the Credential Feature on the probability of receiving views on LinkedIn is an increase of 0.00619 for all views and 0.00246 for views by others. This corresponds to a percentage increase from baseline levels of 3.371% for all views and 1.8041% for views by others.', reference_answer_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>)),\n",
       " LabelledRagDataExample(query='**Question:** What impact do non-traditional credentials, such as MOOC certificates, have on labor market outcomes according to the study, and how does the visibility of these credentials on platforms like LinkedIn affect employability?', query_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>), reference_contexts=['6 Conclusion\\nThis study provides insights into the impact of non-traditional credentials, specifically MOOC certifi-\\ncates, on labor market outcomes. Our randomized experiment first shows that features that encourage\\nand simplify credential sharing can improve job outcomes for learners. Second, we show that learn-\\ners who showcased their Coursera certificates on LinkedIn experienced a significant increase in the\\nlikelihood of reporting new employment, particularly in roles related to their MOOC credentials. This\\neffect was most pronounced among learners with lower baseline employability, suggesting that sig-\\nnaling skills through non-traditional credentials can be particularly beneficial for this group and may\\ncontribute to more equitable employment outcomes. The findings also highlight the importance of\\nthe visibility of credentials on professional networking platforms, as the treatment effect was medi-\\nated by the presence of certificates on learners’ LinkedIn profiles. This underscores the value of online\\nplatforms in facilitating skill signaling and enhancing employability.\\nFor further research, it would be valuable to explore the longitudinal impact of showcasing MOOC\\ncredentials on career advancement and income growth, providing a more comprehensive understand-\\ning of their value over time. Investigating employers’ perceptions of non-traditional credentials in\\nmore depth, including the factors that influence their recognition and acceptance, would provide valu-\\nable insights for both learners and MOOC providers. Furthermore, examining the impact of MOOC\\ncredentials in different cultural and economic contexts could shed light on the differences in the ap-\\nplicability of these findings. Further research could also assess the extent to which MOOCs contribute\\nto skill development and how this relates to employability, exploring the balance between signaling\\nand skill acquisition.\\nReferences\\nAbebe, G., Caria, S., Fafchamps, M., Falco, P ., Franklin, S., Quinn, S., and Shilpi, F. (2020). Matching\\nfrictions and distorted beliefs: Evidence from a job fair experiment. Department of Economics, Oxford\\nUniversity (mimeo).\\nAngrist, J. and Imbens, G. (1995). Identification and estimation of local average treatment effects.\\nAthey, S., Keleher, N., and Spiess, J. (2023). Machine learning who to nudge: Causal vs predictive\\ntargeting in a field experiment on student financial aid renewal. arXiv preprint arXiv:2310.08672.\\n18'], reference_answer='According to the study, non-traditional credentials, such as MOOC certificates, have a positive impact on labor market outcomes. The study found that features encouraging and simplifying credential sharing can improve job outcomes for learners. Specifically, learners who showcased their Coursera certificates on LinkedIn experienced a significant increase in the likelihood of reporting new employment, particularly in roles related to their MOOC credentials. This effect was most pronounced among learners with lower baseline employability, suggesting that signaling skills through non-traditional credentials can be particularly beneficial for this group and may contribute to more equitable employment outcomes. The visibility of these credentials on professional networking platforms like LinkedIn is crucial, as the treatment effect was mediated by the presence of certificates on learners’ profiles. This underscores the value of online platforms in facilitating skill signaling and enhancing employability.', reference_answer_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>)),\n",
       " LabelledRagDataExample(query=\"**Answer:** The study indicates that non-traditional credentials, specifically MOOC certificates, positively impact labor market outcomes by improving job prospects for learners. It highlights that learners who displayed their Coursera certificates on LinkedIn experienced a significant increase in the likelihood of reporting new employment, especially in roles related to their MOOC credentials. This effect was particularly pronounced among learners with lower baseline employability, suggesting that signaling skills through non-traditional credentials can be especially beneficial for this group. The visibility of these credentials on professional networking platforms like LinkedIn plays a crucial role, as the treatment effect was mediated by the presence of certificates on learners' profiles, underscoring the value of online platforms in facilitating skill signaling and enhancing employability.\", query_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>), reference_contexts=['6 Conclusion\\nThis study provides insights into the impact of non-traditional credentials, specifically MOOC certifi-\\ncates, on labor market outcomes. Our randomized experiment first shows that features that encourage\\nand simplify credential sharing can improve job outcomes for learners. Second, we show that learn-\\ners who showcased their Coursera certificates on LinkedIn experienced a significant increase in the\\nlikelihood of reporting new employment, particularly in roles related to their MOOC credentials. This\\neffect was most pronounced among learners with lower baseline employability, suggesting that sig-\\nnaling skills through non-traditional credentials can be particularly beneficial for this group and may\\ncontribute to more equitable employment outcomes. The findings also highlight the importance of\\nthe visibility of credentials on professional networking platforms, as the treatment effect was medi-\\nated by the presence of certificates on learners’ LinkedIn profiles. This underscores the value of online\\nplatforms in facilitating skill signaling and enhancing employability.\\nFor further research, it would be valuable to explore the longitudinal impact of showcasing MOOC\\ncredentials on career advancement and income growth, providing a more comprehensive understand-\\ning of their value over time. Investigating employers’ perceptions of non-traditional credentials in\\nmore depth, including the factors that influence their recognition and acceptance, would provide valu-\\nable insights for both learners and MOOC providers. Furthermore, examining the impact of MOOC\\ncredentials in different cultural and economic contexts could shed light on the differences in the ap-\\nplicability of these findings. Further research could also assess the extent to which MOOCs contribute\\nto skill development and how this relates to employability, exploring the balance between signaling\\nand skill acquisition.\\nReferences\\nAbebe, G., Caria, S., Fafchamps, M., Falco, P ., Franklin, S., Quinn, S., and Shilpi, F. (2020). Matching\\nfrictions and distorted beliefs: Evidence from a job fair experiment. Department of Economics, Oxford\\nUniversity (mimeo).\\nAngrist, J. and Imbens, G. (1995). Identification and estimation of local average treatment effects.\\nAthey, S., Keleher, N., and Spiess, J. (2023). Machine learning who to nudge: Causal vs predictive\\ntargeting in a field experiment on student financial aid renewal. arXiv preprint arXiv:2310.08672.\\n18'], reference_answer=\"The study indicates that non-traditional credentials, specifically MOOC certificates, positively impact labor market outcomes by improving job prospects for learners. It highlights that learners who displayed their Coursera certificates on LinkedIn experienced a significant increase in the likelihood of reporting new employment, especially in roles related to their MOOC credentials. This effect was particularly pronounced among learners with lower baseline employability, suggesting that signaling skills through non-traditional credentials can be especially beneficial for this group. The visibility of these credentials on professional networking platforms like LinkedIn plays a crucial role, as the treatment effect was mediated by the presence of certificates on learners' profiles, underscoring the value of online platforms in facilitating skill signaling and enhancing employability.\", reference_answer_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>)),\n",
       " LabelledRagDataExample(query='Question: What are some of the key studies and findings related to the impact of online education platforms and MOOCs on labor market outcomes and education democratization?', query_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>), reference_contexts=['Athey, S. and Palikot, E. (2022). Effective and scalable programs to facilitate labor market transitions\\nfor women in technolog. arXiv preprint arXiv:2211.09968.\\nBassi, V . and Nansamba, A. (2022). Screening and signalling non-cognitive skills: experimental evi-\\ndence from uganda. The Economic Journal, 132(642):471–511.\\nCarranza, E., Garlick, R., Orkin, K., and Rankin, N. (2020). Job search and hiring with two-sided\\nlimited information about workseekers’ skills. Economic Research Initiatives at Duke (ERID) Working\\nPaper, (296).\\nCastaño-Muñoz, J. and Rodrigues, M. (2021). Open to moocs? evidence of their impact on labour\\nmarket outcomes. Computers & Education, 173:104289.\\nChirikov, I., Semenova, T., Maloshonok, N., Bettinger, E., and Kizilcec, R. F. (2020). Online education\\nplatforms scale college stem instruction with equivalent learning outcomes at lower cost. Science\\nadvances, 6(15):eaay5324.\\nChristensen, G., Steinmetz, A., Alcorn, B., Bennett, A., Woods, D., and Emanuel, E. (2013). The mooc\\nphenomenon: Who takes massive open online courses and why? Available at SSRN 2350964.\\nCoursera, I. (2022). Coursera, inc. - coursera reports fourth quarter and full year 2022.Coursera Investor\\nRelations. Accessed: November 16, 2023.\\nCoursera, Inc. (2023). Coursera reports third quarter 2023 financial results. Quarterly Results, Cours-\\nera, Inc. Accessed: November 16, 2023.\\nDeming, D. J., Yuchtman, N., Abulafi, A., Goldin, C., and Katz, L. F. (2016). The value of postsecondary\\ncredentials in the labor market: An experimental study. American Economic Review, 106(3):778–806.\\nHadavand, A., Gooding, I., and Leek, J. T. (2018). Can mooc programs improve student employment\\nprospects? Available at SSRN 3260695.\\nHansen, J. D. and Reich, J. (2015). Democratizing education? examining access and usage patterns in\\nmassive open online courses. Science, 350(6265):1245–1248.\\nHussey, A. (2012). Human capital augmentation versus the signaling value of mba education. Eco-\\nnomics of Education Review, 31(4):442–451.\\n19'], reference_answer='The context provides references to several key studies related to the impact of online education platforms and MOOCs on labor market outcomes and education democratization:\\n\\n1. **Castaño-Muñoz and Rodrigues (2021)**: This study examines the impact of MOOCs on labor market outcomes, suggesting that these courses can influence employment prospects.\\n\\n2. **Chirikov et al. (2020)**: This research indicates that online education platforms can scale college STEM instruction while maintaining equivalent learning outcomes at a lower cost, highlighting the potential for cost-effective education delivery.\\n\\n3. **Christensen et al. (2013)**: This study explores who participates in MOOCs and their motivations, providing insights into the demographics and reasons behind MOOC enrollment.\\n\\n4. **Hansen and Reich (2015)**: This research investigates the democratization of education through MOOCs, examining access and usage patterns to understand how these courses may broaden educational opportunities.\\n\\nThese studies collectively suggest that online education platforms and MOOCs have the potential to improve labor market outcomes by providing accessible and cost-effective education, while also contributing to the democratization of education by reaching a broader audience.', reference_answer_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>)),\n",
       " LabelledRagDataExample(query=\"Answer: The context provides several studies related to online education platforms and MOOCs. Chirikov et al. (2020) found that online education platforms can scale college STEM instruction with equivalent learning outcomes at a lower cost. Castaño-Muñoz and Rodrigues (2021) provided evidence of MOOCs' impact on labor market outcomes. Hansen and Reich (2015) examined the democratization of education through MOOCs, focusing on access and usage patterns. Additionally, Hadavand et al. (2018) explored whether MOOC programs can improve student employment prospects. These studies collectively highlight the potential of online education to enhance learning outcomes, democratize access to education, and positively influence labor market outcomes.\", query_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>), reference_contexts=['Athey, S. and Palikot, E. (2022). Effective and scalable programs to facilitate labor market transitions\\nfor women in technolog. arXiv preprint arXiv:2211.09968.\\nBassi, V . and Nansamba, A. (2022). Screening and signalling non-cognitive skills: experimental evi-\\ndence from uganda. The Economic Journal, 132(642):471–511.\\nCarranza, E., Garlick, R., Orkin, K., and Rankin, N. (2020). Job search and hiring with two-sided\\nlimited information about workseekers’ skills. Economic Research Initiatives at Duke (ERID) Working\\nPaper, (296).\\nCastaño-Muñoz, J. and Rodrigues, M. (2021). Open to moocs? evidence of their impact on labour\\nmarket outcomes. Computers & Education, 173:104289.\\nChirikov, I., Semenova, T., Maloshonok, N., Bettinger, E., and Kizilcec, R. F. (2020). Online education\\nplatforms scale college stem instruction with equivalent learning outcomes at lower cost. Science\\nadvances, 6(15):eaay5324.\\nChristensen, G., Steinmetz, A., Alcorn, B., Bennett, A., Woods, D., and Emanuel, E. (2013). The mooc\\nphenomenon: Who takes massive open online courses and why? Available at SSRN 2350964.\\nCoursera, I. (2022). Coursera, inc. - coursera reports fourth quarter and full year 2022.Coursera Investor\\nRelations. Accessed: November 16, 2023.\\nCoursera, Inc. (2023). Coursera reports third quarter 2023 financial results. Quarterly Results, Cours-\\nera, Inc. Accessed: November 16, 2023.\\nDeming, D. J., Yuchtman, N., Abulafi, A., Goldin, C., and Katz, L. F. (2016). The value of postsecondary\\ncredentials in the labor market: An experimental study. American Economic Review, 106(3):778–806.\\nHadavand, A., Gooding, I., and Leek, J. T. (2018). Can mooc programs improve student employment\\nprospects? Available at SSRN 3260695.\\nHansen, J. D. and Reich, J. (2015). Democratizing education? examining access and usage patterns in\\nmassive open online courses. Science, 350(6265):1245–1248.\\nHussey, A. (2012). Human capital augmentation versus the signaling value of mba education. Eco-\\nnomics of Education Review, 31(4):442–451.\\n19'], reference_answer=\"The context provides several studies related to online education platforms and MOOCs. Chirikov et al. (2020) found that online education platforms can scale college STEM instruction with equivalent learning outcomes at a lower cost. Castaño-Muñoz and Rodrigues (2021) provided evidence of MOOCs' impact on labor market outcomes. Hansen and Reich (2015) examined the democratization of education through MOOCs, focusing on access and usage patterns. Additionally, Hadavand et al. (2018) explored whether MOOC programs can improve student employment prospects. These studies collectively highlight the potential of online education to enhance learning outcomes, democratize access to education, and positively influence labor market outcomes.\", reference_answer_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>)),\n",
       " LabelledRagDataExample(query='Question: What are some of the potential benefits and challenges associated with online degrees and digital skill certificates in the labor market, as discussed in the provided context?', query_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>), reference_contexts=['Kässi, O. and Lehdonvirta, V . (2019). Do digital skill certificates help new workers enter the market?\\nevidence from an online labour platform.\\nKizilcec, R., Davis, D., and Wang, E. (2019). Online degree stigma and stereotypes: A new instrument\\nand implications for diversity in higher education. Available at SSRN 3339768.\\nKizilcec, R. F., Saltarelli, A. J., Reich, J., and Cohen, G. L. (2017). Closing global achievement gaps in\\nmoocs. Science, 355(6322):251–252.\\nLaryea, K., Paepcke, A., Mirzaei, K., and Stevens, M. L. (2021). Ambiguous credentials: How learners\\nuse and make sense of massively open online courses.The Journal of Higher Education, 92(4):596–622.\\nLearnopoly (2022). Coursera statistics (2023): Top statistics on coursera.org. Learnopoly. Accessed:\\nNovember 16, 2023.\\nLennon, C. (2021). How do online degrees affect labor market prospects? evidence from a correspon-\\ndence audit study. ILR Review, 74(4):920–947.\\nMoura, V . F., Souza, C. A., Oliveira Neto, J. D., and Viana, A. B. (2017). Moocs’potential for democratiz-\\ning education: An analysis from the perspective of access to technology. InInformation Systems: 14th\\nEuropean, Mediterranean, and Middle Eastern Conference, EMCIS 2017, Coimbra, Portugal, September 7-8,\\n2017, Proceedings 14, pages 139–153. Springer.\\nPallais, A. (2014). Inefficient hiring in entry-level labor markets. American Economic Review ,\\n104(11):3565–3599.\\nPiopiunik, M., Schwerdt, G., Simon, L., and Woessmann, L. (2020). Skills, signals, and employability:\\nAn experimental investigation. European Economic Review, 123:103374.\\nRadford, A. W., Robles, J., Cataylo, S., Horn, L., Thornton, J., and Whitfield, K. (2014). The employer\\npotential of moocs: A mixed-methods study of human resource professionals’ thinking on moocs.\\nInternational Review of Research in Open and Distributed Learning, 15(5):1–25.\\nReddick, R. (2019). Using a glicko-based algorithm to measure in-course learning. International Edu-\\ncational Data Mining Society.\\n20'], reference_answer='The provided context mentions several studies and articles that explore the potential benefits and challenges associated with online degrees and digital skill certificates in the labor market. Here are some insights based on the context:\\n\\n**Potential Benefits:**\\n1. **Market Entry Assistance:** Kässi and Lehdonvirta (2019) discuss how digital skill certificates can help new workers enter the market, suggesting that these credentials may provide a pathway for individuals to demonstrate their skills and gain employment.\\n2. **Democratizing Education:** Moura et al. (2017) highlight the potential of MOOCs (Massively Open Online Courses) to democratize education by providing access to technology and learning opportunities to a broader audience, which can enhance employability.\\n3. **Closing Achievement Gaps:** Kizilcec et al. (2017) mention the potential of MOOCs to close global achievement gaps, which could lead to a more diverse and skilled workforce.\\n\\n**Challenges:**\\n1. **Stigma and Stereotypes:** Kizilcec, Davis, and Wang (2019) address the stigma and stereotypes associated with online degrees, which can impact the perception of these credentials in the labor market and potentially affect employment prospects.\\n2. **Ambiguity in Credentials:** Laryea et al. (2021) discuss the ambiguity surrounding how learners use and interpret MOOCs, which can lead to challenges in how these credentials are perceived by employers.\\n3. **Labor Market Prospects:** Lennon (2021) examines how online degrees affect labor market prospects, indicating that there may be varying perceptions and acceptance of these credentials among employers.\\n\\nOverall, while online degrees and digital skill certificates offer opportunities for skill development and market entry, they also face challenges related to perception and acceptance in the labor market.', reference_answer_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>)),\n",
       " LabelledRagDataExample(query=\"Answer: The context suggests that digital skill certificates and online degrees can potentially help new workers enter the market, as indicated by Kässi and Lehdonvirta (2019). However, there may also be stigma and stereotypes associated with online degrees, which could impact their acceptance in the labor market, as explored by Kizilcec, Davis, and Wang (2019). Additionally, Lennon (2021) examines how online degrees affect labor market prospects, suggesting that there are mixed perceptions about their value. Overall, while online credentials can democratize education and provide access to skills, their effectiveness in improving employability may be influenced by employers' perceptions and the existing stereotypes about online education.\", query_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>), reference_contexts=['Kässi, O. and Lehdonvirta, V . (2019). Do digital skill certificates help new workers enter the market?\\nevidence from an online labour platform.\\nKizilcec, R., Davis, D., and Wang, E. (2019). Online degree stigma and stereotypes: A new instrument\\nand implications for diversity in higher education. Available at SSRN 3339768.\\nKizilcec, R. F., Saltarelli, A. J., Reich, J., and Cohen, G. L. (2017). Closing global achievement gaps in\\nmoocs. Science, 355(6322):251–252.\\nLaryea, K., Paepcke, A., Mirzaei, K., and Stevens, M. L. (2021). Ambiguous credentials: How learners\\nuse and make sense of massively open online courses.The Journal of Higher Education, 92(4):596–622.\\nLearnopoly (2022). Coursera statistics (2023): Top statistics on coursera.org. Learnopoly. Accessed:\\nNovember 16, 2023.\\nLennon, C. (2021). How do online degrees affect labor market prospects? evidence from a correspon-\\ndence audit study. ILR Review, 74(4):920–947.\\nMoura, V . F., Souza, C. A., Oliveira Neto, J. D., and Viana, A. B. (2017). Moocs’potential for democratiz-\\ning education: An analysis from the perspective of access to technology. InInformation Systems: 14th\\nEuropean, Mediterranean, and Middle Eastern Conference, EMCIS 2017, Coimbra, Portugal, September 7-8,\\n2017, Proceedings 14, pages 139–153. Springer.\\nPallais, A. (2014). Inefficient hiring in entry-level labor markets. American Economic Review ,\\n104(11):3565–3599.\\nPiopiunik, M., Schwerdt, G., Simon, L., and Woessmann, L. (2020). Skills, signals, and employability:\\nAn experimental investigation. European Economic Review, 123:103374.\\nRadford, A. W., Robles, J., Cataylo, S., Horn, L., Thornton, J., and Whitfield, K. (2014). The employer\\npotential of moocs: A mixed-methods study of human resource professionals’ thinking on moocs.\\nInternational Review of Research in Open and Distributed Learning, 15(5):1–25.\\nReddick, R. (2019). Using a glicko-based algorithm to measure in-course learning. International Edu-\\ncational Data Mining Society.\\n20'], reference_answer=\"The context suggests that digital skill certificates and online degrees can potentially help new workers enter the market, as indicated by Kässi and Lehdonvirta (2019). However, there may also be stigma and stereotypes associated with online degrees, which could impact their acceptance in the labor market, as explored by Kizilcec, Davis, and Wang (2019). Additionally, Lennon (2021) examines how online degrees affect labor market prospects, suggesting that there are mixed perceptions about their value. Overall, while online credentials can democratize education and provide access to skills, their effectiveness in improving employability may be influenced by employers' perceptions and the existing stereotypes about online education.\", reference_answer_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>)),\n",
       " LabelledRagDataExample(query='**Question:** Based on the provided context, what are some of the key studies or reports that have examined the value and impact of MOOCs in the job market?', query_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>), reference_contexts=['Rivas, M. J., Baker, R. B., and Evans, B. J. (2020). Do moocs make you more marketable? an experi-\\nmental analysis of the value of moocs relative to traditional credentials and experience.AERA Open,\\n6(4):2332858420973577.\\nRosendale, J. A. (2016). Valuing non-degree, online training: An examination of hiring managers’ perceptions\\nof MOOCs. Indiana University of Pennsylvania.\\nShah, D. (2021). A decade of moocs: A review of stats and trends for large-scale online courses in 2021.\\nEdSurge. Accessed at McKinsey website: \"Growth in online education. Are providers ready?\".\\nSpence, M. (1978). Job market signaling. In Uncertainty in economics, pages 281–306. Elsevier.\\nThinkImpact (2021). Coursera statistics 2023 - number of users and revenue. ThinkImpact. Accessed:\\nNovember 16, 2023.\\nTyler, J. H., Murnane, R. J., and Willett, J. B. (2000). Estimating the labor market signaling value of the\\nged. The Quarterly Journal of Economics, 115(2):431–468.\\nZhenghao, C., Alcorn, B., Christensen, G., Eriksson, N., Koller, D., and Emanuel, E. J. (2015). Who’s\\nbenefiting from moocs, and why. Harvard Business Review.\\n21'], reference_answer='Based on the provided context, some of the key studies and reports that have examined the value and impact of MOOCs in the job market include:\\n\\n1. Rivas, M. J., Baker, R. B., and Evans, B. J. (2020). \"Do MOOCs make you more marketable? An experimental analysis of the value of MOOCs relative to traditional credentials and experience.\" Published in AERA Open.\\n\\n2. Rosendale, J. A. (2016). \"Valuing non-degree, online training: An examination of hiring managers’ perceptions of MOOCs.\" Conducted at Indiana University of Pennsylvania.\\n\\n3. Shah, D. (2021). \"A decade of MOOCs: A review of stats and trends for large-scale online courses in 2021.\" Published on EdSurge and accessed at the McKinsey website.\\n\\nThese studies and reports focus on the marketability, perceptions, and trends related to MOOCs in the context of employment and hiring practices.', reference_answer_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>)),\n",
       " LabelledRagDataExample(query='**Answer:** The key studies and reports that have examined the value and impact of MOOCs in the job market include:', query_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>), reference_contexts=['Rivas, M. J., Baker, R. B., and Evans, B. J. (2020). Do moocs make you more marketable? an experi-\\nmental analysis of the value of moocs relative to traditional credentials and experience.AERA Open,\\n6(4):2332858420973577.\\nRosendale, J. A. (2016). Valuing non-degree, online training: An examination of hiring managers’ perceptions\\nof MOOCs. Indiana University of Pennsylvania.\\nShah, D. (2021). A decade of moocs: A review of stats and trends for large-scale online courses in 2021.\\nEdSurge. Accessed at McKinsey website: \"Growth in online education. Are providers ready?\".\\nSpence, M. (1978). Job market signaling. In Uncertainty in economics, pages 281–306. Elsevier.\\nThinkImpact (2021). Coursera statistics 2023 - number of users and revenue. ThinkImpact. Accessed:\\nNovember 16, 2023.\\nTyler, J. H., Murnane, R. J., and Willett, J. B. (2000). Estimating the labor market signaling value of the\\nged. The Quarterly Journal of Economics, 115(2):431–468.\\nZhenghao, C., Alcorn, B., Christensen, G., Eriksson, N., Koller, D., and Emanuel, E. J. (2015). Who’s\\nbenefiting from moocs, and why. Harvard Business Review.\\n21'], reference_answer='The key studies and reports that have examined the value and impact of MOOCs in the job market include:\\n\\n1. Rivas, M. J., Baker, R. B., and Evans, B. J. (2020). \"Do MOOCs make you more marketable? An experimental analysis of the value of MOOCs relative to traditional credentials and experience.\" AERA Open, 6(4):2332858420973577.\\n\\n2. Rosendale, J. A. (2016). \"Valuing non-degree, online training: An examination of hiring managers’ perceptions of MOOCs.\" Indiana University of Pennsylvania.\\n\\n3. Shah, D. (2021). \"A decade of MOOCs: A review of stats and trends for large-scale online courses in 2021.\" EdSurge. Accessed at McKinsey website: \"Growth in online education. Are providers ready?\".\\n\\n4. Zhenghao, C., Alcorn, B., Christensen, G., Eriksson, N., Koller, D., and Emanuel, E. J. (2015). \"Who’s benefiting from MOOCs, and why.\" Harvard Business Review.', reference_answer_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>)),\n",
       " LabelledRagDataExample(query='Rivas, M. J., Baker, R. B., and Evans, B. J. (2020) conducted an experimental analysis on the marketability of MOOCs relative to traditional credentials and experience, published in AERA Open.', query_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>), reference_contexts=['Rivas, M. J., Baker, R. B., and Evans, B. J. (2020). Do moocs make you more marketable? an experi-\\nmental analysis of the value of moocs relative to traditional credentials and experience.AERA Open,\\n6(4):2332858420973577.\\nRosendale, J. A. (2016). Valuing non-degree, online training: An examination of hiring managers’ perceptions\\nof MOOCs. Indiana University of Pennsylvania.\\nShah, D. (2021). A decade of moocs: A review of stats and trends for large-scale online courses in 2021.\\nEdSurge. Accessed at McKinsey website: \"Growth in online education. Are providers ready?\".\\nSpence, M. (1978). Job market signaling. In Uncertainty in economics, pages 281–306. Elsevier.\\nThinkImpact (2021). Coursera statistics 2023 - number of users and revenue. ThinkImpact. Accessed:\\nNovember 16, 2023.\\nTyler, J. H., Murnane, R. J., and Willett, J. B. (2000). Estimating the labor market signaling value of the\\nged. The Quarterly Journal of Economics, 115(2):431–468.\\nZhenghao, C., Alcorn, B., Christensen, G., Eriksson, N., Koller, D., and Emanuel, E. J. (2015). Who’s\\nbenefiting from moocs, and why. Harvard Business Review.\\n21'], reference_answer='Rivas, M. J., Baker, R. B., and Evans, B. J. (2020) conducted an experimental analysis on the marketability of MOOCs relative to traditional credentials and experience, and their findings were published in AERA Open, volume 6, issue 4, with the article identifier 2332858420973577.', reference_answer_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>)),\n",
       " LabelledRagDataExample(query=\"Rosendale, J. A. (2016) explored hiring managers' perceptions of MOOCs in his examination of valuing non-degree, online training at Indiana University of Pennsylvania.\", query_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>), reference_contexts=['Rivas, M. J., Baker, R. B., and Evans, B. J. (2020). Do moocs make you more marketable? an experi-\\nmental analysis of the value of moocs relative to traditional credentials and experience.AERA Open,\\n6(4):2332858420973577.\\nRosendale, J. A. (2016). Valuing non-degree, online training: An examination of hiring managers’ perceptions\\nof MOOCs. Indiana University of Pennsylvania.\\nShah, D. (2021). A decade of moocs: A review of stats and trends for large-scale online courses in 2021.\\nEdSurge. Accessed at McKinsey website: \"Growth in online education. Are providers ready?\".\\nSpence, M. (1978). Job market signaling. In Uncertainty in economics, pages 281–306. Elsevier.\\nThinkImpact (2021). Coursera statistics 2023 - number of users and revenue. ThinkImpact. Accessed:\\nNovember 16, 2023.\\nTyler, J. H., Murnane, R. J., and Willett, J. B. (2000). Estimating the labor market signaling value of the\\nged. The Quarterly Journal of Economics, 115(2):431–468.\\nZhenghao, C., Alcorn, B., Christensen, G., Eriksson, N., Koller, D., and Emanuel, E. J. (2015). Who’s\\nbenefiting from moocs, and why. Harvard Business Review.\\n21'], reference_answer=\"Rosendale, J. A. (2016) conducted an examination of hiring managers' perceptions of MOOCs, focusing on the value of non-degree, online training at Indiana University of Pennsylvania.\", reference_answer_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>)),\n",
       " LabelledRagDataExample(query='Shah, D. (2021) reviewed statistics and trends for large-scale online courses over a decade, as accessed on the McKinsey website.', query_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>), reference_contexts=['Rivas, M. J., Baker, R. B., and Evans, B. J. (2020). Do moocs make you more marketable? an experi-\\nmental analysis of the value of moocs relative to traditional credentials and experience.AERA Open,\\n6(4):2332858420973577.\\nRosendale, J. A. (2016). Valuing non-degree, online training: An examination of hiring managers’ perceptions\\nof MOOCs. Indiana University of Pennsylvania.\\nShah, D. (2021). A decade of moocs: A review of stats and trends for large-scale online courses in 2021.\\nEdSurge. Accessed at McKinsey website: \"Growth in online education. Are providers ready?\".\\nSpence, M. (1978). Job market signaling. In Uncertainty in economics, pages 281–306. Elsevier.\\nThinkImpact (2021). Coursera statistics 2023 - number of users and revenue. ThinkImpact. Accessed:\\nNovember 16, 2023.\\nTyler, J. H., Murnane, R. J., and Willett, J. B. (2000). Estimating the labor market signaling value of the\\nged. The Quarterly Journal of Economics, 115(2):431–468.\\nZhenghao, C., Alcorn, B., Christensen, G., Eriksson, N., Koller, D., and Emanuel, E. J. (2015). Who’s\\nbenefiting from moocs, and why. Harvard Business Review.\\n21'], reference_answer='Shah, D. (2021) conducted a review of statistics and trends for large-scale online courses over a decade, which was accessed on the McKinsey website under the title \"Growth in online education. Are providers ready?\".', reference_answer_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>)),\n",
       " LabelledRagDataExample(query='Zhenghao, C., Alcorn, B., Christensen, G., Eriksson, N., Koller, D., and Emanuel, E. J. (2015) discussed who benefits from MOOCs and why in the Harvard Business Review.', query_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>), reference_contexts=['Rivas, M. J., Baker, R. B., and Evans, B. J. (2020). Do moocs make you more marketable? an experi-\\nmental analysis of the value of moocs relative to traditional credentials and experience.AERA Open,\\n6(4):2332858420973577.\\nRosendale, J. A. (2016). Valuing non-degree, online training: An examination of hiring managers’ perceptions\\nof MOOCs. Indiana University of Pennsylvania.\\nShah, D. (2021). A decade of moocs: A review of stats and trends for large-scale online courses in 2021.\\nEdSurge. Accessed at McKinsey website: \"Growth in online education. Are providers ready?\".\\nSpence, M. (1978). Job market signaling. In Uncertainty in economics, pages 281–306. Elsevier.\\nThinkImpact (2021). Coursera statistics 2023 - number of users and revenue. ThinkImpact. Accessed:\\nNovember 16, 2023.\\nTyler, J. H., Murnane, R. J., and Willett, J. B. (2000). Estimating the labor market signaling value of the\\nged. The Quarterly Journal of Economics, 115(2):431–468.\\nZhenghao, C., Alcorn, B., Christensen, G., Eriksson, N., Koller, D., and Emanuel, E. J. (2015). Who’s\\nbenefiting from moocs, and why. Harvard Business Review.\\n21'], reference_answer='Zhenghao, C., Alcorn, B., Christensen, G., Eriksson, N., Koller, D., and Emanuel, E. J. (2015) discussed who benefits from MOOCs and why in the Harvard Business Review.', reference_answer_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>)),\n",
       " LabelledRagDataExample(query='**Question:** What is the primary domain and credential type of the course \"Neural Networks and Deep Learning\" included in the experiment?', query_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>), reference_contexts=['Appendix\\nA Sample of courses included in the experiment\\nIn Table 7, we show a sample of 50 courses of 7355 from which the learners included in the experiment\\ngraduated.\\nTable 7: Sample of course included in the experiment\\nPrimary domain Credential Type Certificate Name\\nInformation Technology Course Fundamentos do Suporte Técnico\\nBusiness Guided Project Develop a Company Website with Wix\\nData Science Course SQL for Data Science\\nInformation Technology Course Fundamentals of Red Hat Enterprise Linux\\nData Science Course Neural Networks and Deep Learning\\nInformation Technology Course Introduction to Cloud Computing\\nInformation Technology Course AWS Cloud Practitioner Essentials\\nBusiness Course Capital-investissement et capital-risque\\nData Science Specialization Introduction to Data Science\\nBusiness Course Teamwork Skills: Communicating Effectively in Groups\\nInformation Technology Course Crash Course on Python\\nBusiness Course Excel Skills for Business: Advanced\\nData Science Guided Project Introduction to Business Analysis Using Spreadsheets: Basics\\nBusiness Course Foundations of Project Management\\nBusiness Course Assess for Success: Marketing Analytics and Measurement\\nBusiness Course Bookkeeping Basics\\nComputer Science Course Introduction to Front-End Development\\nBusiness Guided Project Create a Project Charter with Google Docs\\nData Science Professional Certificate Google Data Analytics\\nInformation Technology Course Technical Support Fundamentals\\nComputer Science Course Python Programming: A Concise Introduction\\nInformation Technology Course Introduction to Web Development with HTML, CSS, JavaScript\\nComputer Science Guided Project Get Started with Figma\\nComputer Science Course Foundations of User Experience (UX) Design\\nComputer Science Course Programming for Everybody (Getting Started with Python)\\nData Science Professional Certificate IBM Data Analyst\\nComputer Science Course JavaScript Basics\\nBusiness Course Foundations of Digital Marketing and E-commerce\\nData Science Course Foundations: Data, Data, Everywhere\\nInformation Technology Course AWS Cloud Technical Essentials\\nComputer Science Course Blockchain: Foundations and Use Cases\\nComputer Science Course HTML, CSS, and Javascript for Web Developers\\nBusiness Course Developing Innovative Ideas for Product Leaders\\nBusiness Guided Project Introduction to Microsoft Excel\\nBusiness Course Construction Project Management\\nData Science Course Introduction to Genomic Technologies\\nInformation Technology Course Explore Core Data Concepts in Microsoft Azure\\nComputer Science Course Responsive Website Basics: Code with HTML, CSS, and JavaScript\\nBusiness Course Esports Teams and Professional Players\\nComputer Science Guided Project Build a mobile app with Google Sheets on Glide and no coding\\nBusiness Guided Project Designing and Formatting a Presentation in PowerPoint\\nNote: A sample of courses in which learners’ included in the experiment graduated from.\\nA1'], reference_answer='The primary domain of the course \"Neural Networks and Deep Learning\" is Data Science, and the credential type is Course.', reference_answer_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>)),\n",
       " LabelledRagDataExample(query='**Answer:** The primary domain of the course \"Neural Networks and Deep Learning\" is Data Science, and the credential type is Course.', query_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>), reference_contexts=['Appendix\\nA Sample of courses included in the experiment\\nIn Table 7, we show a sample of 50 courses of 7355 from which the learners included in the experiment\\ngraduated.\\nTable 7: Sample of course included in the experiment\\nPrimary domain Credential Type Certificate Name\\nInformation Technology Course Fundamentos do Suporte Técnico\\nBusiness Guided Project Develop a Company Website with Wix\\nData Science Course SQL for Data Science\\nInformation Technology Course Fundamentals of Red Hat Enterprise Linux\\nData Science Course Neural Networks and Deep Learning\\nInformation Technology Course Introduction to Cloud Computing\\nInformation Technology Course AWS Cloud Practitioner Essentials\\nBusiness Course Capital-investissement et capital-risque\\nData Science Specialization Introduction to Data Science\\nBusiness Course Teamwork Skills: Communicating Effectively in Groups\\nInformation Technology Course Crash Course on Python\\nBusiness Course Excel Skills for Business: Advanced\\nData Science Guided Project Introduction to Business Analysis Using Spreadsheets: Basics\\nBusiness Course Foundations of Project Management\\nBusiness Course Assess for Success: Marketing Analytics and Measurement\\nBusiness Course Bookkeeping Basics\\nComputer Science Course Introduction to Front-End Development\\nBusiness Guided Project Create a Project Charter with Google Docs\\nData Science Professional Certificate Google Data Analytics\\nInformation Technology Course Technical Support Fundamentals\\nComputer Science Course Python Programming: A Concise Introduction\\nInformation Technology Course Introduction to Web Development with HTML, CSS, JavaScript\\nComputer Science Guided Project Get Started with Figma\\nComputer Science Course Foundations of User Experience (UX) Design\\nComputer Science Course Programming for Everybody (Getting Started with Python)\\nData Science Professional Certificate IBM Data Analyst\\nComputer Science Course JavaScript Basics\\nBusiness Course Foundations of Digital Marketing and E-commerce\\nData Science Course Foundations: Data, Data, Everywhere\\nInformation Technology Course AWS Cloud Technical Essentials\\nComputer Science Course Blockchain: Foundations and Use Cases\\nComputer Science Course HTML, CSS, and Javascript for Web Developers\\nBusiness Course Developing Innovative Ideas for Product Leaders\\nBusiness Guided Project Introduction to Microsoft Excel\\nBusiness Course Construction Project Management\\nData Science Course Introduction to Genomic Technologies\\nInformation Technology Course Explore Core Data Concepts in Microsoft Azure\\nComputer Science Course Responsive Website Basics: Code with HTML, CSS, and JavaScript\\nBusiness Course Esports Teams and Professional Players\\nComputer Science Guided Project Build a mobile app with Google Sheets on Glide and no coding\\nBusiness Guided Project Designing and Formatting a Presentation in PowerPoint\\nNote: A sample of courses in which learners’ included in the experiment graduated from.\\nA1'], reference_answer='The primary domain of the course \"Neural Networks and Deep Learning\" is Data Science, and the credential type is Course.', reference_answer_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>)),\n",
       " LabelledRagDataExample(query='Question: How is the \"Current Enrollment in Educational Program\" feature determined in the LinkedIn feature engineering process?', query_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>), reference_contexts=['A.1 LinkedIn Feature Engineering\\n• Current Enrollment in Educational Program: This binary feature is set to TRUE if the end date\\nof the participant’s educational program is later than 2022. It is important to note that only the\\nyear of the start and end dates of the educational programs are available in our dataset.\\n• Level of Education: This categorical feature classifies the participant’s highest level of education\\nbased on keywords found in the title of their degree. The classifications are as follows:\\n– Master’s Degree: Identified through keywords such as ’master’, ’msc’, ’maestría’, or ’ma’.\\n– Bachelor’s Degree: Identified through keywords like ’bsc’, ’bs’, ’bachillerato’, or ’bachelor’.\\n– Doctor’s Degree:Identified through keywords such as ’doctor’, ’doutorado’, or ’docteur’.\\n– Degree: This is marked as TRUE if any of the above conditions are satisfied.\\n• University Ranking of the Latest Academic Degree : Utilizing the national rankings provided\\nby a public Kaggle dataset (https://www.kaggle.com/datasets/mylesoneill/world-\\nuniversity-rankings), we assigned rankings based on the latest available data, predomi-\\nnantly from 2015. Note that rankings may vary annually, and institutions may hold different\\npositions in different years.\\n• Years Since Latest Academic Degree : This feature calculates the difference in years between\\n2023 and the year of the participant’s most recent academic degree. If the result is negative,\\nindicating that the participant has not yet graduated, the value is set to 0.\\nAdditionally, to discern career outcomes from the LinkedIn scraped data, the following method-\\nology was applied:\\n1. Internship Identification : Initially, we extracted the current job position from the profile to\\nascertain whether the term “Intern” was present, which would indicate an internship role.\\n2. Time Difference Calculation : Subsequently, we calculated the time difference in months be-\\ntween the start date of the most recent experience and September 2022, when our experiment\\nstarted.\\n3. Career Outcome Determination : Based on the computed time difference, we categorized the\\ncareer outcomes as follows:\\nA2'], reference_answer='The \"Current Enrollment in Educational Program\" feature is determined by checking if the end date of the participant’s educational program is later than 2022. This feature is set to TRUE if the end date is beyond 2022. The dataset only provides the year of the start and end dates of the educational programs.', reference_answer_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>)),\n",
       " LabelledRagDataExample(query='Answer: The \"Current Enrollment in Educational Program\" feature is determined as a binary feature set to TRUE if the end date of the participant\\'s educational program is later than 2022. This determination is based solely on the year of the start and end dates of the educational programs available in the dataset.', query_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>), reference_contexts=['A.1 LinkedIn Feature Engineering\\n• Current Enrollment in Educational Program: This binary feature is set to TRUE if the end date\\nof the participant’s educational program is later than 2022. It is important to note that only the\\nyear of the start and end dates of the educational programs are available in our dataset.\\n• Level of Education: This categorical feature classifies the participant’s highest level of education\\nbased on keywords found in the title of their degree. The classifications are as follows:\\n– Master’s Degree: Identified through keywords such as ’master’, ’msc’, ’maestría’, or ’ma’.\\n– Bachelor’s Degree: Identified through keywords like ’bsc’, ’bs’, ’bachillerato’, or ’bachelor’.\\n– Doctor’s Degree:Identified through keywords such as ’doctor’, ’doutorado’, or ’docteur’.\\n– Degree: This is marked as TRUE if any of the above conditions are satisfied.\\n• University Ranking of the Latest Academic Degree : Utilizing the national rankings provided\\nby a public Kaggle dataset (https://www.kaggle.com/datasets/mylesoneill/world-\\nuniversity-rankings), we assigned rankings based on the latest available data, predomi-\\nnantly from 2015. Note that rankings may vary annually, and institutions may hold different\\npositions in different years.\\n• Years Since Latest Academic Degree : This feature calculates the difference in years between\\n2023 and the year of the participant’s most recent academic degree. If the result is negative,\\nindicating that the participant has not yet graduated, the value is set to 0.\\nAdditionally, to discern career outcomes from the LinkedIn scraped data, the following method-\\nology was applied:\\n1. Internship Identification : Initially, we extracted the current job position from the profile to\\nascertain whether the term “Intern” was present, which would indicate an internship role.\\n2. Time Difference Calculation : Subsequently, we calculated the time difference in months be-\\ntween the start date of the most recent experience and September 2022, when our experiment\\nstarted.\\n3. Career Outcome Determination : Based on the computed time difference, we categorized the\\ncareer outcomes as follows:\\nA2'], reference_answer='True. The \"Current Enrollment in Educational Program\" feature is indeed determined as a binary feature set to TRUE if the end date of the participant\\'s educational program is later than 2022, based solely on the year of the start and end dates available in the dataset.', reference_answer_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>)),\n",
       " LabelledRagDataExample(query='Question: Based on the criteria outlined for analyzing career development, how would you classify a situation where an individual\\'s current job title includes \"Intern\" and the time difference between their previous and current job is greater than or equal to 0 months?', query_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>), reference_contexts=['• If the time difference is greater than or equal to 0 months, it implies a recent career devel-\\nopment, leading to further analysis:\\n– If “Intern” is found in the current job title, the outcome is classified as a new internship.\\n– If the employer of the current job differs from the employer of the previous job, it\\nindicates a change in job roles, leading to the classification of new job.\\n– Otherwise, the outcome is classified as a promotion.\\nB Descriptive statistics\\nTable 8 presents summary statistics for the covariates provided by the Coursera internal dataset.\\nA3'], reference_answer='The situation would be classified as a new internship.', reference_answer_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>)),\n",
       " LabelledRagDataExample(query='Answer: If an individual\\'s current job title includes \"Intern\" and the time difference between their previous and current job is greater than or equal to 0 months, the situation would be classified as a new internship.', query_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>), reference_contexts=['• If the time difference is greater than or equal to 0 months, it implies a recent career devel-\\nopment, leading to further analysis:\\n– If “Intern” is found in the current job title, the outcome is classified as a new internship.\\n– If the employer of the current job differs from the employer of the previous job, it\\nindicates a change in job roles, leading to the classification of new job.\\n– Otherwise, the outcome is classified as a promotion.\\nB Descriptive statistics\\nTable 8 presents summary statistics for the covariates provided by the Coursera internal dataset.\\nA3'], reference_answer='Yes, if an individual\\'s current job title includes \"Intern\" and the time difference between their previous and current job is greater than or equal to 0 months, the situation would be classified as a new internship.', reference_answer_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>)),\n",
       " LabelledRagDataExample(query='**Question:** Based on the summary statistics provided in Table 8, which primary domain has the highest mean value among Coursera participants, and what is that mean value?', query_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>), reference_contexts=['Table 8: Summary Statistics for Internal Coursera Covariates\\nVariable Group Count Min Max Mean SD\\ngender unknown 470459 0.00 1.00 0.53 0.50\\ngender male 269836 0.00 1.00 0.30 0.46\\ngender female 146897 0.00 1.00 0.17 0.37\\ngender other 1027 0.00 1.00 0.00 0.03\\neducation level unknown 570268 0.00 1.00 0.64 0.48\\neducation level associate degree 25298 0.00 1.00 0.03 0.17\\neducation level masters degree 44975 0.00 1.00 0.05 0.22\\neducation level bachelor degree 114926 0.00 1.00 0.13 0.34\\neducation level professional degree 3540 0.00 1.00 0.00 0.06\\neducation level college no degree 64078 0.00 1.00 0.07 0.26\\neducation level high school diploma 53155 0.00 1.00 0.06 0.24\\neducation level doctorate degree 3963 0.00 1.00 0.00 0.07\\neducation level less than high school diploma 8016 0.00 1.00 0.01 0.09\\nprimary domain business 330462 0.00 1.00 0.37 0.48\\nprimary domain data science 208819 0.00 1.00 0.24 0.42\\nprimary domain computer science 222335 0.00 1.00 0.25 0.43\\nprimary domain information technology 126603 0.00 1.00 0.14 0.35\\ncredential type course 727602 0.00 1.00 0.82 0.38\\ncredential type guided project 147540 0.00 1.00 0.17 0.37\\ncredential type specialization 8278 0.00 1.00 0.01 0.10\\ncredential type professional certificate 4799 0.00 1.00 0.01 0.07\\ndeveloped country - 888219 0.00 1.00 0.10 0.30\\ncertificate has page views - 888219 0.00 1.00 0.20 0.40\\ncertificate has page views from linkedin - 888219 0.00 1.00 0.17 0.38\\ncount all views - 888219 0.00 726.00 0.71 3.09\\ncount all views not by user - 888219 0.00 725.00 0.60 3.03\\ncount linkedin views - 888219 0.00 411.00 0.58 2.37\\ncount linkedin views not by user - 888219 0.00 411.00 0.49 2.31\\nhas degree linkedin - 20396 0.00 1.00 0.62 0.48\\nhas bachelor linkedin - 20396 0.00 1.00 0.43 0.49\\nhas master linkedin - 20396 0.00 1.00 0.18 0.38\\nhas doctor linkedin - 20396 0.00 1.00 0.02 0.13\\nyearsSinceEnrollment - 20396 0.00 46.00 3.97 5.43\\nnew internship linkedin - 20396 0.00 1.00 0.05 0.22\\nnew job linkedin - 20396 0.00 1.00 0.31 0.46\\npromotion linkedin - 20396 0.00 1.00 0.08 0.27\\nnew job or promotion linkedin - 20396 0.00 1.00 0.39 0.49\\nany outcome linkedin - 20396 0.00 1.00 0.44 0.50\\nB.1 Balance check analysis\\nTable 9 presents a balance check analysis for the total population of the experiment participants. Re-\\nsults show no significant differences between treatment and control groups.\\nA4'], reference_answer='The primary domain with the highest mean value among Coursera participants is \"business,\" with a mean value of 0.37.', reference_answer_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>)),\n",
       " LabelledRagDataExample(query='**Answer:** The primary domain with the highest mean value among Coursera participants is \"business,\" with a mean value of 0.37.', query_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>), reference_contexts=['Table 8: Summary Statistics for Internal Coursera Covariates\\nVariable Group Count Min Max Mean SD\\ngender unknown 470459 0.00 1.00 0.53 0.50\\ngender male 269836 0.00 1.00 0.30 0.46\\ngender female 146897 0.00 1.00 0.17 0.37\\ngender other 1027 0.00 1.00 0.00 0.03\\neducation level unknown 570268 0.00 1.00 0.64 0.48\\neducation level associate degree 25298 0.00 1.00 0.03 0.17\\neducation level masters degree 44975 0.00 1.00 0.05 0.22\\neducation level bachelor degree 114926 0.00 1.00 0.13 0.34\\neducation level professional degree 3540 0.00 1.00 0.00 0.06\\neducation level college no degree 64078 0.00 1.00 0.07 0.26\\neducation level high school diploma 53155 0.00 1.00 0.06 0.24\\neducation level doctorate degree 3963 0.00 1.00 0.00 0.07\\neducation level less than high school diploma 8016 0.00 1.00 0.01 0.09\\nprimary domain business 330462 0.00 1.00 0.37 0.48\\nprimary domain data science 208819 0.00 1.00 0.24 0.42\\nprimary domain computer science 222335 0.00 1.00 0.25 0.43\\nprimary domain information technology 126603 0.00 1.00 0.14 0.35\\ncredential type course 727602 0.00 1.00 0.82 0.38\\ncredential type guided project 147540 0.00 1.00 0.17 0.37\\ncredential type specialization 8278 0.00 1.00 0.01 0.10\\ncredential type professional certificate 4799 0.00 1.00 0.01 0.07\\ndeveloped country - 888219 0.00 1.00 0.10 0.30\\ncertificate has page views - 888219 0.00 1.00 0.20 0.40\\ncertificate has page views from linkedin - 888219 0.00 1.00 0.17 0.38\\ncount all views - 888219 0.00 726.00 0.71 3.09\\ncount all views not by user - 888219 0.00 725.00 0.60 3.03\\ncount linkedin views - 888219 0.00 411.00 0.58 2.37\\ncount linkedin views not by user - 888219 0.00 411.00 0.49 2.31\\nhas degree linkedin - 20396 0.00 1.00 0.62 0.48\\nhas bachelor linkedin - 20396 0.00 1.00 0.43 0.49\\nhas master linkedin - 20396 0.00 1.00 0.18 0.38\\nhas doctor linkedin - 20396 0.00 1.00 0.02 0.13\\nyearsSinceEnrollment - 20396 0.00 46.00 3.97 5.43\\nnew internship linkedin - 20396 0.00 1.00 0.05 0.22\\nnew job linkedin - 20396 0.00 1.00 0.31 0.46\\npromotion linkedin - 20396 0.00 1.00 0.08 0.27\\nnew job or promotion linkedin - 20396 0.00 1.00 0.39 0.49\\nany outcome linkedin - 20396 0.00 1.00 0.44 0.50\\nB.1 Balance check analysis\\nTable 9 presents a balance check analysis for the total population of the experiment participants. Re-\\nsults show no significant differences between treatment and control groups.\\nA4'], reference_answer='The primary domain with the highest mean value among Coursera participants is \"business,\" with a mean value of 0.37.', reference_answer_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>)),\n",
       " LabelledRagDataExample(query='**Question:** Based on Table 9, what is the mean difference in the \"no_education_mentioned\" variable between the treatment and control groups, and what does this suggest about the balance of this covariate?', query_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>), reference_contexts=['Table 9: Covariate balance between treatment and control\\nVariable Mean Difference Standard Error Treatment Mean Control Mean Treatment N Control N\\nfirst_skill_score_1 3e-04 0.0014 0.1002 0.0999 381815 383801\\nfirst_skill_score_3 0 1e-04 0 0 381815 383801\\nassociate_degree 3e-04 4e-04 0.029 0.0287 381815 383801\\nbachelor_degree -8e-04 8e-04 0.1269 0.1278 381815 383801\\nsome_college -5e-04 6e-04 0.0721 0.0726 381815 383801\\ndoctorate_degree -2e-04 2e-04 0.0043 0.0045 381815 383801\\nhigh_school_diploma -4e-04 5e-04 0.0592 0.0596 381815 383801\\nless_than_high_school 0 2e-04 0.0089 0.009 381815 383801\\nmasters_degree -7e-04 5e-04 0.0496 0.0503 381815 383801\\nno_education_mentioned 0.0022 0.0011 0.6458 0.6436 381815 383801\\nprofessional_degree 2e-04 1e-04 0.0041 0.0038 381815 383801\\nmale -8e-04 0.001 0.3014 0.3022 381815 383801\\ngender_not_mentioned 9e-04 0.0011 0.5336 0.5328 381815 383801\\nprimary_domain_computer_science 0.0015 0.001 0.2529 0.2514 381815 383801\\nprimary_domain_data_science -0.001 0.001 0.2353 0.2363 381815 383801\\nprimary_domain_information_technology -6e-04 8e-04 0.1398 0.1404 381815 383801\\ncredential_type_guided_project 1e-04 9e-04 0.1679 0.1678 381815 383801\\ncredential_type_professional_certificate -1e-04 2e-04 0.0054 0.0055 381815 383801\\ncredential_type_specialization -3e-04 2e-04 0.0084 0.0087 381815 383801\\ndeveloping_country 5e-04 7e-04 0.8962 0.8957 381815 383801\\nprofessional_exp_years 0.0464 0.0609 3.6122 3.5658 18487 18459\\npast_business_job -0.0014 0.0026 0.0641 0.0655 18487 18459\\npast_tech_job 0.0034 0.0035 0.1308 0.1274 18487 18459\\nNote: Averages of covariate values across treatment and control groups.\\nC Impact of Credential Feature on Credential Sharing\\nPanel A of Table 10 presents the average treatment effect estimates on credential sharing per batch. We\\ncan observe differences in the baseline shares of learners who shared their credentials, as well as in the\\naverage treatment effect estimates. Notably, the final batch exhibited a significantly lower treatment\\neffect compared to other batches. Various factors may contribute to these discrepancies, including\\nthe baseline propensity to respond to treatment and the number of learners effectively exposed to the\\ntreatment.\\nNotifications aimed at encouraging credential sharing were displayed within the Coursera apps,\\nhence only those learners who logged into the platform post-randomization were targeted. The per-\\ncentage of learners who did so varied, with the second batch having the highest share (96%) and the\\nfinal batch having the lowest share (82%). Furthermore, in instances where Coursera was sending\\nadditional notifications to learners, depending on their priority level, they might be shown before our\\nnotifications. In such cases, treated learners would encounter the notification during their subsequent\\nvisit to the Coursera app.'], reference_answer='The mean difference in the \"no_education_mentioned\" variable between the treatment and control groups is 0.0022. This suggests that there is a slight imbalance in this covariate between the treatment and control groups, with the treatment group having a slightly higher mean for this variable.', reference_answer_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>)),\n",
       " LabelledRagDataExample(query='**Answer:** The mean difference in the \"no_education_mentioned\" variable between the treatment and control groups is 0.0022. This suggests that there is a slight imbalance in this covariate, with the treatment group having a marginally higher mean than the control group. However, given the small magnitude of the difference, it may not be practically significant.', query_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>), reference_contexts=['Table 9: Covariate balance between treatment and control\\nVariable Mean Difference Standard Error Treatment Mean Control Mean Treatment N Control N\\nfirst_skill_score_1 3e-04 0.0014 0.1002 0.0999 381815 383801\\nfirst_skill_score_3 0 1e-04 0 0 381815 383801\\nassociate_degree 3e-04 4e-04 0.029 0.0287 381815 383801\\nbachelor_degree -8e-04 8e-04 0.1269 0.1278 381815 383801\\nsome_college -5e-04 6e-04 0.0721 0.0726 381815 383801\\ndoctorate_degree -2e-04 2e-04 0.0043 0.0045 381815 383801\\nhigh_school_diploma -4e-04 5e-04 0.0592 0.0596 381815 383801\\nless_than_high_school 0 2e-04 0.0089 0.009 381815 383801\\nmasters_degree -7e-04 5e-04 0.0496 0.0503 381815 383801\\nno_education_mentioned 0.0022 0.0011 0.6458 0.6436 381815 383801\\nprofessional_degree 2e-04 1e-04 0.0041 0.0038 381815 383801\\nmale -8e-04 0.001 0.3014 0.3022 381815 383801\\ngender_not_mentioned 9e-04 0.0011 0.5336 0.5328 381815 383801\\nprimary_domain_computer_science 0.0015 0.001 0.2529 0.2514 381815 383801\\nprimary_domain_data_science -0.001 0.001 0.2353 0.2363 381815 383801\\nprimary_domain_information_technology -6e-04 8e-04 0.1398 0.1404 381815 383801\\ncredential_type_guided_project 1e-04 9e-04 0.1679 0.1678 381815 383801\\ncredential_type_professional_certificate -1e-04 2e-04 0.0054 0.0055 381815 383801\\ncredential_type_specialization -3e-04 2e-04 0.0084 0.0087 381815 383801\\ndeveloping_country 5e-04 7e-04 0.8962 0.8957 381815 383801\\nprofessional_exp_years 0.0464 0.0609 3.6122 3.5658 18487 18459\\npast_business_job -0.0014 0.0026 0.0641 0.0655 18487 18459\\npast_tech_job 0.0034 0.0035 0.1308 0.1274 18487 18459\\nNote: Averages of covariate values across treatment and control groups.\\nC Impact of Credential Feature on Credential Sharing\\nPanel A of Table 10 presents the average treatment effect estimates on credential sharing per batch. We\\ncan observe differences in the baseline shares of learners who shared their credentials, as well as in the\\naverage treatment effect estimates. Notably, the final batch exhibited a significantly lower treatment\\neffect compared to other batches. Various factors may contribute to these discrepancies, including\\nthe baseline propensity to respond to treatment and the number of learners effectively exposed to the\\ntreatment.\\nNotifications aimed at encouraging credential sharing were displayed within the Coursera apps,\\nhence only those learners who logged into the platform post-randomization were targeted. The per-\\ncentage of learners who did so varied, with the second batch having the highest share (96%) and the\\nfinal batch having the lowest share (82%). Furthermore, in instances where Coursera was sending\\nadditional notifications to learners, depending on their priority level, they might be shown before our\\nnotifications. In such cases, treated learners would encounter the notification during their subsequent\\nvisit to the Coursera app.'], reference_answer='The mean difference in the \"no_education_mentioned\" variable between the treatment and control groups is indeed 0.0022. This indicates a slight imbalance in this covariate, with the treatment group having a marginally higher mean than the control group. However, considering the small magnitude of the difference, it may not be practically significant.', reference_answer_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>)),\n",
       " LabelledRagDataExample(query='**Question:** What factors might contribute to the discrepancies in the treatment effect estimates observed across different batches of learners in the study on credential sharing?', query_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>), reference_contexts=['We\\ncan observe differences in the baseline shares of learners who shared their credentials, as well as in the\\naverage treatment effect estimates. Notably, the final batch exhibited a significantly lower treatment\\neffect compared to other batches. Various factors may contribute to these discrepancies, including\\nthe baseline propensity to respond to treatment and the number of learners effectively exposed to the\\ntreatment.\\nNotifications aimed at encouraging credential sharing were displayed within the Coursera apps,\\nhence only those learners who logged into the platform post-randomization were targeted. The per-\\ncentage of learners who did so varied, with the second batch having the highest share (96%) and the\\nfinal batch having the lowest share (82%). Furthermore, in instances where Coursera was sending\\nadditional notifications to learners, depending on their priority level, they might be shown before our\\nnotifications. In such cases, treated learners would encounter the notification during their subsequent\\nvisit to the Coursera app. Panel B of Table 10 illustrates the average treatment effect on credential\\nsharing limited to learners who logged into the app post-randomization (the restriction is applied to\\nboth treatment and control groups). We observe a higher treatment effect across all batches, including\\nA5'], reference_answer=\"The discrepancies in the treatment effect estimates observed across different batches of learners in the study on credential sharing might be attributed to several factors. These include:\\n\\n1. **Baseline Propensity to Respond to Treatment:** Differences in the initial likelihood of learners to respond to the treatment could affect the observed treatment effects across batches.\\n\\n2. **Number of Learners Exposed to Treatment:** Variations in the number of learners who were effectively exposed to the treatment could lead to differences in treatment effect estimates.\\n\\n3. **Percentage of Learners Logging into the Platform:** The percentage of learners who logged into the Coursera platform post-randomization varied across batches, with the second batch having the highest share (96%) and the final batch having the lowest share (82%). This variation could influence the treatment effect.\\n\\n4. **Additional Notifications from Coursera:** In cases where Coursera sent additional notifications to learners, these might have been shown before the study's notifications, potentially affecting the timing and impact of the treatment.\", reference_answer_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>)),\n",
       " LabelledRagDataExample(query='**Answer:** The discrepancies in the treatment effect estimates across different batches of learners could be attributed to several factors, including the baseline propensity of learners to respond to the treatment and the number of learners effectively exposed to the treatment. Additionally, the percentage of learners who logged into the Coursera app post-randomization varied between batches, with the second batch having the highest share (96%) and the final batch having the lowest share (82%). Furthermore, the presence of additional notifications from Coursera, depending on their priority level, might have affected the visibility and timing of the treatment notifications, potentially influencing the treatment effect.', query_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>), reference_contexts=['We\\ncan observe differences in the baseline shares of learners who shared their credentials, as well as in the\\naverage treatment effect estimates. Notably, the final batch exhibited a significantly lower treatment\\neffect compared to other batches. Various factors may contribute to these discrepancies, including\\nthe baseline propensity to respond to treatment and the number of learners effectively exposed to the\\ntreatment.\\nNotifications aimed at encouraging credential sharing were displayed within the Coursera apps,\\nhence only those learners who logged into the platform post-randomization were targeted. The per-\\ncentage of learners who did so varied, with the second batch having the highest share (96%) and the\\nfinal batch having the lowest share (82%). Furthermore, in instances where Coursera was sending\\nadditional notifications to learners, depending on their priority level, they might be shown before our\\nnotifications. In such cases, treated learners would encounter the notification during their subsequent\\nvisit to the Coursera app. Panel B of Table 10 illustrates the average treatment effect on credential\\nsharing limited to learners who logged into the app post-randomization (the restriction is applied to\\nboth treatment and control groups). We observe a higher treatment effect across all batches, including\\nA5'], reference_answer='The discrepancies in the treatment effect estimates across different batches of learners could be attributed to several factors, including the baseline propensity of learners to respond to the treatment and the number of learners effectively exposed to the treatment. Additionally, the percentage of learners who logged into the Coursera app post-randomization varied between batches, with the second batch having the highest share (96%) and the final batch having the lowest share (82%). Furthermore, the presence of additional notifications from Coursera, depending on their priority level, might have affected the visibility and timing of the treatment notifications, potentially influencing the treatment effect.', reference_answer_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>)),\n",
       " LabelledRagDataExample(query='Question: Based on Table 10 in the provided context, which batch in Panel A showed the highest average treatment effect (ATE) percentage for the Credential Feature on Credential Shared?', query_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>), reference_contexts=['batch 5, compared to the unrestricted sample.\\nTable 10: Average treatment effect of Credential Feature on Credential Shared by Batch\\nBatch Mean Control Mean Treatment ATE ATE (%)\\nPanel A: LinkedIn Matched Sample\\n1 17.832 20.074 2.242 12.571\\n(0.617) (0.650) (0.896) (5.025)\\n2 14.992 18.255 3.262 21.759\\n(0.569) (0.601) (0.828) (5.521)\\n3 16.398 19.382 2.984 18.196\\n(0.579) (0.627) (0.853) (5.203)\\n4 17.533 21.794 4.261 24.303\\n(0.616) (0.669) (0.909) (5.185)\\n5 16.546 18.123 1.577 9.528\\n(0.706) (0.732) (1.017) (6.147)\\nPanel B: Sample of learners that logged in after randomization\\n1 18.007 20.203 2.195 12.191\\n(0.623) (0.655) (0.904) (5.022)\\n2 15.259 18.679 3.420 22.410\\n(0.579) (0.614) (0.844) (5.531)\\n3 16.853 19.917 3.064 18.183\\n(0.596) (0.644) (0.877) (5.206)\\n4 17.749 22.292 4.543 25.594\\n(0.628) (0.686) (0.930) (5.241)\\n5 16.829 18.581 1.752 10.411\\n(0.724) (0.754) (1.045) (6.211)\\nNote: Estimates of the average treatment effect obtained using a difference-in-means estimator. Standard errors in parentheses.\\nD Correlation between views and new jobs\\nTable 11 shows the estimates from the linear probability regressions of New job on the four types of\\ncredential views using LinkedIn Matched Sample. We find that there is a strong correlation between\\nreceiving credential views and reporting a new job.\\nA6'], reference_answer='Based on Table 10 in the provided context, Batch 4 in Panel A showed the highest average treatment effect (ATE) percentage for the Credential Feature on Credential Shared, with an ATE of 24.303%.', reference_answer_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>)),\n",
       " LabelledRagDataExample(query='Answer: In Panel A of Table 10, Batch 4 showed the highest average treatment effect (ATE) percentage for the Credential Feature on Credential Shared, with an ATE of 24.303%.', query_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>), reference_contexts=['batch 5, compared to the unrestricted sample.\\nTable 10: Average treatment effect of Credential Feature on Credential Shared by Batch\\nBatch Mean Control Mean Treatment ATE ATE (%)\\nPanel A: LinkedIn Matched Sample\\n1 17.832 20.074 2.242 12.571\\n(0.617) (0.650) (0.896) (5.025)\\n2 14.992 18.255 3.262 21.759\\n(0.569) (0.601) (0.828) (5.521)\\n3 16.398 19.382 2.984 18.196\\n(0.579) (0.627) (0.853) (5.203)\\n4 17.533 21.794 4.261 24.303\\n(0.616) (0.669) (0.909) (5.185)\\n5 16.546 18.123 1.577 9.528\\n(0.706) (0.732) (1.017) (6.147)\\nPanel B: Sample of learners that logged in after randomization\\n1 18.007 20.203 2.195 12.191\\n(0.623) (0.655) (0.904) (5.022)\\n2 15.259 18.679 3.420 22.410\\n(0.579) (0.614) (0.844) (5.531)\\n3 16.853 19.917 3.064 18.183\\n(0.596) (0.644) (0.877) (5.206)\\n4 17.749 22.292 4.543 25.594\\n(0.628) (0.686) (0.930) (5.241)\\n5 16.829 18.581 1.752 10.411\\n(0.724) (0.754) (1.045) (6.211)\\nNote: Estimates of the average treatment effect obtained using a difference-in-means estimator. Standard errors in parentheses.\\nD Correlation between views and new jobs\\nTable 11 shows the estimates from the linear probability regressions of New job on the four types of\\ncredential views using LinkedIn Matched Sample. We find that there is a strong correlation between\\nreceiving credential views and reporting a new job.\\nA6'], reference_answer='True. In Panel A of Table 10, Batch 4 indeed showed the highest average treatment effect (ATE) percentage for the Credential Feature on Credential Shared, with an ATE of 24.303%.', reference_answer_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>)),\n",
       " LabelledRagDataExample(query='**Question:** Based on the data presented in Table 11, what can be inferred about the relationship between obtaining a new job and the number of views on LinkedIn?', query_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>), reference_contexts=['Table 11: Correlation between views and new jobs\\nDependent variable:\\nAll views All views by others Views LinkedIn Views LinkedIn by others\\n(1) (2) (3) (4)\\nNew job 0.513 ∗∗∗ 0.400∗∗∗ 0.497∗∗∗ 0.379∗∗∗\\n(0.008) (0.007) (0.007) (0.006)\\nObservations 36,946 36,946 36,946 36,946\\nR2 0.109 0.090 0.107 0.086\\nAdjusted R2 0.109 0.090 0.107 0.086\\nResidual Std. Error (df = 36945) 0.618 0.538 0.604 0.520\\nF Statistic (df = 1; 36945) 4,538.226 ∗∗∗ 3,641.660∗∗∗ 4,446.666∗∗∗ 3,492.890∗∗∗\\nNote: ∗p<0.1;∗∗p<0.05;∗∗∗p<0.01\\nNote: Estimate from linear probability models regressing new jobs on the four types of views outcomes. Estimates based on the LinkedIn\\nMatched Sample.\\nE Local average treatment effect across deciles\\nTo analyze the impact of Credential Shared across various levels of employability as predicted by our\\nmodels, we predict baseline employability using a Gradient Boosting Machine (GBM) with cross-\\nfitting on a LinkedIn Matched Sample. The GBM was trained on nine of these folds to predict em-\\nployability scores, which were then utilized to assign each observation into deciles based on predicted\\nemployability levels. Next, we compute indicators of deciles of baseline employability.\\nUsing these declines, we estimate LATE within the groups defined by cumulative deciles (e.g.,\\nthe first model includes only the lowest decile, the second model spans the first and second deciles,\\netc.). Results are presented in Figure 3. Our analysis shows a higher LATE in the two lowest deciles,\\nsuggesting that interventions might be most effective within these groups.\\nA7'], reference_answer='Based on the data presented in Table 11, it can be inferred that there is a positive correlation between obtaining a new job and the number of views on LinkedIn. Specifically, the coefficients for \"New job\" in relation to \"Views LinkedIn\" and \"Views LinkedIn by others\" are 0.497 and 0.379, respectively, both of which are statistically significant at the 0.01 level (indicated by the ***). This suggests that obtaining a new job is associated with an increase in the number of LinkedIn views, both overall and by others.', reference_answer_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>)),\n",
       " LabelledRagDataExample(query='**Answer:** The data in Table 11 indicates a positive correlation between obtaining a new job and the number of views on LinkedIn. Specifically, the coefficients for \"New job\" in columns (3) and (4) are 0.497 and 0.379, respectively, both statistically significant at the 0.01 level. This suggests that obtaining a new job is associated with an increase in LinkedIn views, both overall and by others.', query_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>), reference_contexts=['Table 11: Correlation between views and new jobs\\nDependent variable:\\nAll views All views by others Views LinkedIn Views LinkedIn by others\\n(1) (2) (3) (4)\\nNew job 0.513 ∗∗∗ 0.400∗∗∗ 0.497∗∗∗ 0.379∗∗∗\\n(0.008) (0.007) (0.007) (0.006)\\nObservations 36,946 36,946 36,946 36,946\\nR2 0.109 0.090 0.107 0.086\\nAdjusted R2 0.109 0.090 0.107 0.086\\nResidual Std. Error (df = 36945) 0.618 0.538 0.604 0.520\\nF Statistic (df = 1; 36945) 4,538.226 ∗∗∗ 3,641.660∗∗∗ 4,446.666∗∗∗ 3,492.890∗∗∗\\nNote: ∗p<0.1;∗∗p<0.05;∗∗∗p<0.01\\nNote: Estimate from linear probability models regressing new jobs on the four types of views outcomes. Estimates based on the LinkedIn\\nMatched Sample.\\nE Local average treatment effect across deciles\\nTo analyze the impact of Credential Shared across various levels of employability as predicted by our\\nmodels, we predict baseline employability using a Gradient Boosting Machine (GBM) with cross-\\nfitting on a LinkedIn Matched Sample. The GBM was trained on nine of these folds to predict em-\\nployability scores, which were then utilized to assign each observation into deciles based on predicted\\nemployability levels. Next, we compute indicators of deciles of baseline employability.\\nUsing these declines, we estimate LATE within the groups defined by cumulative deciles (e.g.,\\nthe first model includes only the lowest decile, the second model spans the first and second deciles,\\netc.). Results are presented in Figure 3. Our analysis shows a higher LATE in the two lowest deciles,\\nsuggesting that interventions might be most effective within these groups.\\nA7'], reference_answer='The data in Table 11 indicates a positive correlation between obtaining a new job and the number of views on LinkedIn. Specifically, the coefficients for \"New job\" in columns (3) and (4) are 0.497 and 0.379, respectively, both statistically significant at the 0.01 level. This suggests that obtaining a new job is associated with an increase in LinkedIn views, both overall and by others.', reference_answer_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>)),\n",
       " LabelledRagDataExample(query='Question: What does Figure 3 in the document \"non_traditional_credentials.pdf\" illustrate regarding the Local Average Treatment Effects?', query_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>), reference_contexts=['Figure 3: Conditional Local Average Treatment Effects\\nNote: Estimates of the Local Average Treatment Effects of sharing the credential conditional on the baseline level of employability.\\nEstimates from models estimated with data on learners with an increasing baseline employability.\\nA8'], reference_answer='Figure 3 in the document \"non_traditional_credentials.pdf\" illustrates the Conditional Local Average Treatment Effects of sharing the credential, based on the baseline level of employability. It provides estimates from models that are estimated using data on learners with an increasing baseline employability.', reference_answer_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>)),\n",
       " LabelledRagDataExample(query='Answer: Figure 3 illustrates the Conditional Local Average Treatment Effects of sharing the credential, specifically conditional on the baseline level of employability. It provides estimates from models that are based on data from learners with an increasing baseline employability.', query_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>), reference_contexts=['Figure 3: Conditional Local Average Treatment Effects\\nNote: Estimates of the Local Average Treatment Effects of sharing the credential conditional on the baseline level of employability.\\nEstimates from models estimated with data on learners with an increasing baseline employability.\\nA8'], reference_answer='Figure 3 illustrates the Conditional Local Average Treatment Effects of sharing the credential, specifically conditional on the baseline level of employability. It provides estimates from models that are based on data from learners with an increasing baseline employability.', reference_answer_by=CreatedBy(model_name='gpt-4o', type=<CreatedByType.AI: 'ai'>))]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_dataset.examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8728935d",
   "metadata": {},
   "source": [
    "## Vanilla RAG Evaluation\n",
    "Before running any finetuning it's always important to run a vanilla RAG evaluation. That way we can quantify the gains from finetuning and ascertain if finetuning was even needed!\n",
    "\n",
    "In this case I host my LLM using Ollama (but you can use other providers such as Local LM, vLLM, etc.)\n",
    "> !ollama pull llama3.2:1b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62a59d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.ollama import Ollama\n",
    "\n",
    "llm = Ollama(model=\"llama3.2:1b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8986a9",
   "metadata": {},
   "source": [
    "Creating our RAG query engine\n",
    "> Seriously it's just one line. Thank you LlamaIndex for making this so easy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bef87208",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = VectorStoreIndex.from_documents(docs)\n",
    "query_engine = index.as_query_engine(similarity_top_k=6, llm=llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00472223",
   "metadata": {},
   "source": [
    "Now let's instiate our RAG Evaluator. The RagEvaluatorPack is a Llama Pack developed by amazing open sourced developers. It abstracts away the need to learn a new framework (RAGAS) while allowing you to do the exact same thing with just 1 line of code.\n",
    "\n",
    "> Pro-Tip: I always suggest using a stronger LLM (gpt-4o) to judge the LLM we are trying to finetune (Llama 3.2 1Bn). That way if our strong LLM thinks the finetuned LLM meets the mark, we'd have an LLM that punches far above its weight!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aeea84f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.packs.rag_evaluator import RagEvaluatorPack\n",
    "\n",
    "rag_evaluator = RagEvaluatorPack(\n",
    "    query_engine=query_engine, \n",
    "    rag_dataset=qa_dataset,\n",
    "    judge_llm=Settings.llm, #use the same llm that we use to create the dataset to judge\n",
    "    embed_model=Settings.embed_model\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9275b1a",
   "metadata": {},
   "source": [
    "This cell will take awhile! It took me 10 minutes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4a23fce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:48<00:00,  4.88s/it]\n",
      "100%|██████████| 10/10 [00:34<00:00,  3.48s/it]\n",
      "100%|██████████| 10/10 [00:47<00:00,  4.72s/it]\n",
      "100%|██████████| 4/4 [00:16<00:00,  4.17s/it]\n",
      "2it [00:07,  3.88s/it]\n",
      "2it [00:11,  5.59s/it]\n",
      "2it [00:09,  4.67s/it]\n",
      "2it [00:29, 14.73s/it]\n",
      "2it [00:09,  4.79s/it]\n",
      "2it [00:08,  4.44s/it]\n",
      "2it [00:07,  3.96s/it]\n",
      "2it [00:26, 13.34s/it]\n",
      "2it [00:08,  4.39s/it]\n",
      "2it [00:07,  3.93s/it]\n",
      "2it [00:15,  7.84s/it]\n",
      "2it [00:20, 10.08s/it]\n",
      "2it [00:13,  6.79s/it]\n",
      "2it [00:24, 12.03s/it]\n",
      "2it [00:08,  4.28s/it]\n",
      "2it [00:12,  6.16s/it]\n",
      "2it [00:09,  4.76s/it]\n",
      "2it [00:07,  3.90s/it]\n",
      "2it [00:21, 10.85s/it]\n",
      "2it [00:08,  4.48s/it]\n",
      "2it [00:08,  4.23s/it]\n",
      "2it [00:08,  4.28s/it]\n",
      "2it [00:08,  4.00s/it]\n",
      "2it [00:15,  7.76s/it]\n",
      "2it [00:08,  4.44s/it]\n",
      "2it [00:07,  3.69s/it]\n",
      "2it [00:07,  3.64s/it]\n",
      "2it [00:07,  3.97s/it]\n",
      "2it [00:16,  8.05s/it]\n",
      "2it [00:07,  3.68s/it]\n",
      "2it [00:09,  4.55s/it]\n",
      "2it [00:08,  4.31s/it]\n"
     ]
    }
   ],
   "source": [
    "benchmark_df = rag_evaluator.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2abadab6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>rag</th>\n",
       "      <th>base_rag</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metrics</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean_correctness_score</th>\n",
       "      <td>2.81250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_relevancy_score</th>\n",
       "      <td>0.68750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_faithfulness_score</th>\n",
       "      <td>0.87500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_context_similarity_score</th>\n",
       "      <td>0.95766</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "rag                            base_rag\n",
       "metrics                                \n",
       "mean_correctness_score          2.81250\n",
       "mean_relevancy_score            0.68750\n",
       "mean_faithfulness_score         0.87500\n",
       "mean_context_similarity_score   0.95766"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9cc3a1",
   "metadata": {},
   "source": [
    "This is not bad actually! Our LLM is actually performing quite well! Let's see if we can make it do better!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bdfe6e6",
   "metadata": {},
   "source": [
    "# Retrieval Augmented Finetuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4ef8f1",
   "metadata": {},
   "source": [
    "## Getting the RAFT dataset\n",
    "\n",
    "We start by generating the RAFT dataset - courtesy of yet another Llama pack!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f541fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.packs.raft_dataset import RAFTDatasetPack\n",
    "\n",
    "raft_dataset = RAFTDatasetPack(\n",
    "    file_path = \"../data/non_traditional_credentials.pdf\",\n",
    "    llm = Settings.llm,\n",
    "    embed_model=Settings.embed_model\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5b4f17",
   "metadata": {},
   "source": [
    "This cell takes quite long to run! Go have a coffee ☕\n",
    "> It took 19 minutes for the cell to finish running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e192e2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = raft_dataset.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d4c073",
   "metadata": {},
   "source": [
    "Let's take a look at what we did!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5a1f4bd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>type</th>\n",
       "      <th>question</th>\n",
       "      <th>context</th>\n",
       "      <th>oracle_context</th>\n",
       "      <th>cot_answer</th>\n",
       "      <th>instruction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>seed_task_0</td>\n",
       "      <td>general</td>\n",
       "      <td>What percentage increase in credential sharing...</td>\n",
       "      <td>{'sentences': [['The value of non-traditional ...</td>\n",
       "      <td>The value of non-traditional credentials in th...</td>\n",
       "      <td>assistant: To determine the percentage increas...</td>\n",
       "      <td>&lt;DOCUMENT&gt;The value of non-traditional credent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>seed_task_1</td>\n",
       "      <td>general</td>\n",
       "      <td>How much more likely were learners in the trea...</td>\n",
       "      <td>{'sentences': [['The control group did not rec...</td>\n",
       "      <td>The value of non-traditional credentials in th...</td>\n",
       "      <td>assistant: To answer the question \"How much mo...</td>\n",
       "      <td>&lt;DOCUMENT&gt;The control group did not receive th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>seed_task_2</td>\n",
       "      <td>general</td>\n",
       "      <td>What was the increase in jobs related to the c...</td>\n",
       "      <td>{'sentences': [['The value of non-traditional ...</td>\n",
       "      <td>The value of non-traditional credentials in th...</td>\n",
       "      <td>assistant: To determine the increase in jobs r...</td>\n",
       "      <td>&lt;DOCUMENT&gt;The value of non-traditional credent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>seed_task_3</td>\n",
       "      <td>general</td>\n",
       "      <td>Which group of LinkedIn users showed a more pr...</td>\n",
       "      <td>{'sentences': [['The value of non-traditional ...</td>\n",
       "      <td>The value of non-traditional credentials in th...</td>\n",
       "      <td>assistant: To determine which group of LinkedI...</td>\n",
       "      <td>&lt;DOCUMENT&gt;The value of non-traditional credent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>seed_task_4</td>\n",
       "      <td>general</td>\n",
       "      <td>What platform were the courses completed on fo...</td>\n",
       "      <td>{'sentences': [['Analogously, Past\n",
       "Managerial ...</td>\n",
       "      <td>The value of non-traditional credentials in th...</td>\n",
       "      <td>assistant: To answer the question \"What platfo...</td>\n",
       "      <td>&lt;DOCUMENT&gt;Analogously, Past\\nManagerial Job fo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id     type                                           question  \\\n",
       "0  seed_task_0  general  What percentage increase in credential sharing...   \n",
       "1  seed_task_1  general  How much more likely were learners in the trea...   \n",
       "2  seed_task_2  general  What was the increase in jobs related to the c...   \n",
       "3  seed_task_3  general  Which group of LinkedIn users showed a more pr...   \n",
       "4  seed_task_4  general  What platform were the courses completed on fo...   \n",
       "\n",
       "                                             context  \\\n",
       "0  {'sentences': [['The value of non-traditional ...   \n",
       "1  {'sentences': [['The control group did not rec...   \n",
       "2  {'sentences': [['The value of non-traditional ...   \n",
       "3  {'sentences': [['The value of non-traditional ...   \n",
       "4  {'sentences': [['Analogously, Past\n",
       "Managerial ...   \n",
       "\n",
       "                                      oracle_context  \\\n",
       "0  The value of non-traditional credentials in th...   \n",
       "1  The value of non-traditional credentials in th...   \n",
       "2  The value of non-traditional credentials in th...   \n",
       "3  The value of non-traditional credentials in th...   \n",
       "4  The value of non-traditional credentials in th...   \n",
       "\n",
       "                                          cot_answer  \\\n",
       "0  assistant: To determine the percentage increas...   \n",
       "1  assistant: To answer the question \"How much mo...   \n",
       "2  assistant: To determine the increase in jobs r...   \n",
       "3  assistant: To determine which group of LinkedI...   \n",
       "4  assistant: To answer the question \"What platfo...   \n",
       "\n",
       "                                         instruction  \n",
       "0  <DOCUMENT>The value of non-traditional credent...  \n",
       "1  <DOCUMENT>The control group did not receive th...  \n",
       "2  <DOCUMENT>The value of non-traditional credent...  \n",
       "3  <DOCUMENT>The value of non-traditional credent...  \n",
       "4  <DOCUMENT>Analogously, Past\\nManagerial Job fo...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(dataset)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0e60d1",
   "metadata": {},
   "source": [
    "Notice that the LLM also generated context, oracle_context and instruction along with just the question and the chain of thought answer. We'll be using these in crafting the final dataset to finetune our Llama 3.2 1Bn!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9b85ea48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<DOCUMENT>The value of non-traditional credentials in the labor market*\n",
       "Susan Athey & Emil Palikot\n",
       "May 2, 2024\n",
       "Abstract\n",
       "This study investigates the labor market value of credentials obtained from Massive Open On-\n",
       "line Courses (MOOCs) and shared on business networking platforms. We conducted a random-\n",
       "ized experiment involving more than 800,000 learners, primarily from developing countries and\n",
       "without college degrees, who completed technology or business-related courses on the Coursera\n",
       "platform between September 2022 and March 2023. The intervention targeted learners who had\n",
       "recently completed their courses, encouraging them to share their credentials and simplifying the\n",
       "sharing process. One year after the intervention, we collected data from LinkedIn profiles of ap-\n",
       "proximately 40,000 experimental subjects. We find that the intervention leads to an increase of 17\n",
       "percentage points for credential sharing. Further, learners in the treatment group were 6% more\n",
       "likely to report new employment within a year, with an 8% increase in jobs related to their certifi-\n",
       "cates. This effect was more pronounced among LinkedIn users with lower baseline employability.\n",
       "Across the entire sample, the treated group received a higher number of certificate views, indicat-\n",
       "ing an increased interest in their profiles. These results suggest that facilitating credential sharing\n",
       "and reminding learners of the value of skill signaling can yield significant gains. When the ex-\n",
       "periment is viewed as an encouragement design for credential sharing, we can estimate the local\n",
       "average treatment effect (LATE) of credential sharing (that is, the impact of credential sharing on\n",
       "the workers induced to share by the intervention) for the outcome of getting a job. The LATE esti-\n",
       "mates are imprecise but large in magnitude; they suggest that credential sharing more than doubles\n",
       "the baseline probability of getting a new job in scope for the credential.\n",
       "*We thank Eric Karsten and his team in Coursera for collaborating on this project. </DOCUMENT>\n",
       "<DOCUMENT>13 p.p.) and 36 p.p. (S.E. </DOCUMENT>\n",
       "<DOCUMENT>), which corresponds to a\n",
       "17% increase from baseline. The remaining columns present estimates from the instrumental variable\n",
       "regression with New Job and New Job in Scope as outcomes. In Columns 6, 7, and 8, we restrict attention\n",
       "to jobs reported with a starting date at least four months after treatment. We estimate positive and\n",
       "statistically significant effects. Specifically, we estimate the local average treatment effect of 0.24 (S.E.\n",
       "0.13) for any new job starting at least one month after treatment and 0.36 (S.E. 0.12) when restricting\n",
       "14</DOCUMENT>\n",
       "What percentage increase in credential sharing was observed after the intervention?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "display(Markdown(df.iloc[0]['instruction']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "08098b01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The value of non-traditional credentials in the labor market*\n",
       "Susan Athey & Emil Palikot\n",
       "May 2, 2024\n",
       "Abstract\n",
       "This study investigates the labor market value of credentials obtained from Massive Open On-\n",
       "line Courses (MOOCs) and shared on business networking platforms. We conducted a random-\n",
       "ized experiment involving more than 800,000 learners, primarily from developing countries and\n",
       "without college degrees, who completed technology or business-related courses on the Coursera\n",
       "platform between September 2022 and March 2023. The intervention targeted learners who had\n",
       "recently completed their courses, encouraging them to share their credentials and simplifying the\n",
       "sharing process. One year after the intervention, we collected data from LinkedIn profiles of ap-\n",
       "proximately 40,000 experimental subjects. We find that the intervention leads to an increase of 17\n",
       "percentage points for credential sharing. Further, learners in the treatment group were 6% more\n",
       "likely to report new employment within a year, with an 8% increase in jobs related to their certifi-\n",
       "cates. This effect was more pronounced among LinkedIn users with lower baseline employability.\n",
       "Across the entire sample, the treated group received a higher number of certificate views, indicat-\n",
       "ing an increased interest in their profiles. These results suggest that facilitating credential sharing\n",
       "and reminding learners of the value of skill signaling can yield significant gains. When the ex-\n",
       "periment is viewed as an encouragement design for credential sharing, we can estimate the local\n",
       "average treatment effect (LATE) of credential sharing (that is, the impact of credential sharing on\n",
       "the workers induced to share by the intervention) for the outcome of getting a job. The LATE esti-\n",
       "mates are imprecise but large in magnitude; they suggest that credential sharing more than doubles\n",
       "the baseline probability of getting a new job in scope for the credential.\n",
       "*We thank Eric Karsten and his team in Coursera for collaborating on this project. "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(df.iloc[0]['oracle_context']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b02a7419",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6bddf7b4fd1411eb08901dbb3ffddda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2966201"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save as .jsonl format\n",
    "dataset.to_json(\"raft_train.jsonl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231940bb",
   "metadata": {},
   "source": [
    "## Training the LLM\n",
    "We'll be using the amazing Unsloth framework to save VRAM resources and finish training faster!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d911efa",
   "metadata": {},
   "source": [
    "Let's first start with a simple train-test split!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "050ba451",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = dataset.train_test_split(test_size=0.1)\n",
    "train_ds = splits[\"train\"]\n",
    "eval_ds  = splits[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "099f990b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dataset({\n",
       "     features: ['id', 'type', 'question', 'context', 'oracle_context', 'cot_answer', 'instruction'],\n",
       "     num_rows: 301\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['id', 'type', 'question', 'context', 'oracle_context', 'cot_answer', 'instruction'],\n",
       "     num_rows: 34\n",
       " }))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds, eval_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22929c7f",
   "metadata": {},
   "source": [
    "Load the model and tokenizer we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5317f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "🦥 Unsloth Zoo will now patch everything to make training faster!\n",
      "INFO 05-21 06:09:36 [importing.py:53] Triton module has been replaced with a placeholder.\n",
      "INFO 05-21 06:09:36 [__init__.py:239] Automatically detected platform cuda.\n",
      "==((====))==  Unsloth 2025.4.7: Fast Llama patching. Transformers: 4.51.3. vLLM: 0.8.5.post1.\n",
      "   \\\\   /|    NVIDIA A10G. Num GPUs = 1. Max memory: 22.184 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 8.6. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post2. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"unsloth/Llama-3.2-1B-Instruct\",\n",
    "    max_seq_length = 2048, # Choose any for long context!\n",
    "    load_in_4bit = True,  # 4 bit quantization to reduce memory\n",
    "    load_in_8bit = False, \n",
    "    full_finetuning = False, \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a3d235",
   "metadata": {},
   "source": [
    "We can choose full model finetuning - or just to speed things up, let's use the LoRA method of finetuning!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8d23825a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2025.4.7 patched 16 layers with 16 QKV layers, 16 O layers and 16 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = 16, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
    "    lora_alpha = 16,\n",
    "    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
    "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
    "    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n",
    "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n",
    "    random_state = 2025,\n",
    "    use_rslora = False,  # We support rank stabilized LoRA\n",
    "    loftq_config = None, # And LoftQ\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c3deb6",
   "metadata": {},
   "source": [
    "## Formatting the prompts\n",
    "We need to put everything together into a single 'text' field for the LLM to be trained on. Here we collapse the context, and other passages together into a single text prompt for LLM finetuning as specified by the RAFT paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dbee4ea9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4702b474d09245d3b0d1e0f54b879ea5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/301 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd4c7ce455d84b8aa9289e8ba99f0fa8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/34 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def formatting_prompts_func(examples):\n",
    "    \"\"\"Define a formatter that injects the retrieved context:\"\"\"\n",
    "    \n",
    "    texts = []\n",
    "    for qn, ctx, oracle, instr, ans in zip(\n",
    "        examples['question'],\n",
    "        examples[\"context\"],\n",
    "        examples[\"oracle_context\"],\n",
    "        examples[\"instruction\"],\n",
    "        examples[\"cot_answer\"]\n",
    "    ):\n",
    "        # You can choose to use `oracle_context` (gold) vs. `context` (retrieved)\n",
    "        # Here we show both, but you could just use `context`.\n",
    "        prompt = (\n",
    "            \"### Question:\\n\"\n",
    "            f\"{qn}\\n\\n\"\n",
    "            \"### Context:\\n\"\n",
    "            f\"{ctx}\\n\\n\"\n",
    "            \"### (Oracle Passages):\\n\"\n",
    "            f\"{oracle}\\n\\n\"\n",
    "            \"### Instruction:\\n\"\n",
    "            f\"{instr}\\n\\n\"\n",
    "            \"### Answer:\\n\"\n",
    "        )\n",
    "        # Append the gold answer plus EOS\n",
    "        texts.append(prompt + ans + tokenizer.eos_token)\n",
    "    return {\"text\": texts}\n",
    "\n",
    "# then:\n",
    "train_ds = train_ds.map(formatting_prompts_func, batched=True)\n",
    "eval_ds = eval_ds.map(formatting_prompts_func, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e318a0",
   "metadata": {},
   "source": [
    "Let's take a look at what we did!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "af2f6851",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Question:\n",
       "What is the mean value for the 'Data Science' variable in the LinkedIn matched sample?\n",
       "\n",
       "### Context:\n",
       "{'sentences': [['Table 1: Summary statistics pretreatment and outcome variables\\nCoursera Internal Data LinkedIn Matched Sample\\nVariable name Mean S.E. Mean S.E.\\nTreatment 0.499 0.001 0.500 0.003\\nPanel A: Pre-treatment covariates\\nProfessional Experience Years – – 3.040 0.028\\nPast Tech Job – – 0.127 0.002\\nPast Managerial Job – – 0.064 0.001\\nMain Skill Absolute 0.099 0.001 2.074 0.010\\nMain Skill Standardized 0.000 <0.001 0.000 0.001\\nComputer Science 0.252 0.001 0.230 0.002\\nData Science 0.236 0.001 0.300 0.002\\nInformation Technology 0.140 0.001 0.138 0.002\\nGuided Project 0.168 0.001 0.097 0.002\\nProfessional Certificate 0.005 <0.001 0.005 <0.001\\nSpecialization 0.009 <0.001 0.009 0.001\\nDeveloping Country 0.896 0.001 0.850 0.002\\nAssociate Degree 0.029 <0.001 0.062 0.001\\nBachelor Degree 0.127 0.001 0.367 0.003\\nSome College 0.072 0.001 0.130 0.002\\nDoctorate Degree 0.004 <0.001 0.012 0.001\\nHigh School Diploma 0.059 0.001 0.097 0.002\\nLess than High School 0.009 <0.001 0.012 0.001\\nMasters Degree 0.050 0.001 0.146 0.002\\nNo Education Mentioned 0.645 0.002 0.164 0.002\\nProfessional Degree 0.004 <0.001 0.010 0.001\\nMale 0.302 0.002 0.674 0.002\\nGender Not Mentioned 0.533 0.002 0.101 0.002\\nPanel B: Outcome variables\\nNew Job – – 0.177 0.002\\nNew Job in Scope – – 0.133 0.002\\nCredential Shared – – 0.181 0.002\\nAll Views 0.191 0.001 0.429 0.003\\nAll Views by Others 0.143 0.001 0.318 0.002\\nViews LinkedIn 0.165 0.001 0.409 0.003\\nViews LinkedIn by Others 0.124 0.001 0.296 0.002\\nNote: Professional Experience Years is the number of years between the starting date of the first job and August 2023. Past Tech Job\\ntakes the value of 1 when the learner had a job title related to technology before randomization and zero otherwise. ', 'effects between the bottom and top tertiles, the difference is 0.1 p.p. (S.E. ', 'For each learner, Coursera assesses skill mastery and assigns a score (Red-\\ndick, 2019). Additionally, we compute a max-mean standardization of the learners’ skill level. We also\\nobserve the country where the learner registered for the course. Following the OECD classification,\\nwe use this information to group countries into developing and developed. Finally, we also observe\\nthe information provided by the learners in their registration survey. ']], 'title': [['placeholder_title', 'placeholder_title', 'placeholder_title']]}\n",
       "\n",
       "### (Oracle Passages):\n",
       "Table 1: Summary statistics pretreatment and outcome variables\n",
       "Coursera Internal Data LinkedIn Matched Sample\n",
       "Variable name Mean S.E. Mean S.E.\n",
       "Treatment 0.499 0.001 0.500 0.003\n",
       "Panel A: Pre-treatment covariates\n",
       "Professional Experience Years – – 3.040 0.028\n",
       "Past Tech Job – – 0.127 0.002\n",
       "Past Managerial Job – – 0.064 0.001\n",
       "Main Skill Absolute 0.099 0.001 2.074 0.010\n",
       "Main Skill Standardized 0.000 <0.001 0.000 0.001\n",
       "Computer Science 0.252 0.001 0.230 0.002\n",
       "Data Science 0.236 0.001 0.300 0.002\n",
       "Information Technology 0.140 0.001 0.138 0.002\n",
       "Guided Project 0.168 0.001 0.097 0.002\n",
       "Professional Certificate 0.005 <0.001 0.005 <0.001\n",
       "Specialization 0.009 <0.001 0.009 0.001\n",
       "Developing Country 0.896 0.001 0.850 0.002\n",
       "Associate Degree 0.029 <0.001 0.062 0.001\n",
       "Bachelor Degree 0.127 0.001 0.367 0.003\n",
       "Some College 0.072 0.001 0.130 0.002\n",
       "Doctorate Degree 0.004 <0.001 0.012 0.001\n",
       "High School Diploma 0.059 0.001 0.097 0.002\n",
       "Less than High School 0.009 <0.001 0.012 0.001\n",
       "Masters Degree 0.050 0.001 0.146 0.002\n",
       "No Education Mentioned 0.645 0.002 0.164 0.002\n",
       "Professional Degree 0.004 <0.001 0.010 0.001\n",
       "Male 0.302 0.002 0.674 0.002\n",
       "Gender Not Mentioned 0.533 0.002 0.101 0.002\n",
       "Panel B: Outcome variables\n",
       "New Job – – 0.177 0.002\n",
       "New Job in Scope – – 0.133 0.002\n",
       "Credential Shared – – 0.181 0.002\n",
       "All Views 0.191 0.001 0.429 0.003\n",
       "All Views by Others 0.143 0.001 0.318 0.002\n",
       "Views LinkedIn 0.165 0.001 0.409 0.003\n",
       "Views LinkedIn by Others 0.124 0.001 0.296 0.002\n",
       "Note: Professional Experience Years is the number of years between the starting date of the first job and August 2023. Past Tech Job\n",
       "takes the value of 1 when the learner had a job title related to technology before randomization and zero otherwise. \n",
       "\n",
       "### Instruction:\n",
       "<DOCUMENT>Table 1: Summary statistics pretreatment and outcome variables\n",
       "Coursera Internal Data LinkedIn Matched Sample\n",
       "Variable name Mean S.E. Mean S.E.\n",
       "Treatment 0.499 0.001 0.500 0.003\n",
       "Panel A: Pre-treatment covariates\n",
       "Professional Experience Years – – 3.040 0.028\n",
       "Past Tech Job – – 0.127 0.002\n",
       "Past Managerial Job – – 0.064 0.001\n",
       "Main Skill Absolute 0.099 0.001 2.074 0.010\n",
       "Main Skill Standardized 0.000 <0.001 0.000 0.001\n",
       "Computer Science 0.252 0.001 0.230 0.002\n",
       "Data Science 0.236 0.001 0.300 0.002\n",
       "Information Technology 0.140 0.001 0.138 0.002\n",
       "Guided Project 0.168 0.001 0.097 0.002\n",
       "Professional Certificate 0.005 <0.001 0.005 <0.001\n",
       "Specialization 0.009 <0.001 0.009 0.001\n",
       "Developing Country 0.896 0.001 0.850 0.002\n",
       "Associate Degree 0.029 <0.001 0.062 0.001\n",
       "Bachelor Degree 0.127 0.001 0.367 0.003\n",
       "Some College 0.072 0.001 0.130 0.002\n",
       "Doctorate Degree 0.004 <0.001 0.012 0.001\n",
       "High School Diploma 0.059 0.001 0.097 0.002\n",
       "Less than High School 0.009 <0.001 0.012 0.001\n",
       "Masters Degree 0.050 0.001 0.146 0.002\n",
       "No Education Mentioned 0.645 0.002 0.164 0.002\n",
       "Professional Degree 0.004 <0.001 0.010 0.001\n",
       "Male 0.302 0.002 0.674 0.002\n",
       "Gender Not Mentioned 0.533 0.002 0.101 0.002\n",
       "Panel B: Outcome variables\n",
       "New Job – – 0.177 0.002\n",
       "New Job in Scope – – 0.133 0.002\n",
       "Credential Shared – – 0.181 0.002\n",
       "All Views 0.191 0.001 0.429 0.003\n",
       "All Views by Others 0.143 0.001 0.318 0.002\n",
       "Views LinkedIn 0.165 0.001 0.409 0.003\n",
       "Views LinkedIn by Others 0.124 0.001 0.296 0.002\n",
       "Note: Professional Experience Years is the number of years between the starting date of the first job and August 2023. Past Tech Job\n",
       "takes the value of 1 when the learner had a job title related to technology before randomization and zero otherwise. </DOCUMENT>\n",
       "<DOCUMENT>effects between the bottom and top tertiles, the difference is 0.1 p.p. (S.E. </DOCUMENT>\n",
       "<DOCUMENT>For each learner, Coursera assesses skill mastery and assigns a score (Red-\n",
       "dick, 2019). Additionally, we compute a max-mean standardization of the learners’ skill level. We also\n",
       "observe the country where the learner registered for the course. Following the OECD classification,\n",
       "we use this information to group countries into developing and developed. Finally, we also observe\n",
       "the information provided by the learners in their registration survey. </DOCUMENT>\n",
       "What is the mean value for the 'Data Science' variable in the LinkedIn matched sample?\n",
       "\n",
       "### Answer:\n",
       "assistant: To answer the question about the mean value for the 'Data Science' variable in the LinkedIn matched sample, we need to follow these steps:\n",
       "\n",
       "1. **Identify the Relevant Section**: The context provides a table with summary statistics for various variables. We need to locate the section that pertains to the LinkedIn matched sample.\n",
       "\n",
       "2. **Locate the 'Data Science' Variable**: Within the table, find the row labeled 'Data Science'. This row will contain the mean value for the 'Data Science' variable in both the Coursera Internal Data and the LinkedIn Matched Sample.\n",
       "\n",
       "3. **Extract the Mean Value for LinkedIn Matched Sample**: Once the 'Data Science' row is located, extract the mean value specifically for the LinkedIn matched sample.\n",
       "\n",
       "Let's proceed with these steps:\n",
       "\n",
       "- The context provides a table with two columns of mean values: one for Coursera Internal Data and another for LinkedIn Matched Sample.\n",
       "\n",
       "- ##begin_quote## Data Science 0.236 0.001 0.300 0.002 ##end_quote##: This line from the context shows the mean values for the 'Data Science' variable. The first mean value (0.236) corresponds to the Coursera Internal Data, and the second mean value (0.300) corresponds to the LinkedIn Matched Sample.\n",
       "\n",
       "Therefore, the mean value for the 'Data Science' variable in the LinkedIn matched sample is 0.300.\n",
       "\n",
       "<ANSWER>: 0.300<|eot_id|>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "display(Markdown(pd.DataFrame(train_ds).head()['text'].iloc[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4c7c7c",
   "metadata": {},
   "source": [
    "### Finally let's start training!\n",
    "\n",
    "I've experimented a little and I found that 5 training epochs was sufficient. But feel free to adjust the hyperparameters to anything you prefer!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91d643e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "065a8f099e084b70a9b554628248a109",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Unsloth: Tokenizing [\"text\"] (num_proc=4):   0%|          | 0/301 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fa1652bdf324656b058a3ac21bd2dc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Unsloth: Tokenizing [\"text\"] (num_proc=4):   0%|          | 0/34 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"llama32_1bn_raft_v2\", #This will also be used as your huggingfacehub model id name\n",
    "    report_to=\"wandb\", #Leave this to be blank if you don't want to use wandb\n",
    "    run_name=\"RAFT_SFT_Take7\",\n",
    "    eval_steps=5,\n",
    "    eval_strategy=\"steps\",\n",
    "    per_device_train_batch_size=1,    # small batches if quantized\n",
    "    per_device_eval_batch_size=1,\n",
    "    gradient_accumulation_steps=8,\n",
    "    learning_rate=2e-5,\n",
    "    num_train_epochs=5,\n",
    "    # max_steps=60,                    # or set num_train_epochs\n",
    "    save_strategy=\"no\",\n",
    "    bf16=True,\n",
    "    fp16=False,\n",
    "    gradient_checkpointing=True,\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=5,\n",
    "    seed=42,\n",
    "    optim=\"adamw_torch\",\n",
    "    lr_scheduler_type=\"cosine\",\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset = train_ds,\n",
    "    eval_dataset = eval_ds, \n",
    "    args=training_args,\n",
    "    dataset_text_field=\"text\",\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05b2b5a",
   "metadata": {},
   "source": [
    "Current memory statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "09fdea09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU = NVIDIA A10G. Max memory = 22.184 GB.\n",
      "1.457 GB of memory reserved.\n"
     ]
    }
   ],
   "source": [
    "gpu_stats = torch.cuda.get_device_properties(0)\n",
    "start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
    "max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n",
    "print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n",
    "print(f\"{start_gpu_memory} GB of memory reserved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e619a1bf",
   "metadata": {},
   "source": [
    "Train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9adf6997",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 301 | Num Epochs = 5 | Total steps = 185\n",
      "O^O/ \\_/ \\    Batch size per device = 1 | Gradient accumulation steps = 8\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (1 x 8 x 1) = 8\n",
      " \"-____-\"     Trainable parameters = 11,272,192/1,000,000,000 (1.13% trained)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtituslhy\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/ideal-palm-tree/notebooks/wandb/run-20250521_061652-hc9ebbef</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/tituslhy/huggingface/runs/hc9ebbef' target=\"_blank\">RAFT_SFT_Take7</a></strong> to <a href='https://wandb.ai/tituslhy/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/tituslhy/huggingface' target=\"_blank\">https://wandb.ai/tituslhy/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/tituslhy/huggingface/runs/hc9ebbef' target=\"_blank\">https://wandb.ai/tituslhy/huggingface/runs/hc9ebbef</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Will smartly offload gradients to save VRAM!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='185' max='185' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [185/185 10:29, Epoch 4/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.493000</td>\n",
       "      <td>1.633143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.466600</td>\n",
       "      <td>1.617843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.546300</td>\n",
       "      <td>1.596143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.485900</td>\n",
       "      <td>1.571562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.449800</td>\n",
       "      <td>1.546785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.426500</td>\n",
       "      <td>1.521693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>1.446800</td>\n",
       "      <td>1.497457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.376700</td>\n",
       "      <td>1.474485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>1.334400</td>\n",
       "      <td>1.454567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.365500</td>\n",
       "      <td>1.434021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>1.316800</td>\n",
       "      <td>1.413398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.372000</td>\n",
       "      <td>1.392783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>1.300700</td>\n",
       "      <td>1.373677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1.275900</td>\n",
       "      <td>1.352113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>1.247600</td>\n",
       "      <td>1.334677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.229100</td>\n",
       "      <td>1.317328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>1.204400</td>\n",
       "      <td>1.301929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.168800</td>\n",
       "      <td>1.288014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>1.255500</td>\n",
       "      <td>1.275806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.246700</td>\n",
       "      <td>1.264712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105</td>\n",
       "      <td>1.135600</td>\n",
       "      <td>1.254323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1.122600</td>\n",
       "      <td>1.242589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>115</td>\n",
       "      <td>1.171900</td>\n",
       "      <td>1.239755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1.166100</td>\n",
       "      <td>1.233676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>1.179500</td>\n",
       "      <td>1.228176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1.090000</td>\n",
       "      <td>1.223785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135</td>\n",
       "      <td>1.133300</td>\n",
       "      <td>1.220154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1.124100</td>\n",
       "      <td>1.216492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>145</td>\n",
       "      <td>1.119700</td>\n",
       "      <td>1.214525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.122200</td>\n",
       "      <td>1.210105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155</td>\n",
       "      <td>1.116500</td>\n",
       "      <td>1.210061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1.118800</td>\n",
       "      <td>1.210211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>165</td>\n",
       "      <td>1.135800</td>\n",
       "      <td>1.208962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1.110000</td>\n",
       "      <td>1.208903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>1.113200</td>\n",
       "      <td>1.208125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1.147100</td>\n",
       "      <td>1.208712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>185</td>\n",
       "      <td>1.133800</td>\n",
       "      <td>1.208498</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Not an error, but LlamaForCausalLM does not accept `num_items_in_batch`.\n",
      "Using gradient accumulation will be very slightly less accurate.\n",
      "Read more on gradient accumulation issues here: https://unsloth.ai/blog/gradient\n"
     ]
    }
   ],
   "source": [
    "trainer_stats = trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718da831",
   "metadata": {},
   "source": [
    "Compute used memory statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "98003bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "637.9309 seconds used for training.\n",
      "10.63 minutes used for training.\n",
      "Peak reserved memory = 2.156 GB.\n",
      "Peak reserved memory for training = 0.699 GB.\n",
      "Peak reserved memory % of max memory = 9.719 %.\n",
      "Peak reserved memory for training % of max memory = 3.151 %.\n"
     ]
    }
   ],
   "source": [
    "used_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
    "used_memory_for_lora = round(used_memory - start_gpu_memory, 3)\n",
    "used_percentage = round(used_memory / max_memory * 100, 3)\n",
    "lora_percentage = round(used_memory_for_lora / max_memory * 100, 3)\n",
    "print(f\"{trainer_stats.metrics['train_runtime']} seconds used for training.\")\n",
    "print(\n",
    "    f\"{round(trainer_stats.metrics['train_runtime']/60, 2)} minutes used for training.\"\n",
    ")\n",
    "print(f\"Peak reserved memory = {used_memory} GB.\")\n",
    "print(f\"Peak reserved memory for training = {used_memory_for_lora} GB.\")\n",
    "print(f\"Peak reserved memory % of max memory = {used_percentage} %.\")\n",
    "print(f\"Peak reserved memory for training % of max memory = {lora_percentage} %.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f8b4e4",
   "metadata": {},
   "source": [
    "## Save the model!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc28f18",
   "metadata": {},
   "source": [
    "### Local save\n",
    "It's important to save the merged model - otherwise you'll just be saving the LoRA weights which will make it harder to deploy on Ollama/any platform in the future (you'll need one extra step to pull the base model too)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dcbf89b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: You have 2 CPUs. Using `safe_serialization` is 10x slower.\n",
      "We shall switch to Pytorch saving, which might take 3 minutes and not 30 minutes.\n",
      "To force `safe_serialization`, set it to `None` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Merging 4bit and LoRA weights to 16bit...\n",
      "Unsloth: Will use up to 3.81 out of 15.42 RAM for saving.\n",
      "Unsloth: Saving model... This might take 5 minutes ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:00<00:00, 56.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Saving tokenizer... Done.\n",
      "Unsloth: Saving llama32_1bn_raft_merged_v2/pytorch_model.bin...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "model.save_pretrained_merged(\n",
    "    save_directory = \"llama32_1bn_raft_merged_v2\",     # Local path to store merged model\n",
    "    tokenizer = tokenizer,\n",
    "    save_method = \"merged_16bit\",        # Can also use \"merged_4bit\" or \"merged_8bit\" if needed\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368138cc",
   "metadata": {},
   "source": [
    "### Push to HuggingFace Hub!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ede235b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: You are pushing to hub, but you passed your HF username = tituslhy.\n",
      "We shall truncate tituslhy/llama32_1bn_raft_non_traditional_credentials_v2 to llama32_1bn_raft_non_traditional_credentials_v2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Merging 4bit and LoRA weights to 16bit...\n",
      "Unsloth: Will use up to 3.63 out of 15.42 RAM for saving.\n",
      "Unsloth: Saving model... This might take 5 minutes ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:00<00:00, 103.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Saving tokenizer..."
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb950e1f652948b68711e1cbbd51977f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Done.\n",
      "Unsloth: Saving llama32_1bn_raft_non_traditional_credentials_v2/pytorch_model.bin...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0e0173ddd4d4095a0138f042fb08548",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/613 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "768c6ee17d03431781c3104b4f6b977a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/2.47G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "Saved merged model to https://huggingface.co/tituslhy/llama32_1bn_raft_non_traditional_credentials_v2\n"
     ]
    }
   ],
   "source": [
    "model.push_to_hub_merged(\n",
    "    repo_id=\"tituslhy/llama32_1bn_raft_non_traditional_credentials_v2\",\n",
    "    tokenizer=tokenizer,\n",
    "    save_method=\"merged_16bit\",\n",
    "    token=os.environ[\"HUGGINGFACE_ACCESS_TOKEN\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82370e9",
   "metadata": {},
   "source": [
    "### Push the GGUF files to HuggingFace Hub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951c06d8",
   "metadata": {},
   "source": [
    "You don't have to run this cell if your llama.cpp gguf execution (`model.push_to_hub_gguf`) works! \n",
    "> I had to because it could not find where the llama-quantize binary was."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "35ad8d09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook sees: ['.github', 'CODEOWNERS', 'pyproject.toml', 'README.md', 'gguf-py', 'ggml', '.clang-tidy', '.pre-commit-config.yaml', 'examples', 'tests', 'convert_llama_ggml_to_gguf.py', 'cmake', '.gitignore', 'CMakeLists.txt', 'build-xcframework.sh', 'scripts', 'Makefile', 'pocs', 'pyrightconfig.json', 'poetry.lock', 'convert_hf_to_gguf_update.py', 'src', 'docs', 'convert_hf_to_gguf.py', 'mypy.ini', 'llama-quantize', 'CONTRIBUTING.md', 'models', '.git', '.dockerignore', 'AUTHORS', 'requirements.txt', 'licenses', '.clang-format', 'flake.nix', 'prompts', 'tools', '.ecrc', '.flake8', 'grammars', '.devops', 'media', '.editorconfig', 'SECURITY.md', 'LICENSE', 'include', 'requirements', 'flake.lock', 'CMakePresets.json', 'ci', 'build', 'common', '.gitmodules', 'convert_lora_to_gguf.py', 'quantize']\n"
     ]
    }
   ],
   "source": [
    "# ① Point at the real binary in build/bin\n",
    "real_q = os.path.expanduser(\"~/llama.cpp/build/bin/llama-quantize\")\n",
    "assert os.path.exists(real_q), f\"{real_q} not found!\"\n",
    "\n",
    "# ② Make a local 'llama.cpp' folder in your notebook working directory\n",
    "cwd = os.getcwd()\n",
    "local_pack = os.path.join(cwd, \"llama.cpp\")\n",
    "os.makedirs(local_pack, exist_ok=True)\n",
    "\n",
    "# ③ Symlink it as 'llama-quantize' and also as 'quantize'\n",
    "for name in (\"llama-quantize\", \"quantize\"):\n",
    "    link = os.path.join(local_pack, name)\n",
    "    if os.path.exists(link) or os.path.islink(link):\n",
    "        os.remove(link)\n",
    "    os.symlink(real_q, link)\n",
    "\n",
    "# ④ Verify\n",
    "print(\"Notebook sees:\", os.listdir(local_pack))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "25ac4d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Merging 4bit and LoRA weights to 16bit...\n",
      "Unsloth: Will use up to 4.11 out of 15.42 RAM for saving.\n",
      "Unsloth: Saving model... This might take 5 minutes ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:00<00:00, 102.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Saving tokenizer..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Done.\n",
      "Unsloth: Saving tituslhy/llama32_1bn_raft_non_traditional_credentials_v2/pytorch_model.bin...\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Converting llama model. Can use fast conversion = False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth: Conversion from QLoRA to GGUF information\n",
      "   \\\\   /|    [0] Installing llama.cpp might take 3 minutes.\n",
      "O^O/ \\_/ \\    [1] Converting HF to GGUF 16bits might take 3 minutes.\n",
      "\\        /    [2] Converting GGUF 16bits to ['q4_k_m', 'q8_0', 'q5_k_m'] might take 10 minutes each.\n",
      " \"-____-\"     In total, you will have to wait at least 16 minutes.\n",
      "\n",
      "Unsloth: Installing llama.cpp. This might take 3 minutes...\n",
      "Unsloth: [1] Converting model at tituslhy/llama32_1bn_raft_non_traditional_credentials_v2 into bf16 GGUF format.\n",
      "The output location will be /home/ubuntu/ideal-palm-tree/notebooks/tituslhy/llama32_1bn_raft_non_traditional_credentials_v2/unsloth.BF16.gguf\n",
      "This might take 3 minutes...\n",
      "INFO:hf-to-gguf:Loading model: llama32_1bn_raft_non_traditional_credentials_v2\n",
      "INFO:hf-to-gguf:Model architecture: LlamaForCausalLM\n",
      "INFO:gguf.gguf_writer:gguf: This GGUF file is for Little Endian only\n",
      "INFO:hf-to-gguf:Exporting model...\n",
      "INFO:hf-to-gguf:rope_freqs.weight,           torch.float32 --> F32, shape = {32}\n",
      "INFO:hf-to-gguf:gguf: loading model part 'pytorch_model.bin'\n",
      "INFO:hf-to-gguf:token_embd.weight,           torch.bfloat16 --> BF16, shape = {2048, 128256}\n",
      "INFO:hf-to-gguf:blk.0.attn_q.weight,         torch.bfloat16 --> BF16, shape = {2048, 2048}\n",
      "INFO:hf-to-gguf:blk.0.attn_k.weight,         torch.bfloat16 --> BF16, shape = {2048, 512}\n",
      "INFO:hf-to-gguf:blk.0.attn_v.weight,         torch.bfloat16 --> BF16, shape = {2048, 512}\n",
      "INFO:hf-to-gguf:blk.0.attn_output.weight,    torch.bfloat16 --> BF16, shape = {2048, 2048}\n",
      "INFO:hf-to-gguf:blk.0.ffn_gate.weight,       torch.bfloat16 --> BF16, shape = {2048, 8192}\n",
      "INFO:hf-to-gguf:blk.0.ffn_up.weight,         torch.bfloat16 --> BF16, shape = {2048, 8192}\n",
      "INFO:hf-to-gguf:blk.0.ffn_down.weight,       torch.bfloat16 --> BF16, shape = {8192, 2048}\n",
      "INFO:hf-to-gguf:blk.0.attn_norm.weight,      torch.bfloat16 --> F32, shape = {2048}\n",
      "INFO:hf-to-gguf:blk.0.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {2048}\n",
      "INFO:hf-to-gguf:blk.1.attn_q.weight,         torch.bfloat16 --> BF16, shape = {2048, 2048}\n",
      "INFO:hf-to-gguf:blk.1.attn_k.weight,         torch.bfloat16 --> BF16, shape = {2048, 512}\n",
      "INFO:hf-to-gguf:blk.1.attn_v.weight,         torch.bfloat16 --> BF16, shape = {2048, 512}\n",
      "INFO:hf-to-gguf:blk.1.attn_output.weight,    torch.bfloat16 --> BF16, shape = {2048, 2048}\n",
      "INFO:hf-to-gguf:blk.1.ffn_gate.weight,       torch.bfloat16 --> BF16, shape = {2048, 8192}\n",
      "INFO:hf-to-gguf:blk.1.ffn_up.weight,         torch.bfloat16 --> BF16, shape = {2048, 8192}\n",
      "INFO:hf-to-gguf:blk.1.ffn_down.weight,       torch.bfloat16 --> BF16, shape = {8192, 2048}\n",
      "INFO:hf-to-gguf:blk.1.attn_norm.weight,      torch.bfloat16 --> F32, shape = {2048}\n",
      "INFO:hf-to-gguf:blk.1.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {2048}\n",
      "INFO:hf-to-gguf:blk.2.attn_q.weight,         torch.bfloat16 --> BF16, shape = {2048, 2048}\n",
      "INFO:hf-to-gguf:blk.2.attn_k.weight,         torch.bfloat16 --> BF16, shape = {2048, 512}\n",
      "INFO:hf-to-gguf:blk.2.attn_v.weight,         torch.bfloat16 --> BF16, shape = {2048, 512}\n",
      "INFO:hf-to-gguf:blk.2.attn_output.weight,    torch.bfloat16 --> BF16, shape = {2048, 2048}\n",
      "INFO:hf-to-gguf:blk.2.ffn_gate.weight,       torch.bfloat16 --> BF16, shape = {2048, 8192}\n",
      "INFO:hf-to-gguf:blk.2.ffn_up.weight,         torch.bfloat16 --> BF16, shape = {2048, 8192}\n",
      "INFO:hf-to-gguf:blk.2.ffn_down.weight,       torch.bfloat16 --> BF16, shape = {8192, 2048}\n",
      "INFO:hf-to-gguf:blk.2.attn_norm.weight,      torch.bfloat16 --> F32, shape = {2048}\n",
      "INFO:hf-to-gguf:blk.2.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {2048}\n",
      "INFO:hf-to-gguf:blk.3.attn_q.weight,         torch.bfloat16 --> BF16, shape = {2048, 2048}\n",
      "INFO:hf-to-gguf:blk.3.attn_k.weight,         torch.bfloat16 --> BF16, shape = {2048, 512}\n",
      "INFO:hf-to-gguf:blk.3.attn_v.weight,         torch.bfloat16 --> BF16, shape = {2048, 512}\n",
      "INFO:hf-to-gguf:blk.3.attn_output.weight,    torch.bfloat16 --> BF16, shape = {2048, 2048}\n",
      "INFO:hf-to-gguf:blk.3.ffn_gate.weight,       torch.bfloat16 --> BF16, shape = {2048, 8192}\n",
      "INFO:hf-to-gguf:blk.3.ffn_up.weight,         torch.bfloat16 --> BF16, shape = {2048, 8192}\n",
      "INFO:hf-to-gguf:blk.3.ffn_down.weight,       torch.bfloat16 --> BF16, shape = {8192, 2048}\n",
      "INFO:hf-to-gguf:blk.3.attn_norm.weight,      torch.bfloat16 --> F32, shape = {2048}\n",
      "INFO:hf-to-gguf:blk.3.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {2048}\n",
      "INFO:hf-to-gguf:blk.4.attn_q.weight,         torch.bfloat16 --> BF16, shape = {2048, 2048}\n",
      "INFO:hf-to-gguf:blk.4.attn_k.weight,         torch.bfloat16 --> BF16, shape = {2048, 512}\n",
      "INFO:hf-to-gguf:blk.4.attn_v.weight,         torch.bfloat16 --> BF16, shape = {2048, 512}\n",
      "INFO:hf-to-gguf:blk.4.attn_output.weight,    torch.bfloat16 --> BF16, shape = {2048, 2048}\n",
      "INFO:hf-to-gguf:blk.4.ffn_gate.weight,       torch.bfloat16 --> BF16, shape = {2048, 8192}\n",
      "INFO:hf-to-gguf:blk.4.ffn_up.weight,         torch.bfloat16 --> BF16, shape = {2048, 8192}\n",
      "INFO:hf-to-gguf:blk.4.ffn_down.weight,       torch.bfloat16 --> BF16, shape = {8192, 2048}\n",
      "INFO:hf-to-gguf:blk.4.attn_norm.weight,      torch.bfloat16 --> F32, shape = {2048}\n",
      "INFO:hf-to-gguf:blk.4.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {2048}\n",
      "INFO:hf-to-gguf:blk.5.attn_q.weight,         torch.bfloat16 --> BF16, shape = {2048, 2048}\n",
      "INFO:hf-to-gguf:blk.5.attn_k.weight,         torch.bfloat16 --> BF16, shape = {2048, 512}\n",
      "INFO:hf-to-gguf:blk.5.attn_v.weight,         torch.bfloat16 --> BF16, shape = {2048, 512}\n",
      "INFO:hf-to-gguf:blk.5.attn_output.weight,    torch.bfloat16 --> BF16, shape = {2048, 2048}\n",
      "INFO:hf-to-gguf:blk.5.ffn_gate.weight,       torch.bfloat16 --> BF16, shape = {2048, 8192}\n",
      "INFO:hf-to-gguf:blk.5.ffn_up.weight,         torch.bfloat16 --> BF16, shape = {2048, 8192}\n",
      "INFO:hf-to-gguf:blk.5.ffn_down.weight,       torch.bfloat16 --> BF16, shape = {8192, 2048}\n",
      "INFO:hf-to-gguf:blk.5.attn_norm.weight,      torch.bfloat16 --> F32, shape = {2048}\n",
      "INFO:hf-to-gguf:blk.5.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {2048}\n",
      "INFO:hf-to-gguf:blk.6.attn_q.weight,         torch.bfloat16 --> BF16, shape = {2048, 2048}\n",
      "INFO:hf-to-gguf:blk.6.attn_k.weight,         torch.bfloat16 --> BF16, shape = {2048, 512}\n",
      "INFO:hf-to-gguf:blk.6.attn_v.weight,         torch.bfloat16 --> BF16, shape = {2048, 512}\n",
      "INFO:hf-to-gguf:blk.6.attn_output.weight,    torch.bfloat16 --> BF16, shape = {2048, 2048}\n",
      "INFO:hf-to-gguf:blk.6.ffn_gate.weight,       torch.bfloat16 --> BF16, shape = {2048, 8192}\n",
      "INFO:hf-to-gguf:blk.6.ffn_up.weight,         torch.bfloat16 --> BF16, shape = {2048, 8192}\n",
      "INFO:hf-to-gguf:blk.6.ffn_down.weight,       torch.bfloat16 --> BF16, shape = {8192, 2048}\n",
      "INFO:hf-to-gguf:blk.6.attn_norm.weight,      torch.bfloat16 --> F32, shape = {2048}\n",
      "INFO:hf-to-gguf:blk.6.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {2048}\n",
      "INFO:hf-to-gguf:blk.7.attn_q.weight,         torch.bfloat16 --> BF16, shape = {2048, 2048}\n",
      "INFO:hf-to-gguf:blk.7.attn_k.weight,         torch.bfloat16 --> BF16, shape = {2048, 512}\n",
      "INFO:hf-to-gguf:blk.7.attn_v.weight,         torch.bfloat16 --> BF16, shape = {2048, 512}\n",
      "INFO:hf-to-gguf:blk.7.attn_output.weight,    torch.bfloat16 --> BF16, shape = {2048, 2048}\n",
      "INFO:hf-to-gguf:blk.7.ffn_gate.weight,       torch.bfloat16 --> BF16, shape = {2048, 8192}\n",
      "INFO:hf-to-gguf:blk.7.ffn_up.weight,         torch.bfloat16 --> BF16, shape = {2048, 8192}\n",
      "INFO:hf-to-gguf:blk.7.ffn_down.weight,       torch.bfloat16 --> BF16, shape = {8192, 2048}\n",
      "INFO:hf-to-gguf:blk.7.attn_norm.weight,      torch.bfloat16 --> F32, shape = {2048}\n",
      "INFO:hf-to-gguf:blk.7.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {2048}\n",
      "INFO:hf-to-gguf:blk.8.attn_q.weight,         torch.bfloat16 --> BF16, shape = {2048, 2048}\n",
      "INFO:hf-to-gguf:blk.8.attn_k.weight,         torch.bfloat16 --> BF16, shape = {2048, 512}\n",
      "INFO:hf-to-gguf:blk.8.attn_v.weight,         torch.bfloat16 --> BF16, shape = {2048, 512}\n",
      "INFO:hf-to-gguf:blk.8.attn_output.weight,    torch.bfloat16 --> BF16, shape = {2048, 2048}\n",
      "INFO:hf-to-gguf:blk.8.ffn_gate.weight,       torch.bfloat16 --> BF16, shape = {2048, 8192}\n",
      "INFO:hf-to-gguf:blk.8.ffn_up.weight,         torch.bfloat16 --> BF16, shape = {2048, 8192}\n",
      "INFO:hf-to-gguf:blk.8.ffn_down.weight,       torch.bfloat16 --> BF16, shape = {8192, 2048}\n",
      "INFO:hf-to-gguf:blk.8.attn_norm.weight,      torch.bfloat16 --> F32, shape = {2048}\n",
      "INFO:hf-to-gguf:blk.8.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {2048}\n",
      "INFO:hf-to-gguf:blk.9.attn_q.weight,         torch.bfloat16 --> BF16, shape = {2048, 2048}\n",
      "INFO:hf-to-gguf:blk.9.attn_k.weight,         torch.bfloat16 --> BF16, shape = {2048, 512}\n",
      "INFO:hf-to-gguf:blk.9.attn_v.weight,         torch.bfloat16 --> BF16, shape = {2048, 512}\n",
      "INFO:hf-to-gguf:blk.9.attn_output.weight,    torch.bfloat16 --> BF16, shape = {2048, 2048}\n",
      "INFO:hf-to-gguf:blk.9.ffn_gate.weight,       torch.bfloat16 --> BF16, shape = {2048, 8192}\n",
      "INFO:hf-to-gguf:blk.9.ffn_up.weight,         torch.bfloat16 --> BF16, shape = {2048, 8192}\n",
      "INFO:hf-to-gguf:blk.9.ffn_down.weight,       torch.bfloat16 --> BF16, shape = {8192, 2048}\n",
      "INFO:hf-to-gguf:blk.9.attn_norm.weight,      torch.bfloat16 --> F32, shape = {2048}\n",
      "INFO:hf-to-gguf:blk.9.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {2048}\n",
      "INFO:hf-to-gguf:blk.10.attn_q.weight,        torch.bfloat16 --> BF16, shape = {2048, 2048}\n",
      "INFO:hf-to-gguf:blk.10.attn_k.weight,        torch.bfloat16 --> BF16, shape = {2048, 512}\n",
      "INFO:hf-to-gguf:blk.10.attn_v.weight,        torch.bfloat16 --> BF16, shape = {2048, 512}\n",
      "INFO:hf-to-gguf:blk.10.attn_output.weight,   torch.bfloat16 --> BF16, shape = {2048, 2048}\n",
      "INFO:hf-to-gguf:blk.10.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {2048, 8192}\n",
      "INFO:hf-to-gguf:blk.10.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {2048, 8192}\n",
      "INFO:hf-to-gguf:blk.10.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {8192, 2048}\n",
      "INFO:hf-to-gguf:blk.10.attn_norm.weight,     torch.bfloat16 --> F32, shape = {2048}\n",
      "INFO:hf-to-gguf:blk.10.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {2048}\n",
      "INFO:hf-to-gguf:blk.11.attn_q.weight,        torch.bfloat16 --> BF16, shape = {2048, 2048}\n",
      "INFO:hf-to-gguf:blk.11.attn_k.weight,        torch.bfloat16 --> BF16, shape = {2048, 512}\n",
      "INFO:hf-to-gguf:blk.11.attn_v.weight,        torch.bfloat16 --> BF16, shape = {2048, 512}\n",
      "INFO:hf-to-gguf:blk.11.attn_output.weight,   torch.bfloat16 --> BF16, shape = {2048, 2048}\n",
      "INFO:hf-to-gguf:blk.11.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {2048, 8192}\n",
      "INFO:hf-to-gguf:blk.11.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {2048, 8192}\n",
      "INFO:hf-to-gguf:blk.11.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {8192, 2048}\n",
      "INFO:hf-to-gguf:blk.11.attn_norm.weight,     torch.bfloat16 --> F32, shape = {2048}\n",
      "INFO:hf-to-gguf:blk.11.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {2048}\n",
      "INFO:hf-to-gguf:blk.12.attn_q.weight,        torch.bfloat16 --> BF16, shape = {2048, 2048}\n",
      "INFO:hf-to-gguf:blk.12.attn_k.weight,        torch.bfloat16 --> BF16, shape = {2048, 512}\n",
      "INFO:hf-to-gguf:blk.12.attn_v.weight,        torch.bfloat16 --> BF16, shape = {2048, 512}\n",
      "INFO:hf-to-gguf:blk.12.attn_output.weight,   torch.bfloat16 --> BF16, shape = {2048, 2048}\n",
      "INFO:hf-to-gguf:blk.12.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {2048, 8192}\n",
      "INFO:hf-to-gguf:blk.12.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {2048, 8192}\n",
      "INFO:hf-to-gguf:blk.12.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {8192, 2048}\n",
      "INFO:hf-to-gguf:blk.12.attn_norm.weight,     torch.bfloat16 --> F32, shape = {2048}\n",
      "INFO:hf-to-gguf:blk.12.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {2048}\n",
      "INFO:hf-to-gguf:blk.13.attn_q.weight,        torch.bfloat16 --> BF16, shape = {2048, 2048}\n",
      "INFO:hf-to-gguf:blk.13.attn_k.weight,        torch.bfloat16 --> BF16, shape = {2048, 512}\n",
      "INFO:hf-to-gguf:blk.13.attn_v.weight,        torch.bfloat16 --> BF16, shape = {2048, 512}\n",
      "INFO:hf-to-gguf:blk.13.attn_output.weight,   torch.bfloat16 --> BF16, shape = {2048, 2048}\n",
      "INFO:hf-to-gguf:blk.13.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {2048, 8192}\n",
      "INFO:hf-to-gguf:blk.13.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {2048, 8192}\n",
      "INFO:hf-to-gguf:blk.13.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {8192, 2048}\n",
      "INFO:hf-to-gguf:blk.13.attn_norm.weight,     torch.bfloat16 --> F32, shape = {2048}\n",
      "INFO:hf-to-gguf:blk.13.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {2048}\n",
      "INFO:hf-to-gguf:blk.14.attn_q.weight,        torch.bfloat16 --> BF16, shape = {2048, 2048}\n",
      "INFO:hf-to-gguf:blk.14.attn_k.weight,        torch.bfloat16 --> BF16, shape = {2048, 512}\n",
      "INFO:hf-to-gguf:blk.14.attn_v.weight,        torch.bfloat16 --> BF16, shape = {2048, 512}\n",
      "INFO:hf-to-gguf:blk.14.attn_output.weight,   torch.bfloat16 --> BF16, shape = {2048, 2048}\n",
      "INFO:hf-to-gguf:blk.14.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {2048, 8192}\n",
      "INFO:hf-to-gguf:blk.14.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {2048, 8192}\n",
      "INFO:hf-to-gguf:blk.14.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {8192, 2048}\n",
      "INFO:hf-to-gguf:blk.14.attn_norm.weight,     torch.bfloat16 --> F32, shape = {2048}\n",
      "INFO:hf-to-gguf:blk.14.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {2048}\n",
      "INFO:hf-to-gguf:blk.15.attn_q.weight,        torch.bfloat16 --> BF16, shape = {2048, 2048}\n",
      "INFO:hf-to-gguf:blk.15.attn_k.weight,        torch.bfloat16 --> BF16, shape = {2048, 512}\n",
      "INFO:hf-to-gguf:blk.15.attn_v.weight,        torch.bfloat16 --> BF16, shape = {2048, 512}\n",
      "INFO:hf-to-gguf:blk.15.attn_output.weight,   torch.bfloat16 --> BF16, shape = {2048, 2048}\n",
      "INFO:hf-to-gguf:blk.15.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {2048, 8192}\n",
      "INFO:hf-to-gguf:blk.15.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {2048, 8192}\n",
      "INFO:hf-to-gguf:blk.15.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {8192, 2048}\n",
      "INFO:hf-to-gguf:blk.15.attn_norm.weight,     torch.bfloat16 --> F32, shape = {2048}\n",
      "INFO:hf-to-gguf:blk.15.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {2048}\n",
      "INFO:hf-to-gguf:output_norm.weight,          torch.bfloat16 --> F32, shape = {2048}\n",
      "INFO:hf-to-gguf:Set meta model\n",
      "INFO:hf-to-gguf:Set model parameters\n",
      "INFO:hf-to-gguf:gguf: context length = 131072\n",
      "INFO:hf-to-gguf:gguf: embedding length = 2048\n",
      "INFO:hf-to-gguf:gguf: feed forward length = 8192\n",
      "INFO:hf-to-gguf:gguf: head count = 32\n",
      "INFO:hf-to-gguf:gguf: key-value head count = 8\n",
      "INFO:hf-to-gguf:gguf: rope theta = 500000.0\n",
      "INFO:hf-to-gguf:gguf: rms norm epsilon = 1e-05\n",
      "INFO:hf-to-gguf:gguf: file type = 32\n",
      "INFO:hf-to-gguf:Set model quantization version\n",
      "INFO:hf-to-gguf:Set model tokenizer\n",
      "INFO:gguf.vocab:Adding 280147 merge(s).\n",
      "INFO:gguf.vocab:Setting special token type bos to 128000\n",
      "INFO:gguf.vocab:Setting special token type eos to 128009\n",
      "INFO:gguf.vocab:Setting special token type pad to 128004\n",
      "INFO:gguf.vocab:Setting add_bos_token to True\n",
      "INFO:gguf.vocab:Setting chat_template to {{- bos_token }}\n",
      "{%- if custom_tools is defined %}\n",
      "    {%- set tools = custom_tools %}\n",
      "{%- endif %}\n",
      "{%- if not tools_in_user_message is defined %}\n",
      "    {%- set tools_in_user_message = true %}\n",
      "{%- endif %}\n",
      "{%- if not date_string is defined %}\n",
      "    {%- if strftime_now is defined %}\n",
      "        {%- set date_string = strftime_now(\"%d %b %Y\") %}\n",
      "    {%- else %}\n",
      "        {%- set date_string = \"26 Jul 2024\" %}\n",
      "    {%- endif %}\n",
      "{%- endif %}\n",
      "{%- if not tools is defined %}\n",
      "    {%- set tools = none %}\n",
      "{%- endif %}\n",
      "\n",
      "{#- This block extracts the system message, so we can slot it into the right place. #}\n",
      "{%- if messages[0]['role'] == 'system' %}\n",
      "    {%- set system_message = messages[0]['content']|trim %}\n",
      "    {%- set messages = messages[1:] %}\n",
      "{%- else %}\n",
      "    {%- set system_message = \"\" %}\n",
      "{%- endif %}\n",
      "\n",
      "{#- System message #}\n",
      "{{- \"<|start_header_id|>system<|end_header_id|>\\n\\n\" }}\n",
      "{%- if tools is not none %}\n",
      "    {{- \"Environment: ipython\\n\" }}\n",
      "{%- endif %}\n",
      "{{- \"Cutting Knowledge Date: December 2023\\n\" }}\n",
      "{{- \"Today Date: \" + date_string + \"\\n\\n\" }}\n",
      "{%- if tools is not none and not tools_in_user_message %}\n",
      "    {{- \"You have access to the following functions. To call a function, please respond with JSON for a function call.\" }}\n",
      "    {{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}\n",
      "    {{- \"Do not use variables.\\n\\n\" }}\n",
      "    {%- for t in tools %}\n",
      "        {{- t | tojson(indent=4) }}\n",
      "        {{- \"\\n\\n\" }}\n",
      "    {%- endfor %}\n",
      "{%- endif %}\n",
      "{{- system_message }}\n",
      "{{- \"<|eot_id|>\" }}\n",
      "\n",
      "{#- Custom tools are passed in a user message with some extra guidance #}\n",
      "{%- if tools_in_user_message and not tools is none %}\n",
      "    {#- Extract the first user message so we can plug it in here #}\n",
      "    {%- if messages | length != 0 %}\n",
      "        {%- set first_user_message = messages[0]['content']|trim %}\n",
      "        {%- set messages = messages[1:] %}\n",
      "    {%- else %}\n",
      "        {{- raise_exception(\"Cannot put tools in the first user message when there's no first user message!\") }}\n",
      "{%- endif %}\n",
      "    {{- '<|start_header_id|>user<|end_header_id|>\\n\\n' -}}\n",
      "    {{- \"Given the following functions, please respond with a JSON for a function call \" }}\n",
      "    {{- \"with its proper arguments that best answers the given prompt.\\n\\n\" }}\n",
      "    {{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}\n",
      "    {{- \"Do not use variables.\\n\\n\" }}\n",
      "    {%- for t in tools %}\n",
      "        {{- t | tojson(indent=4) }}\n",
      "        {{- \"\\n\\n\" }}\n",
      "    {%- endfor %}\n",
      "    {{- first_user_message + \"<|eot_id|>\"}}\n",
      "{%- endif %}\n",
      "\n",
      "{%- for message in messages %}\n",
      "    {%- if not (message.role == 'ipython' or message.role == 'tool' or 'tool_calls' in message) %}\n",
      "        {{- '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n'+ message['content'] | trim + '<|eot_id|>' }}\n",
      "    {%- elif 'tool_calls' in message %}\n",
      "        {%- if not message.tool_calls|length == 1 %}\n",
      "            {{- raise_exception(\"This model only supports single tool-calls at once!\") }}\n",
      "        {%- endif %}\n",
      "        {%- set tool_call = message.tool_calls[0].function %}\n",
      "        {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' -}}\n",
      "        {{- '{\"name\": \"' + tool_call.name + '\", ' }}\n",
      "        {{- '\"parameters\": ' }}\n",
      "        {{- tool_call.arguments | tojson }}\n",
      "        {{- \"}\" }}\n",
      "        {{- \"<|eot_id|>\" }}\n",
      "    {%- elif message.role == \"tool\" or message.role == \"ipython\" %}\n",
      "        {{- \"<|start_header_id|>ipython<|end_header_id|>\\n\\n\" }}\n",
      "        {%- if message.content is mapping or message.content is iterable %}\n",
      "            {{- message.content | tojson }}\n",
      "        {%- else %}\n",
      "            {{- message.content }}\n",
      "        {%- endif %}\n",
      "        {{- \"<|eot_id|>\" }}\n",
      "    {%- endif %}\n",
      "{%- endfor %}\n",
      "{%- if add_generation_prompt %}\n",
      "    {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' }}\n",
      "{%- endif %}\n",
      "\n",
      "INFO:gguf.gguf_writer:Writing the following files:\n",
      "INFO:gguf.gguf_writer:/home/ubuntu/ideal-palm-tree/notebooks/tituslhy/llama32_1bn_raft_non_traditional_credentials_v2/unsloth.BF16.gguf: n_tensors = 147, total_size = 2.5G\n",
      "Writing: 100%|██████████| 2.47G/2.47G [00:31<00:00, 79.7Mbyte/s]\n",
      "INFO:hf-to-gguf:Model successfully exported to /home/ubuntu/ideal-palm-tree/notebooks/tituslhy/llama32_1bn_raft_non_traditional_credentials_v2/unsloth.BF16.gguf\n",
      "Unsloth: Conversion completed! Output location: /home/ubuntu/ideal-palm-tree/notebooks/tituslhy/llama32_1bn_raft_non_traditional_credentials_v2/unsloth.BF16.gguf\n",
      "Unsloth: [2] Converting GGUF 16bit into q4_k_m. This might take 20 minutes...\n",
      "main: build = 5361 (cf0a43bb)\n",
      "main: built with cc (Ubuntu 13.3.0-6ubuntu2~24.04) 13.3.0 for x86_64-linux-gnu\n",
      "main: quantizing '/home/ubuntu/ideal-palm-tree/notebooks/tituslhy/llama32_1bn_raft_non_traditional_credentials_v2/unsloth.BF16.gguf' to '/home/ubuntu/ideal-palm-tree/notebooks/tituslhy/llama32_1bn_raft_non_traditional_credentials_v2/unsloth.Q4_K_M.gguf' as Q4_K_M using 8 threads\n",
      "llama_model_loader: loaded meta data with 28 key-value pairs and 147 tensors from /home/ubuntu/ideal-palm-tree/notebooks/tituslhy/llama32_1bn_raft_non_traditional_credentials_v2/unsloth.BF16.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.type str              = model\n",
      "llama_model_loader: - kv   2:                               general.name str              = Llama32_1Bn_Raft_Non_Traditional_Cred...\n",
      "llama_model_loader: - kv   3:                         general.size_label str              = 1.2B\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 16\n",
      "llama_model_loader: - kv   5:                       llama.context_length u32              = 131072\n",
      "llama_model_loader: - kv   6:                     llama.embedding_length u32              = 2048\n",
      "llama_model_loader: - kv   7:                  llama.feed_forward_length u32              = 8192\n",
      "llama_model_loader: - kv   8:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   9:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 500000.000000\n",
      "llama_model_loader: - kv  11:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  12:                 llama.attention.key_length u32              = 64\n",
      "llama_model_loader: - kv  13:               llama.attention.value_length u32              = 64\n",
      "llama_model_loader: - kv  14:                          general.file_type u32              = 32\n",
      "llama_model_loader: - kv  15:                           llama.vocab_size u32              = 128256\n",
      "llama_model_loader: - kv  16:                 llama.rope.dimension_count u32              = 64\n",
      "llama_model_loader: - kv  17:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - kv  18:                       tokenizer.ggml.model str              = gpt2\n",
      "llama_model_loader: - kv  19:                         tokenizer.ggml.pre str              = llama-bpe\n",
      "llama_model_loader: - kv  20:                      tokenizer.ggml.tokens arr[str,128256]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
      "llama_model_loader: - kv  21:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
      "llama_model_loader: - kv  22:                      tokenizer.ggml.merges arr[str,280147]  = [\"Ġ Ġ\", \"Ġ ĠĠĠ\", \"ĠĠ ĠĠ\", \"...\n",
      "llama_model_loader: - kv  23:                tokenizer.ggml.bos_token_id u32              = 128000\n",
      "llama_model_loader: - kv  24:                tokenizer.ggml.eos_token_id u32              = 128009\n",
      "llama_model_loader: - kv  25:            tokenizer.ggml.padding_token_id u32              = 128004\n",
      "llama_model_loader: - kv  26:               tokenizer.ggml.add_bos_token bool             = true\n",
      "llama_model_loader: - kv  27:                    tokenizer.chat_template str              = {{- bos_token }}\\n{%- if custom_tools ...\n",
      "llama_model_loader: - type  f32:   34 tensors\n",
      "llama_model_loader: - type bf16:  113 tensors\n",
      "[   1/ 147]                   output_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
      "[   2/ 147]                    rope_freqs.weight - [   32,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[   3/ 147]                    token_embd.weight - [ 2048, 128256,     1,     1], type =   bf16, converting to q6_K .. size =   501.00 MiB ->   205.49 MiB\n",
      "[   4/ 147]                  blk.0.attn_k.weight - [ 2048,   512,     1,     1], type =   bf16, converting to q4_K .. size =     2.00 MiB ->     0.56 MiB\n",
      "[   5/ 147]               blk.0.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
      "[   6/ 147]             blk.0.attn_output.weight - [ 2048,  2048,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[   7/ 147]                  blk.0.attn_q.weight - [ 2048,  2048,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[   8/ 147]                  blk.0.attn_v.weight - [ 2048,   512,     1,     1], type =   bf16, converting to q6_K .. size =     2.00 MiB ->     0.82 MiB\n",
      "[   9/ 147]                blk.0.ffn_down.weight - [ 8192,  2048,     1,     1], type =   bf16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
      "[  10/ 147]                blk.0.ffn_gate.weight - [ 2048,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[  11/ 147]                blk.0.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
      "[  12/ 147]                  blk.0.ffn_up.weight - [ 2048,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[  13/ 147]                  blk.1.attn_k.weight - [ 2048,   512,     1,     1], type =   bf16, converting to q4_K .. size =     2.00 MiB ->     0.56 MiB\n",
      "[  14/ 147]               blk.1.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
      "[  15/ 147]             blk.1.attn_output.weight - [ 2048,  2048,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[  16/ 147]                  blk.1.attn_q.weight - [ 2048,  2048,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[  17/ 147]                  blk.1.attn_v.weight - [ 2048,   512,     1,     1], type =   bf16, converting to q6_K .. size =     2.00 MiB ->     0.82 MiB\n",
      "[  18/ 147]                blk.1.ffn_down.weight - [ 8192,  2048,     1,     1], type =   bf16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
      "[  19/ 147]                blk.1.ffn_gate.weight - [ 2048,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[  20/ 147]                blk.1.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
      "[  21/ 147]                  blk.1.ffn_up.weight - [ 2048,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[  22/ 147]                  blk.2.attn_k.weight - [ 2048,   512,     1,     1], type =   bf16, converting to q4_K .. size =     2.00 MiB ->     0.56 MiB\n",
      "[  23/ 147]               blk.2.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
      "[  24/ 147]             blk.2.attn_output.weight - [ 2048,  2048,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[  25/ 147]                  blk.2.attn_q.weight - [ 2048,  2048,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[  26/ 147]                  blk.2.attn_v.weight - [ 2048,   512,     1,     1], type =   bf16, converting to q4_K .. size =     2.00 MiB ->     0.56 MiB\n",
      "[  27/ 147]                blk.2.ffn_down.weight - [ 8192,  2048,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[  28/ 147]                blk.2.ffn_gate.weight - [ 2048,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[  29/ 147]                blk.2.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
      "[  30/ 147]                  blk.2.ffn_up.weight - [ 2048,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[  31/ 147]                  blk.3.attn_k.weight - [ 2048,   512,     1,     1], type =   bf16, converting to q4_K .. size =     2.00 MiB ->     0.56 MiB\n",
      "[  32/ 147]               blk.3.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
      "[  33/ 147]             blk.3.attn_output.weight - [ 2048,  2048,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[  34/ 147]                  blk.3.attn_q.weight - [ 2048,  2048,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[  35/ 147]                  blk.3.attn_v.weight - [ 2048,   512,     1,     1], type =   bf16, converting to q4_K .. size =     2.00 MiB ->     0.56 MiB\n",
      "[  36/ 147]                blk.3.ffn_down.weight - [ 8192,  2048,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[  37/ 147]                blk.3.ffn_gate.weight - [ 2048,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[  38/ 147]                blk.3.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
      "[  39/ 147]                  blk.3.ffn_up.weight - [ 2048,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[  40/ 147]                  blk.4.attn_k.weight - [ 2048,   512,     1,     1], type =   bf16, converting to q4_K .. size =     2.00 MiB ->     0.56 MiB\n",
      "[  41/ 147]               blk.4.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
      "[  42/ 147]             blk.4.attn_output.weight - [ 2048,  2048,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[  43/ 147]                  blk.4.attn_q.weight - [ 2048,  2048,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[  44/ 147]                  blk.4.attn_v.weight - [ 2048,   512,     1,     1], type =   bf16, converting to q6_K .. size =     2.00 MiB ->     0.82 MiB\n",
      "[  45/ 147]                blk.4.ffn_down.weight - [ 8192,  2048,     1,     1], type =   bf16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
      "[  46/ 147]                blk.4.ffn_gate.weight - [ 2048,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[  47/ 147]                blk.4.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
      "[  48/ 147]                  blk.4.ffn_up.weight - [ 2048,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[  49/ 147]                  blk.5.attn_k.weight - [ 2048,   512,     1,     1], type =   bf16, converting to q4_K .. size =     2.00 MiB ->     0.56 MiB\n",
      "[  50/ 147]               blk.5.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
      "[  51/ 147]             blk.5.attn_output.weight - [ 2048,  2048,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[  52/ 147]                  blk.5.attn_q.weight - [ 2048,  2048,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[  53/ 147]                  blk.5.attn_v.weight - [ 2048,   512,     1,     1], type =   bf16, converting to q4_K .. size =     2.00 MiB ->     0.56 MiB\n",
      "[  54/ 147]                blk.5.ffn_down.weight - [ 8192,  2048,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[  55/ 147]                blk.5.ffn_gate.weight - [ 2048,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[  56/ 147]                blk.5.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
      "[  57/ 147]                  blk.5.ffn_up.weight - [ 2048,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[  58/ 147]                  blk.6.attn_k.weight - [ 2048,   512,     1,     1], type =   bf16, converting to q4_K .. size =     2.00 MiB ->     0.56 MiB\n",
      "[  59/ 147]               blk.6.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
      "[  60/ 147]             blk.6.attn_output.weight - [ 2048,  2048,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[  61/ 147]                  blk.6.attn_q.weight - [ 2048,  2048,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[  62/ 147]                  blk.6.attn_v.weight - [ 2048,   512,     1,     1], type =   bf16, converting to q4_K .. size =     2.00 MiB ->     0.56 MiB\n",
      "[  63/ 147]                blk.6.ffn_down.weight - [ 8192,  2048,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[  64/ 147]                blk.6.ffn_gate.weight - [ 2048,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[  65/ 147]                blk.6.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
      "[  66/ 147]                  blk.6.ffn_up.weight - [ 2048,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[  67/ 147]                  blk.7.attn_k.weight - [ 2048,   512,     1,     1], type =   bf16, converting to q4_K .. size =     2.00 MiB ->     0.56 MiB\n",
      "[  68/ 147]               blk.7.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
      "[  69/ 147]             blk.7.attn_output.weight - [ 2048,  2048,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[  70/ 147]                  blk.7.attn_q.weight - [ 2048,  2048,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[  71/ 147]                  blk.7.attn_v.weight - [ 2048,   512,     1,     1], type =   bf16, converting to q6_K .. size =     2.00 MiB ->     0.82 MiB\n",
      "[  72/ 147]                blk.7.ffn_down.weight - [ 8192,  2048,     1,     1], type =   bf16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
      "[  73/ 147]                blk.7.ffn_gate.weight - [ 2048,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[  74/ 147]                blk.7.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
      "[  75/ 147]                  blk.7.ffn_up.weight - [ 2048,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[  76/ 147]                  blk.8.attn_k.weight - [ 2048,   512,     1,     1], type =   bf16, converting to q4_K .. size =     2.00 MiB ->     0.56 MiB\n",
      "[  77/ 147]               blk.8.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
      "[  78/ 147]             blk.8.attn_output.weight - [ 2048,  2048,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[  79/ 147]                  blk.8.attn_q.weight - [ 2048,  2048,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[  80/ 147]                  blk.8.attn_v.weight - [ 2048,   512,     1,     1], type =   bf16, converting to q4_K .. size =     2.00 MiB ->     0.56 MiB\n",
      "[  81/ 147]                blk.8.ffn_down.weight - [ 8192,  2048,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[  82/ 147]                blk.8.ffn_gate.weight - [ 2048,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[  83/ 147]                blk.8.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
      "[  84/ 147]                  blk.8.ffn_up.weight - [ 2048,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[  85/ 147]                  blk.9.attn_k.weight - [ 2048,   512,     1,     1], type =   bf16, converting to q4_K .. size =     2.00 MiB ->     0.56 MiB\n",
      "[  86/ 147]               blk.9.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
      "[  87/ 147]             blk.9.attn_output.weight - [ 2048,  2048,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[  88/ 147]                  blk.9.attn_q.weight - [ 2048,  2048,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[  89/ 147]                  blk.9.attn_v.weight - [ 2048,   512,     1,     1], type =   bf16, converting to q4_K .. size =     2.00 MiB ->     0.56 MiB\n",
      "[  90/ 147]                blk.9.ffn_down.weight - [ 8192,  2048,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[  91/ 147]                blk.9.ffn_gate.weight - [ 2048,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[  92/ 147]                blk.9.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
      "[  93/ 147]                  blk.9.ffn_up.weight - [ 2048,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[  94/ 147]                 blk.10.attn_k.weight - [ 2048,   512,     1,     1], type =   bf16, converting to q4_K .. size =     2.00 MiB ->     0.56 MiB\n",
      "[  95/ 147]              blk.10.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
      "[  96/ 147]            blk.10.attn_output.weight - [ 2048,  2048,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[  97/ 147]                 blk.10.attn_q.weight - [ 2048,  2048,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[  98/ 147]                 blk.10.attn_v.weight - [ 2048,   512,     1,     1], type =   bf16, converting to q6_K .. size =     2.00 MiB ->     0.82 MiB\n",
      "[  99/ 147]               blk.10.ffn_down.weight - [ 8192,  2048,     1,     1], type =   bf16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
      "[ 100/ 147]               blk.10.ffn_gate.weight - [ 2048,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[ 101/ 147]               blk.10.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
      "[ 102/ 147]                 blk.10.ffn_up.weight - [ 2048,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[ 103/ 147]                 blk.11.attn_k.weight - [ 2048,   512,     1,     1], type =   bf16, converting to q4_K .. size =     2.00 MiB ->     0.56 MiB\n",
      "[ 104/ 147]              blk.11.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
      "[ 105/ 147]            blk.11.attn_output.weight - [ 2048,  2048,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[ 106/ 147]                 blk.11.attn_q.weight - [ 2048,  2048,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[ 107/ 147]                 blk.11.attn_v.weight - [ 2048,   512,     1,     1], type =   bf16, converting to q4_K .. size =     2.00 MiB ->     0.56 MiB\n",
      "[ 108/ 147]               blk.11.ffn_down.weight - [ 8192,  2048,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[ 109/ 147]               blk.11.ffn_gate.weight - [ 2048,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[ 110/ 147]               blk.11.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
      "[ 111/ 147]                 blk.11.ffn_up.weight - [ 2048,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[ 112/ 147]                 blk.12.attn_k.weight - [ 2048,   512,     1,     1], type =   bf16, converting to q4_K .. size =     2.00 MiB ->     0.56 MiB\n",
      "[ 113/ 147]              blk.12.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
      "[ 114/ 147]            blk.12.attn_output.weight - [ 2048,  2048,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[ 115/ 147]                 blk.12.attn_q.weight - [ 2048,  2048,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[ 116/ 147]                 blk.12.attn_v.weight - [ 2048,   512,     1,     1], type =   bf16, converting to q4_K .. size =     2.00 MiB ->     0.56 MiB\n",
      "[ 117/ 147]               blk.12.ffn_down.weight - [ 8192,  2048,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[ 118/ 147]               blk.12.ffn_gate.weight - [ 2048,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[ 119/ 147]               blk.12.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
      "[ 120/ 147]                 blk.12.ffn_up.weight - [ 2048,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[ 121/ 147]                 blk.13.attn_k.weight - [ 2048,   512,     1,     1], type =   bf16, converting to q4_K .. size =     2.00 MiB ->     0.56 MiB\n",
      "[ 122/ 147]              blk.13.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
      "[ 123/ 147]            blk.13.attn_output.weight - [ 2048,  2048,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[ 124/ 147]                 blk.13.attn_q.weight - [ 2048,  2048,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[ 125/ 147]                 blk.13.attn_v.weight - [ 2048,   512,     1,     1], type =   bf16, converting to q6_K .. size =     2.00 MiB ->     0.82 MiB\n",
      "[ 126/ 147]               blk.13.ffn_down.weight - [ 8192,  2048,     1,     1], type =   bf16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
      "[ 127/ 147]               blk.13.ffn_gate.weight - [ 2048,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[ 128/ 147]               blk.13.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
      "[ 129/ 147]                 blk.13.ffn_up.weight - [ 2048,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[ 130/ 147]                 blk.14.attn_k.weight - [ 2048,   512,     1,     1], type =   bf16, converting to q4_K .. size =     2.00 MiB ->     0.56 MiB\n",
      "[ 131/ 147]              blk.14.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
      "[ 132/ 147]            blk.14.attn_output.weight - [ 2048,  2048,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[ 133/ 147]                 blk.14.attn_q.weight - [ 2048,  2048,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[ 134/ 147]                 blk.14.attn_v.weight - [ 2048,   512,     1,     1], type =   bf16, converting to q6_K .. size =     2.00 MiB ->     0.82 MiB\n",
      "[ 135/ 147]               blk.14.ffn_down.weight - [ 8192,  2048,     1,     1], type =   bf16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
      "[ 136/ 147]               blk.14.ffn_gate.weight - [ 2048,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[ 137/ 147]               blk.14.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
      "[ 138/ 147]                 blk.14.ffn_up.weight - [ 2048,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[ 139/ 147]                 blk.15.attn_k.weight - [ 2048,   512,     1,     1], type =   bf16, converting to q4_K .. size =     2.00 MiB ->     0.56 MiB\n",
      "[ 140/ 147]              blk.15.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
      "[ 141/ 147]            blk.15.attn_output.weight - [ 2048,  2048,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[ 142/ 147]                 blk.15.attn_q.weight - [ 2048,  2048,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[ 143/ 147]                 blk.15.attn_v.weight - [ 2048,   512,     1,     1], type =   bf16, converting to q6_K .. size =     2.00 MiB ->     0.82 MiB\n",
      "[ 144/ 147]               blk.15.ffn_down.weight - [ 8192,  2048,     1,     1], type =   bf16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
      "[ 145/ 147]               blk.15.ffn_gate.weight - [ 2048,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[ 146/ 147]               blk.15.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
      "[ 147/ 147]                 blk.15.ffn_up.weight - [ 2048,  8192,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "llama_model_quantize_impl: model size  =  2357.26 MB\n",
      "llama_model_quantize_impl: quant size  =   762.81 MB\n",
      "\n",
      "main: quantize time = 49134.93 ms\n",
      "main:    total time = 49134.93 ms\n",
      "Unsloth: Conversion completed! Output location: /home/ubuntu/ideal-palm-tree/notebooks/tituslhy/llama32_1bn_raft_non_traditional_credentials_v2/unsloth.Q4_K_M.gguf\n",
      "Unsloth: [2] Converting GGUF 16bit into q8_0. This might take 20 minutes...\n",
      "main: build = 5361 (cf0a43bb)\n",
      "main: built with cc (Ubuntu 13.3.0-6ubuntu2~24.04) 13.3.0 for x86_64-linux-gnu\n",
      "main: quantizing '/home/ubuntu/ideal-palm-tree/notebooks/tituslhy/llama32_1bn_raft_non_traditional_credentials_v2/unsloth.BF16.gguf' to '/home/ubuntu/ideal-palm-tree/notebooks/tituslhy/llama32_1bn_raft_non_traditional_credentials_v2/unsloth.Q8_0.gguf' as Q8_0 using 8 threads\n",
      "llama_model_loader: loaded meta data with 28 key-value pairs and 147 tensors from /home/ubuntu/ideal-palm-tree/notebooks/tituslhy/llama32_1bn_raft_non_traditional_credentials_v2/unsloth.BF16.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.type str              = model\n",
      "llama_model_loader: - kv   2:                               general.name str              = Llama32_1Bn_Raft_Non_Traditional_Cred...\n",
      "llama_model_loader: - kv   3:                         general.size_label str              = 1.2B\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 16\n",
      "llama_model_loader: - kv   5:                       llama.context_length u32              = 131072\n",
      "llama_model_loader: - kv   6:                     llama.embedding_length u32              = 2048\n",
      "llama_model_loader: - kv   7:                  llama.feed_forward_length u32              = 8192\n",
      "llama_model_loader: - kv   8:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   9:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 500000.000000\n",
      "llama_model_loader: - kv  11:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  12:                 llama.attention.key_length u32              = 64\n",
      "llama_model_loader: - kv  13:               llama.attention.value_length u32              = 64\n",
      "llama_model_loader: - kv  14:                          general.file_type u32              = 32\n",
      "llama_model_loader: - kv  15:                           llama.vocab_size u32              = 128256\n",
      "llama_model_loader: - kv  16:                 llama.rope.dimension_count u32              = 64\n",
      "llama_model_loader: - kv  17:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - kv  18:                       tokenizer.ggml.model str              = gpt2\n",
      "llama_model_loader: - kv  19:                         tokenizer.ggml.pre str              = llama-bpe\n",
      "llama_model_loader: - kv  20:                      tokenizer.ggml.tokens arr[str,128256]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
      "llama_model_loader: - kv  21:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
      "llama_model_loader: - kv  22:                      tokenizer.ggml.merges arr[str,280147]  = [\"Ġ Ġ\", \"Ġ ĠĠĠ\", \"ĠĠ ĠĠ\", \"...\n",
      "llama_model_loader: - kv  23:                tokenizer.ggml.bos_token_id u32              = 128000\n",
      "llama_model_loader: - kv  24:                tokenizer.ggml.eos_token_id u32              = 128009\n",
      "llama_model_loader: - kv  25:            tokenizer.ggml.padding_token_id u32              = 128004\n",
      "llama_model_loader: - kv  26:               tokenizer.ggml.add_bos_token bool             = true\n",
      "llama_model_loader: - kv  27:                    tokenizer.chat_template str              = {{- bos_token }}\\n{%- if custom_tools ...\n",
      "llama_model_loader: - type  f32:   34 tensors\n",
      "llama_model_loader: - type bf16:  113 tensors\n",
      "[   1/ 147]                   output_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
      "[   2/ 147]                    rope_freqs.weight - [   32,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[   3/ 147]                    token_embd.weight - [ 2048, 128256,     1,     1], type =   bf16, converting to q8_0 .. size =   501.00 MiB ->   266.16 MiB\n",
      "[   4/ 147]                  blk.0.attn_k.weight - [ 2048,   512,     1,     1], type =   bf16, converting to q8_0 .. size =     2.00 MiB ->     1.06 MiB\n",
      "[   5/ 147]               blk.0.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
      "[   6/ 147]             blk.0.attn_output.weight - [ 2048,  2048,     1,     1], type =   bf16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
      "[   7/ 147]                  blk.0.attn_q.weight - [ 2048,  2048,     1,     1], type =   bf16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
      "[   8/ 147]                  blk.0.attn_v.weight - [ 2048,   512,     1,     1], type =   bf16, converting to q8_0 .. size =     2.00 MiB ->     1.06 MiB\n",
      "[   9/ 147]                blk.0.ffn_down.weight - [ 8192,  2048,     1,     1], type =   bf16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
      "[  10/ 147]                blk.0.ffn_gate.weight - [ 2048,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
      "[  11/ 147]                blk.0.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
      "[  12/ 147]                  blk.0.ffn_up.weight - [ 2048,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
      "[  13/ 147]                  blk.1.attn_k.weight - [ 2048,   512,     1,     1], type =   bf16, converting to q8_0 .. size =     2.00 MiB ->     1.06 MiB\n",
      "[  14/ 147]               blk.1.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
      "[  15/ 147]             blk.1.attn_output.weight - [ 2048,  2048,     1,     1], type =   bf16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
      "[  16/ 147]                  blk.1.attn_q.weight - [ 2048,  2048,     1,     1], type =   bf16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
      "[  17/ 147]                  blk.1.attn_v.weight - [ 2048,   512,     1,     1], type =   bf16, converting to q8_0 .. size =     2.00 MiB ->     1.06 MiB\n",
      "[  18/ 147]                blk.1.ffn_down.weight - [ 8192,  2048,     1,     1], type =   bf16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
      "[  19/ 147]                blk.1.ffn_gate.weight - [ 2048,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
      "[  20/ 147]                blk.1.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
      "[  21/ 147]                  blk.1.ffn_up.weight - [ 2048,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
      "[  22/ 147]                  blk.2.attn_k.weight - [ 2048,   512,     1,     1], type =   bf16, converting to q8_0 .. size =     2.00 MiB ->     1.06 MiB\n",
      "[  23/ 147]               blk.2.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
      "[  24/ 147]             blk.2.attn_output.weight - [ 2048,  2048,     1,     1], type =   bf16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
      "[  25/ 147]                  blk.2.attn_q.weight - [ 2048,  2048,     1,     1], type =   bf16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
      "[  26/ 147]                  blk.2.attn_v.weight - [ 2048,   512,     1,     1], type =   bf16, converting to q8_0 .. size =     2.00 MiB ->     1.06 MiB\n",
      "[  27/ 147]                blk.2.ffn_down.weight - [ 8192,  2048,     1,     1], type =   bf16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
      "[  28/ 147]                blk.2.ffn_gate.weight - [ 2048,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
      "[  29/ 147]                blk.2.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
      "[  30/ 147]                  blk.2.ffn_up.weight - [ 2048,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
      "[  31/ 147]                  blk.3.attn_k.weight - [ 2048,   512,     1,     1], type =   bf16, converting to q8_0 .. size =     2.00 MiB ->     1.06 MiB\n",
      "[  32/ 147]               blk.3.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
      "[  33/ 147]             blk.3.attn_output.weight - [ 2048,  2048,     1,     1], type =   bf16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
      "[  34/ 147]                  blk.3.attn_q.weight - [ 2048,  2048,     1,     1], type =   bf16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
      "[  35/ 147]                  blk.3.attn_v.weight - [ 2048,   512,     1,     1], type =   bf16, converting to q8_0 .. size =     2.00 MiB ->     1.06 MiB\n",
      "[  36/ 147]                blk.3.ffn_down.weight - [ 8192,  2048,     1,     1], type =   bf16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
      "[  37/ 147]                blk.3.ffn_gate.weight - [ 2048,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
      "[  38/ 147]                blk.3.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
      "[  39/ 147]                  blk.3.ffn_up.weight - [ 2048,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
      "[  40/ 147]                  blk.4.attn_k.weight - [ 2048,   512,     1,     1], type =   bf16, converting to q8_0 .. size =     2.00 MiB ->     1.06 MiB\n",
      "[  41/ 147]               blk.4.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
      "[  42/ 147]             blk.4.attn_output.weight - [ 2048,  2048,     1,     1], type =   bf16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
      "[  43/ 147]                  blk.4.attn_q.weight - [ 2048,  2048,     1,     1], type =   bf16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
      "[  44/ 147]                  blk.4.attn_v.weight - [ 2048,   512,     1,     1], type =   bf16, converting to q8_0 .. size =     2.00 MiB ->     1.06 MiB\n",
      "[  45/ 147]                blk.4.ffn_down.weight - [ 8192,  2048,     1,     1], type =   bf16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
      "[  46/ 147]                blk.4.ffn_gate.weight - [ 2048,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
      "[  47/ 147]                blk.4.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
      "[  48/ 147]                  blk.4.ffn_up.weight - [ 2048,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
      "[  49/ 147]                  blk.5.attn_k.weight - [ 2048,   512,     1,     1], type =   bf16, converting to q8_0 .. size =     2.00 MiB ->     1.06 MiB\n",
      "[  50/ 147]               blk.5.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
      "[  51/ 147]             blk.5.attn_output.weight - [ 2048,  2048,     1,     1], type =   bf16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
      "[  52/ 147]                  blk.5.attn_q.weight - [ 2048,  2048,     1,     1], type =   bf16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
      "[  53/ 147]                  blk.5.attn_v.weight - [ 2048,   512,     1,     1], type =   bf16, converting to q8_0 .. size =     2.00 MiB ->     1.06 MiB\n",
      "[  54/ 147]                blk.5.ffn_down.weight - [ 8192,  2048,     1,     1], type =   bf16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
      "[  55/ 147]                blk.5.ffn_gate.weight - [ 2048,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
      "[  56/ 147]                blk.5.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
      "[  57/ 147]                  blk.5.ffn_up.weight - [ 2048,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
      "[  58/ 147]                  blk.6.attn_k.weight - [ 2048,   512,     1,     1], type =   bf16, converting to q8_0 .. size =     2.00 MiB ->     1.06 MiB\n",
      "[  59/ 147]               blk.6.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
      "[  60/ 147]             blk.6.attn_output.weight - [ 2048,  2048,     1,     1], type =   bf16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
      "[  61/ 147]                  blk.6.attn_q.weight - [ 2048,  2048,     1,     1], type =   bf16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
      "[  62/ 147]                  blk.6.attn_v.weight - [ 2048,   512,     1,     1], type =   bf16, converting to q8_0 .. size =     2.00 MiB ->     1.06 MiB\n",
      "[  63/ 147]                blk.6.ffn_down.weight - [ 8192,  2048,     1,     1], type =   bf16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
      "[  64/ 147]                blk.6.ffn_gate.weight - [ 2048,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
      "[  65/ 147]                blk.6.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
      "[  66/ 147]                  blk.6.ffn_up.weight - [ 2048,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
      "[  67/ 147]                  blk.7.attn_k.weight - [ 2048,   512,     1,     1], type =   bf16, converting to q8_0 .. size =     2.00 MiB ->     1.06 MiB\n",
      "[  68/ 147]               blk.7.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
      "[  69/ 147]             blk.7.attn_output.weight - [ 2048,  2048,     1,     1], type =   bf16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
      "[  70/ 147]                  blk.7.attn_q.weight - [ 2048,  2048,     1,     1], type =   bf16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
      "[  71/ 147]                  blk.7.attn_v.weight - [ 2048,   512,     1,     1], type =   bf16, converting to q8_0 .. size =     2.00 MiB ->     1.06 MiB\n",
      "[  72/ 147]                blk.7.ffn_down.weight - [ 8192,  2048,     1,     1], type =   bf16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
      "[  73/ 147]                blk.7.ffn_gate.weight - [ 2048,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
      "[  74/ 147]                blk.7.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
      "[  75/ 147]                  blk.7.ffn_up.weight - [ 2048,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
      "[  76/ 147]                  blk.8.attn_k.weight - [ 2048,   512,     1,     1], type =   bf16, converting to q8_0 .. size =     2.00 MiB ->     1.06 MiB\n",
      "[  77/ 147]               blk.8.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
      "[  78/ 147]             blk.8.attn_output.weight - [ 2048,  2048,     1,     1], type =   bf16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
      "[  79/ 147]                  blk.8.attn_q.weight - [ 2048,  2048,     1,     1], type =   bf16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
      "[  80/ 147]                  blk.8.attn_v.weight - [ 2048,   512,     1,     1], type =   bf16, converting to q8_0 .. size =     2.00 MiB ->     1.06 MiB\n",
      "[  81/ 147]                blk.8.ffn_down.weight - [ 8192,  2048,     1,     1], type =   bf16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
      "[  82/ 147]                blk.8.ffn_gate.weight - [ 2048,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
      "[  83/ 147]                blk.8.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
      "[  84/ 147]                  blk.8.ffn_up.weight - [ 2048,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
      "[  85/ 147]                  blk.9.attn_k.weight - [ 2048,   512,     1,     1], type =   bf16, converting to q8_0 .. size =     2.00 MiB ->     1.06 MiB\n",
      "[  86/ 147]               blk.9.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
      "[  87/ 147]             blk.9.attn_output.weight - [ 2048,  2048,     1,     1], type =   bf16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
      "[  88/ 147]                  blk.9.attn_q.weight - [ 2048,  2048,     1,     1], type =   bf16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
      "[  89/ 147]                  blk.9.attn_v.weight - [ 2048,   512,     1,     1], type =   bf16, converting to q8_0 .. size =     2.00 MiB ->     1.06 MiB\n",
      "[  90/ 147]                blk.9.ffn_down.weight - [ 8192,  2048,     1,     1], type =   bf16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
      "[  91/ 147]                blk.9.ffn_gate.weight - [ 2048,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
      "[  92/ 147]                blk.9.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
      "[  93/ 147]                  blk.9.ffn_up.weight - [ 2048,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
      "[  94/ 147]                 blk.10.attn_k.weight - [ 2048,   512,     1,     1], type =   bf16, converting to q8_0 .. size =     2.00 MiB ->     1.06 MiB\n",
      "[  95/ 147]              blk.10.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
      "[  96/ 147]            blk.10.attn_output.weight - [ 2048,  2048,     1,     1], type =   bf16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
      "[  97/ 147]                 blk.10.attn_q.weight - [ 2048,  2048,     1,     1], type =   bf16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
      "[  98/ 147]                 blk.10.attn_v.weight - [ 2048,   512,     1,     1], type =   bf16, converting to q8_0 .. size =     2.00 MiB ->     1.06 MiB\n",
      "[  99/ 147]               blk.10.ffn_down.weight - [ 8192,  2048,     1,     1], type =   bf16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
      "[ 100/ 147]               blk.10.ffn_gate.weight - [ 2048,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
      "[ 101/ 147]               blk.10.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
      "[ 102/ 147]                 blk.10.ffn_up.weight - [ 2048,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
      "[ 103/ 147]                 blk.11.attn_k.weight - [ 2048,   512,     1,     1], type =   bf16, converting to q8_0 .. size =     2.00 MiB ->     1.06 MiB\n",
      "[ 104/ 147]              blk.11.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
      "[ 105/ 147]            blk.11.attn_output.weight - [ 2048,  2048,     1,     1], type =   bf16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
      "[ 106/ 147]                 blk.11.attn_q.weight - [ 2048,  2048,     1,     1], type =   bf16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
      "[ 107/ 147]                 blk.11.attn_v.weight - [ 2048,   512,     1,     1], type =   bf16, converting to q8_0 .. size =     2.00 MiB ->     1.06 MiB\n",
      "[ 108/ 147]               blk.11.ffn_down.weight - [ 8192,  2048,     1,     1], type =   bf16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
      "[ 109/ 147]               blk.11.ffn_gate.weight - [ 2048,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
      "[ 110/ 147]               blk.11.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
      "[ 111/ 147]                 blk.11.ffn_up.weight - [ 2048,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
      "[ 112/ 147]                 blk.12.attn_k.weight - [ 2048,   512,     1,     1], type =   bf16, converting to q8_0 .. size =     2.00 MiB ->     1.06 MiB\n",
      "[ 113/ 147]              blk.12.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
      "[ 114/ 147]            blk.12.attn_output.weight - [ 2048,  2048,     1,     1], type =   bf16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
      "[ 115/ 147]                 blk.12.attn_q.weight - [ 2048,  2048,     1,     1], type =   bf16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
      "[ 116/ 147]                 blk.12.attn_v.weight - [ 2048,   512,     1,     1], type =   bf16, converting to q8_0 .. size =     2.00 MiB ->     1.06 MiB\n",
      "[ 117/ 147]               blk.12.ffn_down.weight - [ 8192,  2048,     1,     1], type =   bf16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
      "[ 118/ 147]               blk.12.ffn_gate.weight - [ 2048,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
      "[ 119/ 147]               blk.12.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
      "[ 120/ 147]                 blk.12.ffn_up.weight - [ 2048,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
      "[ 121/ 147]                 blk.13.attn_k.weight - [ 2048,   512,     1,     1], type =   bf16, converting to q8_0 .. size =     2.00 MiB ->     1.06 MiB\n",
      "[ 122/ 147]              blk.13.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
      "[ 123/ 147]            blk.13.attn_output.weight - [ 2048,  2048,     1,     1], type =   bf16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
      "[ 124/ 147]                 blk.13.attn_q.weight - [ 2048,  2048,     1,     1], type =   bf16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
      "[ 125/ 147]                 blk.13.attn_v.weight - [ 2048,   512,     1,     1], type =   bf16, converting to q8_0 .. size =     2.00 MiB ->     1.06 MiB\n",
      "[ 126/ 147]               blk.13.ffn_down.weight - [ 8192,  2048,     1,     1], type =   bf16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
      "[ 127/ 147]               blk.13.ffn_gate.weight - [ 2048,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
      "[ 128/ 147]               blk.13.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
      "[ 129/ 147]                 blk.13.ffn_up.weight - [ 2048,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
      "[ 130/ 147]                 blk.14.attn_k.weight - [ 2048,   512,     1,     1], type =   bf16, converting to q8_0 .. size =     2.00 MiB ->     1.06 MiB\n",
      "[ 131/ 147]              blk.14.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
      "[ 132/ 147]            blk.14.attn_output.weight - [ 2048,  2048,     1,     1], type =   bf16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
      "[ 133/ 147]                 blk.14.attn_q.weight - [ 2048,  2048,     1,     1], type =   bf16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
      "[ 134/ 147]                 blk.14.attn_v.weight - [ 2048,   512,     1,     1], type =   bf16, converting to q8_0 .. size =     2.00 MiB ->     1.06 MiB\n",
      "[ 135/ 147]               blk.14.ffn_down.weight - [ 8192,  2048,     1,     1], type =   bf16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
      "[ 136/ 147]               blk.14.ffn_gate.weight - [ 2048,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
      "[ 137/ 147]               blk.14.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
      "[ 138/ 147]                 blk.14.ffn_up.weight - [ 2048,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
      "[ 139/ 147]                 blk.15.attn_k.weight - [ 2048,   512,     1,     1], type =   bf16, converting to q8_0 .. size =     2.00 MiB ->     1.06 MiB\n",
      "[ 140/ 147]              blk.15.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
      "[ 141/ 147]            blk.15.attn_output.weight - [ 2048,  2048,     1,     1], type =   bf16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
      "[ 142/ 147]                 blk.15.attn_q.weight - [ 2048,  2048,     1,     1], type =   bf16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
      "[ 143/ 147]                 blk.15.attn_v.weight - [ 2048,   512,     1,     1], type =   bf16, converting to q8_0 .. size =     2.00 MiB ->     1.06 MiB\n",
      "[ 144/ 147]               blk.15.ffn_down.weight - [ 8192,  2048,     1,     1], type =   bf16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
      "[ 145/ 147]               blk.15.ffn_gate.weight - [ 2048,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
      "[ 146/ 147]               blk.15.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
      "[ 147/ 147]                 blk.15.ffn_up.weight - [ 2048,  8192,     1,     1], type =   bf16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
      "llama_model_quantize_impl: model size  =  2357.26 MB\n",
      "llama_model_quantize_impl: quant size  =  1252.41 MB\n",
      "\n",
      "main: quantize time =  6236.23 ms\n",
      "main:    total time =  6236.23 ms\n",
      "Unsloth: Conversion completed! Output location: /home/ubuntu/ideal-palm-tree/notebooks/tituslhy/llama32_1bn_raft_non_traditional_credentials_v2/unsloth.Q8_0.gguf\n",
      "Unsloth: [2] Converting GGUF 16bit into q5_k_m. This might take 20 minutes...\n",
      "main: build = 5361 (cf0a43bb)\n",
      "main: built with cc (Ubuntu 13.3.0-6ubuntu2~24.04) 13.3.0 for x86_64-linux-gnu\n",
      "main: quantizing '/home/ubuntu/ideal-palm-tree/notebooks/tituslhy/llama32_1bn_raft_non_traditional_credentials_v2/unsloth.BF16.gguf' to '/home/ubuntu/ideal-palm-tree/notebooks/tituslhy/llama32_1bn_raft_non_traditional_credentials_v2/unsloth.Q5_K_M.gguf' as Q5_K_M using 8 threads\n",
      "llama_model_loader: loaded meta data with 28 key-value pairs and 147 tensors from /home/ubuntu/ideal-palm-tree/notebooks/tituslhy/llama32_1bn_raft_non_traditional_credentials_v2/unsloth.BF16.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.type str              = model\n",
      "llama_model_loader: - kv   2:                               general.name str              = Llama32_1Bn_Raft_Non_Traditional_Cred...\n",
      "llama_model_loader: - kv   3:                         general.size_label str              = 1.2B\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 16\n",
      "llama_model_loader: - kv   5:                       llama.context_length u32              = 131072\n",
      "llama_model_loader: - kv   6:                     llama.embedding_length u32              = 2048\n",
      "llama_model_loader: - kv   7:                  llama.feed_forward_length u32              = 8192\n",
      "llama_model_loader: - kv   8:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   9:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 500000.000000\n",
      "llama_model_loader: - kv  11:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  12:                 llama.attention.key_length u32              = 64\n",
      "llama_model_loader: - kv  13:               llama.attention.value_length u32              = 64\n",
      "llama_model_loader: - kv  14:                          general.file_type u32              = 32\n",
      "llama_model_loader: - kv  15:                           llama.vocab_size u32              = 128256\n",
      "llama_model_loader: - kv  16:                 llama.rope.dimension_count u32              = 64\n",
      "llama_model_loader: - kv  17:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - kv  18:                       tokenizer.ggml.model str              = gpt2\n",
      "llama_model_loader: - kv  19:                         tokenizer.ggml.pre str              = llama-bpe\n",
      "llama_model_loader: - kv  20:                      tokenizer.ggml.tokens arr[str,128256]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
      "llama_model_loader: - kv  21:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
      "llama_model_loader: - kv  22:                      tokenizer.ggml.merges arr[str,280147]  = [\"Ġ Ġ\", \"Ġ ĠĠĠ\", \"ĠĠ ĠĠ\", \"...\n",
      "llama_model_loader: - kv  23:                tokenizer.ggml.bos_token_id u32              = 128000\n",
      "llama_model_loader: - kv  24:                tokenizer.ggml.eos_token_id u32              = 128009\n",
      "llama_model_loader: - kv  25:            tokenizer.ggml.padding_token_id u32              = 128004\n",
      "llama_model_loader: - kv  26:               tokenizer.ggml.add_bos_token bool             = true\n",
      "llama_model_loader: - kv  27:                    tokenizer.chat_template str              = {{- bos_token }}\\n{%- if custom_tools ...\n",
      "llama_model_loader: - type  f32:   34 tensors\n",
      "llama_model_loader: - type bf16:  113 tensors\n",
      "[   1/ 147]                   output_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
      "[   2/ 147]                    rope_freqs.weight - [   32,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[   3/ 147]                    token_embd.weight - [ 2048, 128256,     1,     1], type =   bf16, converting to q6_K .. size =   501.00 MiB ->   205.49 MiB\n",
      "[   4/ 147]                  blk.0.attn_k.weight - [ 2048,   512,     1,     1], type =   bf16, converting to q5_K .. size =     2.00 MiB ->     0.69 MiB\n",
      "[   5/ 147]               blk.0.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
      "[   6/ 147]             blk.0.attn_output.weight - [ 2048,  2048,     1,     1], type =   bf16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
      "[   7/ 147]                  blk.0.attn_q.weight - [ 2048,  2048,     1,     1], type =   bf16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
      "[   8/ 147]                  blk.0.attn_v.weight - [ 2048,   512,     1,     1], type =   bf16, converting to q6_K .. size =     2.00 MiB ->     0.82 MiB\n",
      "[   9/ 147]                blk.0.ffn_down.weight - [ 8192,  2048,     1,     1], type =   bf16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
      "[  10/ 147]                blk.0.ffn_gate.weight - [ 2048,  8192,     1,     1], type =   bf16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
      "[  11/ 147]                blk.0.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
      "[  12/ 147]                  blk.0.ffn_up.weight - [ 2048,  8192,     1,     1], type =   bf16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
      "[  13/ 147]                  blk.1.attn_k.weight - [ 2048,   512,     1,     1], type =   bf16, converting to q5_K .. size =     2.00 MiB ->     0.69 MiB\n",
      "[  14/ 147]               blk.1.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
      "[  15/ 147]             blk.1.attn_output.weight - [ 2048,  2048,     1,     1], type =   bf16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
      "[  16/ 147]                  blk.1.attn_q.weight - [ 2048,  2048,     1,     1], type =   bf16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
      "[  17/ 147]                  blk.1.attn_v.weight - [ 2048,   512,     1,     1], type =   bf16, converting to q6_K .. size =     2.00 MiB ->     0.82 MiB\n",
      "[  18/ 147]                blk.1.ffn_down.weight - [ 8192,  2048,     1,     1], type =   bf16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
      "[  19/ 147]                blk.1.ffn_gate.weight - [ 2048,  8192,     1,     1], type =   bf16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
      "[  20/ 147]                blk.1.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
      "[  21/ 147]                  blk.1.ffn_up.weight - [ 2048,  8192,     1,     1], type =   bf16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
      "[  22/ 147]                  blk.2.attn_k.weight - [ 2048,   512,     1,     1], type =   bf16, converting to q5_K .. size =     2.00 MiB ->     0.69 MiB\n",
      "[  23/ 147]               blk.2.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
      "[  24/ 147]             blk.2.attn_output.weight - [ 2048,  2048,     1,     1], type =   bf16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
      "[  25/ 147]                  blk.2.attn_q.weight - [ 2048,  2048,     1,     1], type =   bf16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
      "[  26/ 147]                  blk.2.attn_v.weight - [ 2048,   512,     1,     1], type =   bf16, converting to q5_K .. size =     2.00 MiB ->     0.69 MiB\n",
      "[  27/ 147]                blk.2.ffn_down.weight - [ 8192,  2048,     1,     1], type =   bf16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
      "[  28/ 147]                blk.2.ffn_gate.weight - [ 2048,  8192,     1,     1], type =   bf16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
      "[  29/ 147]                blk.2.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
      "[  30/ 147]                  blk.2.ffn_up.weight - [ 2048,  8192,     1,     1], type =   bf16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
      "[  31/ 147]                  blk.3.attn_k.weight - [ 2048,   512,     1,     1], type =   bf16, converting to q5_K .. size =     2.00 MiB ->     0.69 MiB\n",
      "[  32/ 147]               blk.3.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
      "[  33/ 147]             blk.3.attn_output.weight - [ 2048,  2048,     1,     1], type =   bf16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
      "[  34/ 147]                  blk.3.attn_q.weight - [ 2048,  2048,     1,     1], type =   bf16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
      "[  35/ 147]                  blk.3.attn_v.weight - [ 2048,   512,     1,     1], type =   bf16, converting to q5_K .. size =     2.00 MiB ->     0.69 MiB\n",
      "[  36/ 147]                blk.3.ffn_down.weight - [ 8192,  2048,     1,     1], type =   bf16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
      "[  37/ 147]                blk.3.ffn_gate.weight - [ 2048,  8192,     1,     1], type =   bf16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
      "[  38/ 147]                blk.3.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
      "[  39/ 147]                  blk.3.ffn_up.weight - [ 2048,  8192,     1,     1], type =   bf16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
      "[  40/ 147]                  blk.4.attn_k.weight - [ 2048,   512,     1,     1], type =   bf16, converting to q5_K .. size =     2.00 MiB ->     0.69 MiB\n",
      "[  41/ 147]               blk.4.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
      "[  42/ 147]             blk.4.attn_output.weight - [ 2048,  2048,     1,     1], type =   bf16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
      "[  43/ 147]                  blk.4.attn_q.weight - [ 2048,  2048,     1,     1], type =   bf16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
      "[  44/ 147]                  blk.4.attn_v.weight - [ 2048,   512,     1,     1], type =   bf16, converting to q6_K .. size =     2.00 MiB ->     0.82 MiB\n",
      "[  45/ 147]                blk.4.ffn_down.weight - [ 8192,  2048,     1,     1], type =   bf16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
      "[  46/ 147]                blk.4.ffn_gate.weight - [ 2048,  8192,     1,     1], type =   bf16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
      "[  47/ 147]                blk.4.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
      "[  48/ 147]                  blk.4.ffn_up.weight - [ 2048,  8192,     1,     1], type =   bf16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
      "[  49/ 147]                  blk.5.attn_k.weight - [ 2048,   512,     1,     1], type =   bf16, converting to q5_K .. size =     2.00 MiB ->     0.69 MiB\n",
      "[  50/ 147]               blk.5.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
      "[  51/ 147]             blk.5.attn_output.weight - [ 2048,  2048,     1,     1], type =   bf16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
      "[  52/ 147]                  blk.5.attn_q.weight - [ 2048,  2048,     1,     1], type =   bf16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
      "[  53/ 147]                  blk.5.attn_v.weight - [ 2048,   512,     1,     1], type =   bf16, converting to q5_K .. size =     2.00 MiB ->     0.69 MiB\n",
      "[  54/ 147]                blk.5.ffn_down.weight - [ 8192,  2048,     1,     1], type =   bf16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
      "[  55/ 147]                blk.5.ffn_gate.weight - [ 2048,  8192,     1,     1], type =   bf16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
      "[  56/ 147]                blk.5.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
      "[  57/ 147]                  blk.5.ffn_up.weight - [ 2048,  8192,     1,     1], type =   bf16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
      "[  58/ 147]                  blk.6.attn_k.weight - [ 2048,   512,     1,     1], type =   bf16, converting to q5_K .. size =     2.00 MiB ->     0.69 MiB\n",
      "[  59/ 147]               blk.6.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
      "[  60/ 147]             blk.6.attn_output.weight - [ 2048,  2048,     1,     1], type =   bf16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
      "[  61/ 147]                  blk.6.attn_q.weight - [ 2048,  2048,     1,     1], type =   bf16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
      "[  62/ 147]                  blk.6.attn_v.weight - [ 2048,   512,     1,     1], type =   bf16, converting to q5_K .. size =     2.00 MiB ->     0.69 MiB\n",
      "[  63/ 147]                blk.6.ffn_down.weight - [ 8192,  2048,     1,     1], type =   bf16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
      "[  64/ 147]                blk.6.ffn_gate.weight - [ 2048,  8192,     1,     1], type =   bf16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
      "[  65/ 147]                blk.6.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
      "[  66/ 147]                  blk.6.ffn_up.weight - [ 2048,  8192,     1,     1], type =   bf16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
      "[  67/ 147]                  blk.7.attn_k.weight - [ 2048,   512,     1,     1], type =   bf16, converting to q5_K .. size =     2.00 MiB ->     0.69 MiB\n",
      "[  68/ 147]               blk.7.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
      "[  69/ 147]             blk.7.attn_output.weight - [ 2048,  2048,     1,     1], type =   bf16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
      "[  70/ 147]                  blk.7.attn_q.weight - [ 2048,  2048,     1,     1], type =   bf16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
      "[  71/ 147]                  blk.7.attn_v.weight - [ 2048,   512,     1,     1], type =   bf16, converting to q6_K .. size =     2.00 MiB ->     0.82 MiB\n",
      "[  72/ 147]                blk.7.ffn_down.weight - [ 8192,  2048,     1,     1], type =   bf16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
      "[  73/ 147]                blk.7.ffn_gate.weight - [ 2048,  8192,     1,     1], type =   bf16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
      "[  74/ 147]                blk.7.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
      "[  75/ 147]                  blk.7.ffn_up.weight - [ 2048,  8192,     1,     1], type =   bf16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
      "[  76/ 147]                  blk.8.attn_k.weight - [ 2048,   512,     1,     1], type =   bf16, converting to q5_K .. size =     2.00 MiB ->     0.69 MiB\n",
      "[  77/ 147]               blk.8.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
      "[  78/ 147]             blk.8.attn_output.weight - [ 2048,  2048,     1,     1], type =   bf16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
      "[  79/ 147]                  blk.8.attn_q.weight - [ 2048,  2048,     1,     1], type =   bf16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
      "[  80/ 147]                  blk.8.attn_v.weight - [ 2048,   512,     1,     1], type =   bf16, converting to q5_K .. size =     2.00 MiB ->     0.69 MiB\n",
      "[  81/ 147]                blk.8.ffn_down.weight - [ 8192,  2048,     1,     1], type =   bf16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
      "[  82/ 147]                blk.8.ffn_gate.weight - [ 2048,  8192,     1,     1], type =   bf16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
      "[  83/ 147]                blk.8.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
      "[  84/ 147]                  blk.8.ffn_up.weight - [ 2048,  8192,     1,     1], type =   bf16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
      "[  85/ 147]                  blk.9.attn_k.weight - [ 2048,   512,     1,     1], type =   bf16, converting to q5_K .. size =     2.00 MiB ->     0.69 MiB\n",
      "[  86/ 147]               blk.9.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
      "[  87/ 147]             blk.9.attn_output.weight - [ 2048,  2048,     1,     1], type =   bf16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
      "[  88/ 147]                  blk.9.attn_q.weight - [ 2048,  2048,     1,     1], type =   bf16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
      "[  89/ 147]                  blk.9.attn_v.weight - [ 2048,   512,     1,     1], type =   bf16, converting to q5_K .. size =     2.00 MiB ->     0.69 MiB\n",
      "[  90/ 147]                blk.9.ffn_down.weight - [ 8192,  2048,     1,     1], type =   bf16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
      "[  91/ 147]                blk.9.ffn_gate.weight - [ 2048,  8192,     1,     1], type =   bf16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
      "[  92/ 147]                blk.9.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
      "[  93/ 147]                  blk.9.ffn_up.weight - [ 2048,  8192,     1,     1], type =   bf16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
      "[  94/ 147]                 blk.10.attn_k.weight - [ 2048,   512,     1,     1], type =   bf16, converting to q5_K .. size =     2.00 MiB ->     0.69 MiB\n",
      "[  95/ 147]              blk.10.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
      "[  96/ 147]            blk.10.attn_output.weight - [ 2048,  2048,     1,     1], type =   bf16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
      "[  97/ 147]                 blk.10.attn_q.weight - [ 2048,  2048,     1,     1], type =   bf16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
      "[  98/ 147]                 blk.10.attn_v.weight - [ 2048,   512,     1,     1], type =   bf16, converting to q6_K .. size =     2.00 MiB ->     0.82 MiB\n",
      "[  99/ 147]               blk.10.ffn_down.weight - [ 8192,  2048,     1,     1], type =   bf16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
      "[ 100/ 147]               blk.10.ffn_gate.weight - [ 2048,  8192,     1,     1], type =   bf16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
      "[ 101/ 147]               blk.10.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
      "[ 102/ 147]                 blk.10.ffn_up.weight - [ 2048,  8192,     1,     1], type =   bf16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
      "[ 103/ 147]                 blk.11.attn_k.weight - [ 2048,   512,     1,     1], type =   bf16, converting to q5_K .. size =     2.00 MiB ->     0.69 MiB\n",
      "[ 104/ 147]              blk.11.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
      "[ 105/ 147]            blk.11.attn_output.weight - [ 2048,  2048,     1,     1], type =   bf16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
      "[ 106/ 147]                 blk.11.attn_q.weight - [ 2048,  2048,     1,     1], type =   bf16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
      "[ 107/ 147]                 blk.11.attn_v.weight - [ 2048,   512,     1,     1], type =   bf16, converting to q5_K .. size =     2.00 MiB ->     0.69 MiB\n",
      "[ 108/ 147]               blk.11.ffn_down.weight - [ 8192,  2048,     1,     1], type =   bf16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
      "[ 109/ 147]               blk.11.ffn_gate.weight - [ 2048,  8192,     1,     1], type =   bf16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
      "[ 110/ 147]               blk.11.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
      "[ 111/ 147]                 blk.11.ffn_up.weight - [ 2048,  8192,     1,     1], type =   bf16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
      "[ 112/ 147]                 blk.12.attn_k.weight - [ 2048,   512,     1,     1], type =   bf16, converting to q5_K .. size =     2.00 MiB ->     0.69 MiB\n",
      "[ 113/ 147]              blk.12.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
      "[ 114/ 147]            blk.12.attn_output.weight - [ 2048,  2048,     1,     1], type =   bf16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
      "[ 115/ 147]                 blk.12.attn_q.weight - [ 2048,  2048,     1,     1], type =   bf16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
      "[ 116/ 147]                 blk.12.attn_v.weight - [ 2048,   512,     1,     1], type =   bf16, converting to q5_K .. size =     2.00 MiB ->     0.69 MiB\n",
      "[ 117/ 147]               blk.12.ffn_down.weight - [ 8192,  2048,     1,     1], type =   bf16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
      "[ 118/ 147]               blk.12.ffn_gate.weight - [ 2048,  8192,     1,     1], type =   bf16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
      "[ 119/ 147]               blk.12.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
      "[ 120/ 147]                 blk.12.ffn_up.weight - [ 2048,  8192,     1,     1], type =   bf16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
      "[ 121/ 147]                 blk.13.attn_k.weight - [ 2048,   512,     1,     1], type =   bf16, converting to q5_K .. size =     2.00 MiB ->     0.69 MiB\n",
      "[ 122/ 147]              blk.13.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
      "[ 123/ 147]            blk.13.attn_output.weight - [ 2048,  2048,     1,     1], type =   bf16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
      "[ 124/ 147]                 blk.13.attn_q.weight - [ 2048,  2048,     1,     1], type =   bf16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
      "[ 125/ 147]                 blk.13.attn_v.weight - [ 2048,   512,     1,     1], type =   bf16, converting to q6_K .. size =     2.00 MiB ->     0.82 MiB\n",
      "[ 126/ 147]               blk.13.ffn_down.weight - [ 8192,  2048,     1,     1], type =   bf16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
      "[ 127/ 147]               blk.13.ffn_gate.weight - [ 2048,  8192,     1,     1], type =   bf16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
      "[ 128/ 147]               blk.13.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
      "[ 129/ 147]                 blk.13.ffn_up.weight - [ 2048,  8192,     1,     1], type =   bf16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
      "[ 130/ 147]                 blk.14.attn_k.weight - [ 2048,   512,     1,     1], type =   bf16, converting to q5_K .. size =     2.00 MiB ->     0.69 MiB\n",
      "[ 131/ 147]              blk.14.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
      "[ 132/ 147]            blk.14.attn_output.weight - [ 2048,  2048,     1,     1], type =   bf16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
      "[ 133/ 147]                 blk.14.attn_q.weight - [ 2048,  2048,     1,     1], type =   bf16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
      "[ 134/ 147]                 blk.14.attn_v.weight - [ 2048,   512,     1,     1], type =   bf16, converting to q6_K .. size =     2.00 MiB ->     0.82 MiB\n",
      "[ 135/ 147]               blk.14.ffn_down.weight - [ 8192,  2048,     1,     1], type =   bf16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
      "[ 136/ 147]               blk.14.ffn_gate.weight - [ 2048,  8192,     1,     1], type =   bf16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
      "[ 137/ 147]               blk.14.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
      "[ 138/ 147]                 blk.14.ffn_up.weight - [ 2048,  8192,     1,     1], type =   bf16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
      "[ 139/ 147]                 blk.15.attn_k.weight - [ 2048,   512,     1,     1], type =   bf16, converting to q5_K .. size =     2.00 MiB ->     0.69 MiB\n",
      "[ 140/ 147]              blk.15.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
      "[ 141/ 147]            blk.15.attn_output.weight - [ 2048,  2048,     1,     1], type =   bf16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
      "[ 142/ 147]                 blk.15.attn_q.weight - [ 2048,  2048,     1,     1], type =   bf16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
      "[ 143/ 147]                 blk.15.attn_v.weight - [ 2048,   512,     1,     1], type =   bf16, converting to q6_K .. size =     2.00 MiB ->     0.82 MiB\n",
      "[ 144/ 147]               blk.15.ffn_down.weight - [ 8192,  2048,     1,     1], type =   bf16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
      "[ 145/ 147]               blk.15.ffn_gate.weight - [ 2048,  8192,     1,     1], type =   bf16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
      "[ 146/ 147]               blk.15.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
      "[ 147/ 147]                 blk.15.ffn_up.weight - [ 2048,  8192,     1,     1], type =   bf16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
      "llama_model_quantize_impl: model size  =  2357.26 MB\n",
      "llama_model_quantize_impl: quant size  =   861.81 MB\n",
      "\n",
      "main: quantize time = 32490.26 ms\n",
      "main:    total time = 32490.26 ms\n",
      "Unsloth: Conversion completed! Output location: /home/ubuntu/ideal-palm-tree/notebooks/tituslhy/llama32_1bn_raft_non_traditional_credentials_v2/unsloth.Q5_K_M.gguf\n",
      "Unsloth: Uploading GGUF to Huggingface Hub...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8105aa59c89447ebe9871525c6396b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "unsloth.Q4_K_M.gguf:   0%|          | 0.00/808M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved GGUF to https://huggingface.co/tituslhy/llama32_1bn_raft_non_traditional_credentials_v2\n",
      "Unsloth: Uploading GGUF to Huggingface Hub...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a735535a2e4d491b9ef4fdf7d08c096f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "unsloth.Q8_0.gguf:   0%|          | 0.00/1.32G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved GGUF to https://huggingface.co/tituslhy/llama32_1bn_raft_non_traditional_credentials_v2\n",
      "Unsloth: Uploading GGUF to Huggingface Hub...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7812487e04b4ee08ff56ecaa30e2b60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "unsloth.Q5_K_M.gguf:   0%|          | 0.00/912M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved GGUF to https://huggingface.co/tituslhy/llama32_1bn_raft_non_traditional_credentials_v2\n"
     ]
    }
   ],
   "source": [
    "model.push_to_hub_gguf(\n",
    "    \"tituslhy/llama32_1bn_raft_non_traditional_credentials_v2\", # Change hf to your username!\n",
    "    tokenizer,\n",
    "    quantization_method = [\"q4_k_m\", \"q8_0\", \"q5_k_m\",],\n",
    "    token = os.environ[\"HUGGINGFACE_ACCESS_TOKEN\"], # Get a token at https://huggingface.co/settings/tokens\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b0a5ec",
   "metadata": {},
   "source": [
    "# Evaluate finetuned LLM\n",
    "It's now time to evaluate our finetuned LLM! If you're using Ollama like me, you can start by pulling your LLM down using Ollama\n",
    "> !ollama pull hf.co/tituslhy/llama32_1bn_raft_non_traditional_credentials_v2:Q4_K_M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4211ac15",
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuned_llm = Ollama(\n",
    "    \"hf.co/tituslhy/llama32_1bn_raft_non_traditional_credentials_v2:Q4_K_M\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0336af6",
   "metadata": {},
   "source": [
    "Now we set up our query engine with our new shiny LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "65ce27da",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine_finetuned = index.as_query_engine(\n",
    "    llm = finetuned_llm,\n",
    "    similarity_top_k = 6,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09adea49",
   "metadata": {},
   "source": [
    "And instantiate a RagEvaluator using the same qa_dataset generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2953a773",
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuned_rag_evaluator = RagEvaluatorPack(\n",
    "    query_engine=query_engine_finetuned, \n",
    "    rag_dataset=qa_dataset,\n",
    "    judge_llm=Settings.llm, #use the same llm that we use to create the dataset to judge\n",
    "    embed_model=Settings.embed_model\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb5c772",
   "metadata": {},
   "source": [
    "And run!\n",
    "> This cell will take awhile to run - it took me 7.5mins!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d571fdae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:09,  4.70s/it]\n",
      "2it [00:08,  4.30s/it]\n",
      "2it [00:08,  4.37s/it]\n",
      "2it [00:34, 17.36s/it]\n",
      "2it [00:08,  4.11s/it]\n",
      "2it [00:08,  4.38s/it]\n",
      "2it [00:07,  3.83s/it]\n",
      "2it [00:32, 16.26s/it]\n",
      "2it [00:08,  4.36s/it]\n",
      "2it [00:09,  4.66s/it]\n",
      "2it [00:08,  4.36s/it]\n",
      "2it [00:17,  8.79s/it]\n",
      "2it [00:16,  8.11s/it]\n",
      "2it [00:07,  3.94s/it]\n",
      "2it [00:08,  4.21s/it]\n",
      "2it [00:11,  5.83s/it]\n",
      "2it [00:19,  9.68s/it]\n",
      "2it [00:12,  6.07s/it]\n",
      "2it [00:08,  4.06s/it]\n",
      "2it [00:08,  4.22s/it]\n",
      "2it [00:15,  7.69s/it]\n",
      "2it [00:11,  5.93s/it]\n",
      "2it [00:13,  6.78s/it]\n",
      "2it [00:07,  4.00s/it]\n",
      "2it [00:08,  4.07s/it]\n",
      "2it [00:07,  3.79s/it]\n",
      "2it [00:18,  9.36s/it]\n",
      "2it [00:16,  8.26s/it]\n",
      "2it [00:09,  4.54s/it]\n",
      "2it [00:09,  4.56s/it]\n",
      "2it [00:08,  4.19s/it]\n",
      "2it [00:07,  3.91s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>rag</th>\n",
       "      <th>base_rag</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metrics</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean_correctness_score</th>\n",
       "      <td>2.835938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_relevancy_score</th>\n",
       "      <td>0.656250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_faithfulness_score</th>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_context_similarity_score</th>\n",
       "      <td>0.957660</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "rag                            base_rag\n",
       "metrics                                \n",
       "mean_correctness_score         2.835938\n",
       "mean_relevancy_score           0.656250\n",
       "mean_faithfulness_score        0.875000\n",
       "mean_context_similarity_score  0.957660"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark_df_finetuned = finetuned_rag_evaluator.run()\n",
    "benchmark_df_finetuned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35ef559",
   "metadata": {},
   "source": [
    "Hey it worked! But it looks like finetuning did not improve the LLM by very much!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9bd13b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
